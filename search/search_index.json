{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Redes Neurais 2025.2","text":"<p>Este reposit\u00f3rio re\u00fane estudos e projetos em redes neurais e deep learning. Foi explorado conte\u00fados desde os fundamentos \u2014 como perceptrons, fun\u00e7\u00f5es de ativa\u00e7\u00e3o e normaliza\u00e7\u00e3o de dados \u2014 at\u00e9 arquiteturas mais avan\u00e7adas, como redes multicamadas (MLPs), convolucionais (CNNs). O foco est\u00e1 na explora\u00e7\u00e3o dos conceitos e aprendizado de forma pr\u00e1tica.</p> <p>Al\u00e9m de an\u00e1lises pontuais, foram realizadas elabora\u00e7\u00f5es completas, com implementa\u00e7\u00e3o de modelos e estudo sobre a melhor estrutura a ser utilizada de acordo com os datasets utilizados.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Exerc\u00edcio Data - 05/09/2025</li> <li> Exerc\u00edcio Perceptron - 12/09/2025</li> <li> Exerc\u00edcio MLP - 19/09/2025</li> <li> Exerc\u00edcio VAE - 26/09/2025</li> </ul>"},{"location":"exercicios/dados/dados/","title":"Explora\u00e7\u00e3o de dados","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nRANDOM_SEED = 42\nN = 100\n\nclasses = [0, 1, 2, 3]\n\nX_mean = [2, 5, 8, 15]\nY_mean = [3, 6, 1, 4]\n\nX_sd = [0.8, 1.2, 0.9, 0.5]\nY_sd = [2.5, 1.9, 0.9, 2.0]\nlabel_x = []\nlabel_y = []\nlabel_class = []\nnp.random.seed(RANDOM_SEED)\nfor classe in classes:\n    x = np.random.normal(loc=X_mean[classe], scale=X_sd[classe], size=N)\n    y = np.random.normal(loc=Y_mean[classe], scale=Y_sd[classe], size=N)\n    \n    label_x.append(x)\n    label_y.append(y)\n    label_class.append([classe] * N)        \n</pre> import numpy as np RANDOM_SEED = 42 N = 100  classes = [0, 1, 2, 3]  X_mean = [2, 5, 8, 15] Y_mean = [3, 6, 1, 4]  X_sd = [0.8, 1.2, 0.9, 0.5] Y_sd = [2.5, 1.9, 0.9, 2.0] label_x = [] label_y = [] label_class = [] np.random.seed(RANDOM_SEED) for classe in classes:     x = np.random.normal(loc=X_mean[classe], scale=X_sd[classe], size=N)     y = np.random.normal(loc=Y_mean[classe], scale=Y_sd[classe], size=N)          label_x.append(x)     label_y.append(y)     label_class.append([classe] * N)         <p>Utilizando a biblioteca Matplotlib.PyPlot para visualizar como ficaram as distribui\u00e7\u00f5es de cada uma das classes, podemos observar algo como:</p> In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\nscatter = plt.scatter(label_x, label_y, c=label_class, cmap='tab10')\n\nplt.title('Distribui\u00e7\u00e3o das Classes')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.legend(*scatter.legend_elements(), title=\"Classe\")\nplt.show()\n</pre> import matplotlib.pyplot as plt scatter = plt.scatter(label_x, label_y, c=label_class, cmap='tab10')  plt.title('Distribui\u00e7\u00e3o das Classes') plt.xlabel('X') plt.ylabel('Y') plt.legend(*scatter.legend_elements(), title=\"Classe\") plt.show() <p>Em geral, o que pode-se perceber desses dados \u00e9 que as quatro classes possuem uma distribui\u00e7\u00e3o compacta, exceto a classe 1 que \u00e9 um pouco mais esparsa. Por exemplo, a classe 3 est\u00e1 claramente definida entre valores de X pr\u00f3ximo de 15 e Y variando entre 0 e 10, se distanciando bastante das outras classes. A classe 0 tamb\u00e9m tem mais ou menos o mesmo comportamento da classe 3, por\u00e9m em n\u00edveis de valor entre 2 e 2.5 de X. J\u00e1 a classe 1, se apresenta como a mais distinta entre as classes, sendo mais esparsa e gerando bastante sobreposi\u00e7\u00e3o entre seus pontos e os pontos das classes 0 e 2.</p> <p>Simulando poss\u00edveis limites lineares entre os pontos, \u00e9 poss\u00edvel dizer que algumas linhas retas poderiam separar as quatro classes. A classe 3 se apresenta facilmente como candidata a ser separada por uma \u00fanica linha que, em conjunto com outra linha, poderia separar a classe 2. O problema aqui ficou nas classes 0 e 1, em que alguns pontos ficaram sobrepostos, causando dificuldade em separar as classes com apenas uma linha reta. \u00c9 poss\u00edvel tentarmos separar com a reta, mas \u00e9 prov\u00e1vel que isso gere alguns erros de classifica\u00e7\u00e3o.</p> <p>Foi desenhado algumas linhas que podem, de certa forma, simular a separa\u00e7\u00e3o das classes com resolu\u00e7\u00f5es lineares.</p> In\u00a0[3]: Copied! <pre>fig, ax = plt.subplots(figsize=(10, 6.5))\n\nscatter = ax.scatter(label_x, label_y, c=label_class, cmap='tab10')\n\n# x = 12\nfronteira3 = ax.axvline(x=12, color='k', linestyle='--', label='Fronteira Classe 3')\n\n# -1.9x + 11\nx_vals = np.linspace(0, 8, 200)\ny_vals = -1.9 * x_vals + 11\nfronteira01, = ax.plot(x_vals, y_vals, 'm--', label='Fronteira Classe 0/1')\n\n# y=3 x = [4.2, 12]\nx_intersec = (11 - 3) / 1.9\nx_left = max(x_intersec, 0)\nx_right = 12\nfronteira2, = ax.plot([x_left, x_right], [3, 3], linestyle='--', color='gray',\n                      label='Fronteira Classe 2')\n\nax.set_title('Distribui\u00e7\u00e3o das Classes com Fronteiras')\nax.set_xlabel('X')\nax.set_ylabel('Y')\n\nleg_classes = ax.legend(*scatter.legend_elements(), title=\"Classes\",\n                        loc=\"upper center\", bbox_to_anchor=(0.98, 0.98))\nax.add_artist(leg_classes)\n\nax.legend(handles=[fronteira3, fronteira2, fronteira01], title=\"Fronteiras\",\n          loc=\"upper center\", bbox_to_anchor=(0.98, 0.08))\n\nplt.show()\n</pre> fig, ax = plt.subplots(figsize=(10, 6.5))  scatter = ax.scatter(label_x, label_y, c=label_class, cmap='tab10')  # x = 12 fronteira3 = ax.axvline(x=12, color='k', linestyle='--', label='Fronteira Classe 3')  # -1.9x + 11 x_vals = np.linspace(0, 8, 200) y_vals = -1.9 * x_vals + 11 fronteira01, = ax.plot(x_vals, y_vals, 'm--', label='Fronteira Classe 0/1')  # y=3 x = [4.2, 12] x_intersec = (11 - 3) / 1.9 x_left = max(x_intersec, 0) x_right = 12 fronteira2, = ax.plot([x_left, x_right], [3, 3], linestyle='--', color='gray',                       label='Fronteira Classe 2')  ax.set_title('Distribui\u00e7\u00e3o das Classes com Fronteiras') ax.set_xlabel('X') ax.set_ylabel('Y')  leg_classes = ax.legend(*scatter.legend_elements(), title=\"Classes\",                         loc=\"upper center\", bbox_to_anchor=(0.98, 0.98)) ax.add_artist(leg_classes)  ax.legend(handles=[fronteira3, fronteira2, fronteira01], title=\"Fronteiras\",           loc=\"upper center\", bbox_to_anchor=(0.98, 0.08))  plt.show()  In\u00a0[4]: Copied! <pre>import numpy as np\nRANDOM_SEED = 42\nN = 500\nnp.random.seed(RANDOM_SEED)\nclasses = [0, 1]\n\nmean = [[0, 0, 0, 0, 0], [1.5, 1.5, 1.5, 1.5, 1.5]]\nsigma = [\n    [\n        [1.0, 0.8, 0.1, 0.0, 0.0],\n        [0.8, 1.0, 0.3, 0.0, 0.0],\n        [0.1, 0.3, 1.0, 0.5, 0.0],\n        [0.0, 0.0, 0.5, 1.0, 0.2],\n        [0.0, 0.0, 0.0, 0.2, 1.0],\n    ],\n    [\n        [1.5, -0.7, 0.2, 0.0, 0.0],\n        [-0.7, 1.5, 0.4, 0.0, 0.0],\n        [0.2, 0.4, 1.5, 0.6, 0.0],\n        [0.0, 0.0, 0.6, 1.5, 0.3],\n        [0.0, 0.0, 0.0, 0.3, 1.5],\n    ],\n]\n\nlabel_features = []\nlabel_class = []\n\nfor classe in classes:\n    features = np.random.multivariate_normal(mean[classe], sigma[classe], size=N)\n\n    label_features.append(features)\n    label_class.append([classe] * N)\n</pre> import numpy as np RANDOM_SEED = 42 N = 500 np.random.seed(RANDOM_SEED) classes = [0, 1]  mean = [[0, 0, 0, 0, 0], [1.5, 1.5, 1.5, 1.5, 1.5]] sigma = [     [         [1.0, 0.8, 0.1, 0.0, 0.0],         [0.8, 1.0, 0.3, 0.0, 0.0],         [0.1, 0.3, 1.0, 0.5, 0.0],         [0.0, 0.0, 0.5, 1.0, 0.2],         [0.0, 0.0, 0.0, 0.2, 1.0],     ],     [         [1.5, -0.7, 0.2, 0.0, 0.0],         [-0.7, 1.5, 0.4, 0.0, 0.0],         [0.2, 0.4, 1.5, 0.6, 0.0],         [0.0, 0.0, 0.6, 1.5, 0.3],         [0.0, 0.0, 0.0, 0.3, 1.5],     ], ]  label_features = [] label_class = []  for classe in classes:     features = np.random.multivariate_normal(mean[classe], sigma[classe], size=N)      label_features.append(features)     label_class.append([classe] * N) <p>Um grande problema em trabalhar com mais de tr\u00eas dimens\u00f5es, \u00e9 o fato de que n\u00e3o conseguimos mais visualizar os dados o que \u00e9 prejudical, pois muitas vezes, as visualiza\u00e7\u00f5es que trazem grandes insights. Pensando nisso, foi trago aqui uma das v\u00e1rias formas que podemos lidar com esse empecilho: reduzir as dimens\u00f5es utilizando um m\u00e9todo estat\u00edstico - para esse exemplo, foi utilizado o PCA (Principal Component Analysis). Esse transforma um conjunto de vari\u00e1veis possivelmente correlacionadas em um novo conjunto de vari\u00e1veis n\u00e3o correlacionadas, os componentes principais do conjunto de dados. Tais componentes s\u00e3o ordenados de modo a reter a maior parte da vari\u00e2ncia e, portanto, da explicabilidade dos dados. No caso aplicado aqui, o que foi feito \u00e9 transformar os dados que possuem 5 dimens\u00f5es em apenas 2 dimens\u00f5es, possibilitando uma visualiza\u00e7\u00e3o mais clara.</p> <p>Um ponto importante na aplica\u00e7\u00e3o do PCA, \u00e9 a necessidade da normaliza\u00e7\u00e3o dos dados, uma vez que o algoritmo \u00e9 sens\u00edvel \u00e0 escala das vari\u00e1veis. O PCA funciona identificando as dire\u00e7\u00f5es de maior vari\u00e2ncia no conjunto de dados. Se uma vari\u00e1vel estiver em uma escala muito maior que as outras (exemplo: idade $[0,100]$ e renda anual da familia $[100K, 100MM]$), a vari\u00e1vel com maior escala ter\u00e1 uma vari\u00e2ncia numericamente maior e acabar\u00e1 dominando os componentes principais de forma indevida.</p> <p>Ao citar normaliza\u00e7\u00e3o, refere-se a t\u00e9cnica de pr\u00e9-processamento que ajusta a escala das vari\u00e1veis a partir da transforma\u00e7\u00e3o delas, buscando que cada feature tenha m\u00e9dia 0 e desvio padr\u00e3o 1, sem alterar a forma da distribui\u00e7\u00e3o. A f\u00f3rmula matem\u00e1tica para aplicar isso, e que inclusive est\u00e1 implementada na classe <code>StandardScaler</code> utilizada, \u00e9 a seguinte:</p> <p>$$ z_i = \\frac{x_i - \\mu}{\\sigma} $$</p> <p>Onde $x_i$ \u00e9 o valor original, $\\mu$ \u00e9 a m\u00e9dia e $\\sigma$ \u00e9 o desvio padr\u00e3o da vari\u00e1vel.</p> <p>Outro ponto t\u00e3o importante quanto, \u00e9 que as classes foram geradas com distribui\u00e7\u00f5es diferentes e de forma separada, no entanto, para aplicar o PCA, \u00e9 necess\u00e1rio juntar as classes. Uma vez que, se o PCA for feito separadamente em cada classe, o algoritmo vai calcular os componentes principais a partir da matriz de covari\u00e2ncia de cada subconjunto. Isso significa que o primeiro componente principal da classe A n\u00e3o ter\u00e1 rela\u00e7\u00e3o com o primeiro componente principal da classe B, j\u00e1 que cada um \u00e9 constru\u00eddo em um espa\u00e7o pr\u00f3prio. Nesse cen\u00e1rio, se voc\u00ea tentar colocar os dois conjuntos no mesmo gr\u00e1fico, as dire\u00e7\u00f5es escolhidas pelo PCA n\u00e3o ser\u00e3o compar\u00e1veis invalidando nossa explora\u00e7\u00e3o dos dados.</p> <p>Por outro lado, se voc\u00ea empilha os dados das duas classes em uma \u00fanica matriz e aplica o PCA, o resultado \u00e9 um espa\u00e7o bidimensional comum que captura a maior parte da vari\u00e2ncia considerando todas as amostras ao mesmo tempo. Assim, tanto a Classe A quanto a Classe B s\u00e3o projetadas no mesmo sistema de eixos, o que torna poss\u00edvel comparar diretamente as distribui\u00e7\u00f5es e enxergar a separa\u00e7\u00e3o entre elas.</p> <p>Tanto a aplica\u00e7\u00e3o da normaliza\u00e7\u00e3o, quanto o pr\u00f3prio PCA, foram implementados utilizando a biblioteca do Scikit-Learn.</p> In\u00a0[5]: Copied! <pre>from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nx_A, x_B = label_features\nnp.random.seed(RANDOM_SEED)\nN_COMPONENTS = 2\nRANDOM_SEED = 42\n\npca = PCA(n_components=N_COMPONENTS, random_state=RANDOM_SEED)\n\nX = np.vstack([x_A, x_B])\n\nX_scaled = StandardScaler().fit_transform(X)\n\npca_global = PCA(n_components=2, random_state=42)\n\nZ_global = pca_global.fit_transform(X_scaled)\n</pre> from sklearn.decomposition import PCA from sklearn.preprocessing import StandardScaler  x_A, x_B = label_features np.random.seed(RANDOM_SEED) N_COMPONENTS = 2 RANDOM_SEED = 42  pca = PCA(n_components=N_COMPONENTS, random_state=RANDOM_SEED)  X = np.vstack([x_A, x_B])  X_scaled = StandardScaler().fit_transform(X)  pca_global = PCA(n_components=2, random_state=42)  Z_global = pca_global.fit_transform(X_scaled) <p>Agora com os dados em duas dimens\u00f5es, pode-se visualizar:</p> In\u00a0[6]: Copied! <pre>import matplotlib.pyplot as plt\n\nscatter = plt.scatter(Z_global[:, 0], Z_global[:, 1], c=label_class, cmap='tab10')\n\nvr = pca_global.explained_variance_ratio_\n\nplt.title(f'PCA \u2014 Var.Exp: {vr[0]:.2f}, {vr[1]:.2f}')\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.legend(*scatter.legend_elements(), title=\"Classe\")\n</pre> import matplotlib.pyplot as plt  scatter = plt.scatter(Z_global[:, 0], Z_global[:, 1], c=label_class, cmap='tab10')  vr = pca_global.explained_variance_ratio_  plt.title(f'PCA \u2014 Var.Exp: {vr[0]:.2f}, {vr[1]:.2f}') plt.xlabel('PC1') plt.ylabel('PC2') plt.legend(*scatter.legend_elements(), title=\"Classe\") Out[6]: <pre>&lt;matplotlib.legend.Legend at 0x7f705870b390&gt;</pre> <p>Os dois n\u00fameros representados no t\u00edtulo do gr\u00e1fico 0.52 e 0.16 s\u00e3o o somat\u00f3rio da vari\u00e2ncia explicada por cada componente principal gerado pelo PCA. Isto pode ser interpretado como: \"O PC1 carrega 52% da vari\u00e2ncia dos dados e o PC2 16%\". Dessa forma, significa que ao reduzir 3 das 5 dimens\u00f5es, a quantidade de vari\u00e2ncia dos dados perdida foi de 32%. A partir de m\u00e9tricas como essa, pode-se avaliar quantas dimens\u00f5es reduzir no espec\u00edfico dataset, sem perder parte importante da explicabilidade dos dados.</p> <p>Analisando em 2D as duas classes, \u00e9 percept\u00edvel que essas possuem dispers\u00f5es muito parecidas, sendo facilmente confundidas como a mesma classe. Fazendo o exerc\u00edcio de ignonar as cores dos pontos, \u00e9 muito prov\u00e1vel que uma pessoa idenficaria tudo como um cluster s\u00f3. Al\u00e9m disso, uma linha reta \u00e9 completamente invi\u00e1vel de ser usada para separar os dois grupos.</p> <p>Por serem classes de 5 dimens\u00f5es, mesmo abstraindo tr\u00eas das cinco dimens\u00f5es, e transformando a visualiza\u00e7\u00e3o dos dados em um plano, \u00e9 muito dif\u00edcil a resolu\u00e7\u00e3o da separa\u00e7\u00e3o estar presente em fun\u00e7\u00f5es lineares. Para alcan\u00e7ar uma boa forma de separa\u00e7\u00e3o desses dados, seria provavelmente necess\u00e1rio o uso de todas as suas dimens\u00f5es e modelos n\u00e3o lineares, sendo capazes de fazer curvas e se adaptar melhor aos dados. Utilizando como solu\u00e7\u00e3o um MLP, provavelmente seria poss\u00edvel alcan\u00e7ar tal adaptabilidade dos dados, uma vez que suas camadas ocultas possibilitam construir fronteiras de decis\u00e3o por partes, as quais lidam com todas as features das duas classes de forma particionada.</p> In\u00a0[7]: Copied! <pre>from pathlib import Path\nimport pandas as pd\nimport warnings\nwarnings.simplefilter(\"ignore\", FutureWarning)\n\nBASE_DIR = Path().resolve().parent.parent.parent\nDATA_DIR = BASE_DIR / \"docs\" / \"exercicios\" / \"dados\" / \"data\"\ntitanic_df = pd.read_csv(DATA_DIR / \"train.csv\")\n</pre> from pathlib import Path import pandas as pd import warnings warnings.simplefilter(\"ignore\", FutureWarning)  BASE_DIR = Path().resolve().parent.parent.parent DATA_DIR = BASE_DIR / \"docs\" / \"exercicios\" / \"dados\" / \"data\" titanic_df = pd.read_csv(DATA_DIR / \"train.csv\") <p>O dataset Spaceship Titanic trata os dados dos passageiros da viagem do Titanic em formato de s\u00e1tira, onde os passageiros est\u00e3o em uma viagem espacial e sofrem uma anomalia, causando muitas mortes. A ideia aqui \u00e9 desafiar as pessoas a explorar os dados dos passageiros da viagem para descobrir quem foram os sobreviventes, com base nas informa\u00e7\u00f5es de cada um, como por exemplo, n\u00edvel de cabine, idade, a cidade de destino e etc.</p> <p>A vari\u00e1vel Transported, target do dataset, referencia se o passageiro morreu ou n\u00e3o, isto \u00e9, foi transportado para uma outra dimens\u00e3o. Dessa forma, caso seja True seu valor, o passageiro morreu no acidente, e o contr\u00e1rio n\u00e3o.</p> <p>O restante das vari\u00e1vies indepentes trazem algumas informa\u00e7\u00f5es como:</p> <ul> <li>PassengerId: ID do passageiro, com os quatro primeiros d\u00edgitos sendo o grupo de pessoas que ele est\u00e1 viajando e os dois \u00faltimos o seu id dentro do grupo.</li> <li>Name: O nome completo do passageiro.</li> <li>HomePlanet: Onde o passageiro mora.</li> <li>CryoSleep: Vari\u00e1vel booleana se o passageiro escolheu ficar em hiberna\u00e7\u00e3o durante a viagem. Se sim, isso indica que eles ficaram presos nas suas cabines.</li> <li>Cabin: O n\u00famero da cabine e onde ela est\u00e1 localizada na nave. (Deck/N\u00famero do quarto/Lado)</li> <li>Destination: O destino do passageiro.</li> <li>Age: A idade do passageiro.</li> <li>VIP: Vari\u00e1vel booleana se o passageiro pagou para ter tratamentos VIPs durante a viagem.</li> <li>RoomService: Valores gasto pelo passageiro no servi\u00e7o de quarto.</li> <li>FoodCourt: Valores gasto pelo passageiro no restaurante.</li> <li>ShoppingMall: Valores gasto pelo passageiro no shopping da nave.</li> <li>Spa: Valores gasto pelo passageiro no Spa.</li> <li>VRDeck: Valores gasto pelo passageiro no Deck.</li> </ul> In\u00a0[8]: Copied! <pre>titanic_df.info()\n</pre> titanic_df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 8693 entries, 0 to 8692\nData columns (total 14 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   PassengerId   8693 non-null   object \n 1   HomePlanet    8492 non-null   object \n 2   CryoSleep     8476 non-null   object \n 3   Cabin         8494 non-null   object \n 4   Destination   8511 non-null   object \n 5   Age           8514 non-null   float64\n 6   VIP           8490 non-null   object \n 7   RoomService   8512 non-null   float64\n 8   FoodCourt     8510 non-null   float64\n 9   ShoppingMall  8485 non-null   float64\n 10  Spa           8510 non-null   float64\n 11  VRDeck        8505 non-null   float64\n 12  Name          8493 non-null   object \n 13  Transported   8693 non-null   bool   \ndtypes: bool(1), float64(6), object(7)\nmemory usage: 891.5+ KB\n</pre> <p>Com rela\u00e7\u00e3o a dados faltantes, como todo bom dataset, esse cont\u00e9m algumas colunas com valores NaN, mais especificamente 8693 linhas, com todas colunas com valores faltantes, exceto o PassengerId e Transported que s\u00e3o o identificador \u00fanico do passageiro e a vari\u00e1vel dependente. Saber lidar com os dados faltantes de um dataset muitas vezes \u00e9 a virada de chave para um bom desempenho de um modelo/rede neural, porque em algum casos, a quantidade de dados faltantes \u00e9 super relevante e impacta o treinamento do modelo.</p> <p>Tendo isso em vista, para lidar com os dados faltantes, \u00e9 necess\u00e1rio separar elas entre n\u00famericas e categ\u00f3ricas:</p> <p>CATEG\u00d3RICAS:</p> <ul> <li>HomePlanet</li> <li>CryoSleep</li> <li>Cabin</li> <li>Destination</li> <li>VIP</li> <li>Name</li> </ul> <p>N\u00daMERICAS:</p> <ul> <li>Age</li> <li>RoomService</li> <li>FoodCourt</li> <li>ShoppingMall</li> <li>Spa</li> <li>VRDeck</li> </ul> <p>Com rela\u00e7\u00e3o as categ\u00f3ricas, \u00e9 necess\u00e1rio analisar caso a caso.</p> In\u00a0[9]: Copied! <pre>process_titanic_df = titanic_df.copy()\n</pre> process_titanic_df = titanic_df.copy() <p>No caso de HomePlanet que representa a origem do passageiro, pode-se utilizar a moda como forma de input dos dados faltantes.</p> In\u00a0[10]: Copied! <pre>process_titanic_df.HomePlanet.fillna(process_titanic_df.HomePlanet.mode()[0], inplace=True)\n</pre> process_titanic_df.HomePlanet.fillna(process_titanic_df.HomePlanet.mode()[0], inplace=True) <p>J\u00e1 para o caso da Cabin, utilizou-se a moda, por\u00e9m separadas por duas vari\u00e1veis que parecem ser relevantes para a escolha da ala da nave. A primeira, se a pessoa escolheu viajar hibernando, e a segunda, caso a primeira seja falsa, \u00e9 se o passageiro \u00e9 um VIP ou n\u00e3o. A partir dessas separa\u00e7\u00f5es, aplicar\u00e1-se a moda. Uma coisa importante de pontuar, \u00e9 que a vari\u00e1vel de Cabine foi usada de uma forma diferente retirando o n\u00famero da cabine em si e fazendo a moda das combina\u00e7\u00f5es de (deck/side).</p> In\u00a0[11]: Copied! <pre>deck_hiberna, side_hiberna = (\n    process_titanic_df.query(\"CryoSleep == True\").Cabin.mode()[0].split(\"/\")[0:3:2]\n)\ndeck_VIP, side_VIP = (\n    process_titanic_df.query(\"CryoSleep == False and VIP == True\")\n    .Cabin.mode()[0]\n    .split(\"/\")[0:3:2]\n)\ndeck, side = (\n    process_titanic_df.query(\"CryoSleep == False and VIP == False\")\n    .Cabin.mode()[0]\n    .split(\"/\")[0:3:2]\n)\n\n\ndef input_cabin(row):\n    if pd.isna(row.Cabin):\n        if row.CryoSleep == True:\n            return f\"{deck_hiberna}/000/{side_hiberna}\"\n        elif row.VIP == True:\n            return f\"{deck_VIP}/000/{side_VIP}\"\n        else:\n            return f\"{deck}/000/{side}\"\n    return row.Cabin\n\n\nprocess_titanic_df.Cabin = process_titanic_df.apply(input_cabin, axis=1)\n\nprocess_titanic_df = process_titanic_df.assign(\n    Deck=lambda df: df.Cabin.apply(lambda linha: linha.split(\"/\")[0]),\n    Side=lambda df: df.Cabin.apply(lambda linha: linha.split(\"/\")[-1]),\n).drop([\"Cabin\"], axis=1)\n</pre> deck_hiberna, side_hiberna = (     process_titanic_df.query(\"CryoSleep == True\").Cabin.mode()[0].split(\"/\")[0:3:2] ) deck_VIP, side_VIP = (     process_titanic_df.query(\"CryoSleep == False and VIP == True\")     .Cabin.mode()[0]     .split(\"/\")[0:3:2] ) deck, side = (     process_titanic_df.query(\"CryoSleep == False and VIP == False\")     .Cabin.mode()[0]     .split(\"/\")[0:3:2] )   def input_cabin(row):     if pd.isna(row.Cabin):         if row.CryoSleep == True:             return f\"{deck_hiberna}/000/{side_hiberna}\"         elif row.VIP == True:             return f\"{deck_VIP}/000/{side_VIP}\"         else:             return f\"{deck}/000/{side}\"     return row.Cabin   process_titanic_df.Cabin = process_titanic_df.apply(input_cabin, axis=1)  process_titanic_df = process_titanic_df.assign(     Deck=lambda df: df.Cabin.apply(lambda linha: linha.split(\"/\")[0]),     Side=lambda df: df.Cabin.apply(lambda linha: linha.split(\"/\")[-1]), ).drop([\"Cabin\"], axis=1) <p>Para Destination pode-se utilizar a mesma t\u00e9cnica usada para HomePlanet, aplicando apenas a moda.</p> In\u00a0[12]: Copied! <pre>process_titanic_df.Destination.fillna(process_titanic_df.Destination.mode()[0], inplace=True)\n</pre> process_titanic_df.Destination.fillna(process_titanic_df.Destination.mode()[0], inplace=True) <p>Para a vari\u00e1vel VIP, utilizou-se a mesma ideia de Cabin, pegando a mediana do grupo de passageiros VIPs e n\u00e3o VIPs e a partir dos gastos dos passageiros sem r\u00f3tulo de VIP, foi aplicado a eles a mediana mais pr\u00f3xima.</p> In\u00a0[13]: Copied! <pre>medianas_VIP = (\n    process_titanic_df\n    .assign(\n        RoomService=lambda df: df.RoomService.fillna(0),\n        FoodCourt=lambda df: df.FoodCourt.fillna(0),\n        ShoppingMall=lambda df: df.ShoppingMall.fillna(0),\n        Spa=lambda df: df.Spa.fillna(0),\n        VRDeck=lambda df: df.VRDeck.fillna(0),\n        total_amount=lambda df: df.RoomService + df.FoodCourt + df.ShoppingMall + df.Spa + df.VRDeck\n    )\n    .query(\"VIP.notnull()\")\n    .groupby(\"VIP\")[\"total_amount\"]\n    .median()\n    .to_dict()\n)\n\nprocess_titanic_df.VIP = process_titanic_df.assign(\n    RoomService=lambda df: df.RoomService.fillna(0),\n    FoodCourt=lambda df: df.FoodCourt.fillna(0),\n    ShoppingMall=lambda df: df.ShoppingMall.fillna(0),\n    Spa=lambda df: df.Spa.fillna(0),\n    VRDeck=lambda df: df.VRDeck.fillna(0),\n    total_amount=lambda df: df.RoomService + df.FoodCourt + df.ShoppingMall + df.Spa + df.VRDeck,\n    diff_vip_true=lambda df: (df.total_amount - medianas_VIP[True]).abs(),\n    diff_vip_false=lambda df: (df.total_amount - medianas_VIP[False]).abs(),\n    VIP=lambda df: df.VIP.where(\n        df.VIP.notna(),  # mant\u00e9m os j\u00e1 preenchidos\n        df.diff_vip_true &lt; df.diff_vip_false  # preenche os NaN\n    )\n).VIP\n</pre> medianas_VIP = (     process_titanic_df     .assign(         RoomService=lambda df: df.RoomService.fillna(0),         FoodCourt=lambda df: df.FoodCourt.fillna(0),         ShoppingMall=lambda df: df.ShoppingMall.fillna(0),         Spa=lambda df: df.Spa.fillna(0),         VRDeck=lambda df: df.VRDeck.fillna(0),         total_amount=lambda df: df.RoomService + df.FoodCourt + df.ShoppingMall + df.Spa + df.VRDeck     )     .query(\"VIP.notnull()\")     .groupby(\"VIP\")[\"total_amount\"]     .median()     .to_dict() )  process_titanic_df.VIP = process_titanic_df.assign(     RoomService=lambda df: df.RoomService.fillna(0),     FoodCourt=lambda df: df.FoodCourt.fillna(0),     ShoppingMall=lambda df: df.ShoppingMall.fillna(0),     Spa=lambda df: df.Spa.fillna(0),     VRDeck=lambda df: df.VRDeck.fillna(0),     total_amount=lambda df: df.RoomService + df.FoodCourt + df.ShoppingMall + df.Spa + df.VRDeck,     diff_vip_true=lambda df: (df.total_amount - medianas_VIP[True]).abs(),     diff_vip_false=lambda df: (df.total_amount - medianas_VIP[False]).abs(),     VIP=lambda df: df.VIP.where(         df.VIP.notna(),  # mant\u00e9m os j\u00e1 preenchidos         df.diff_vip_true &lt; df.diff_vip_false  # preenche os NaN     ) ).VIP <p>No caso de CryoSleep que \u00e9 a booleana referente ao passageiro que optou por ficar em hiberna\u00e7\u00e3o durante a viagem, essa \u00e9 uma var\u00edavel pass\u00edvel de ser predita a partir das outras vari\u00e1veis como por exemplo os gastos nos estabelecimentos. No entanto, por quest\u00f5es de simplifica\u00e7\u00e3o, foi utilizada apenas a moda como forma de input.</p> In\u00a0[14]: Copied! <pre>process_titanic_df.CryoSleep.fillna(process_titanic_df.CryoSleep.mode()[0], inplace=True)\n</pre> process_titanic_df.CryoSleep.fillna(process_titanic_df.CryoSleep.mode()[0], inplace=True) <p>E por fim, as vari\u00e1veis Nome e PassengerID, por serem var\u00edaveis identificadoras dos indiv\u00edduos, n\u00e3o ser\u00e3o usadas, para n\u00e3o criar um vi\u00e9s na rede.</p> In\u00a0[15]: Copied! <pre>process_titanic_df.drop(['PassengerId', 'Name'], axis=1, inplace=True)\n</pre> process_titanic_df.drop(['PassengerId', 'Name'], axis=1, inplace=True) <p>J\u00e1 sobre as n\u00famericas, a vari\u00e1vel Age ser\u00e1 preenchida com a mediana dos passageiros, por ser a forma mais est\u00e1vel e que traz, em teoria, menos vi\u00e9s para a rede.</p> In\u00a0[16]: Copied! <pre>process_titanic_df.Age = process_titanic_df.Age.fillna(process_titanic_df.Age.median())\n</pre> process_titanic_df.Age = process_titanic_df.Age.fillna(process_titanic_df.Age.median()) <p>J\u00e1 as vari\u00e1veis de gasto nos estabelecimentos: RoomService; FoodCourt; ShoppingMall; Spa; VRDeck, ser\u00e3o preenchidas com a seguinte regra. Se a pessoa tem a vari\u00e1vel CryoSleep igual a True, todo valor faltantes ser\u00e1 preenchido com zero, afinal, ela estava hibernando e n\u00e3o gastou nada.  Agora j\u00e1 aqueles passageiros com CryoSleep igual a False, ou com essa vari\u00e1vel, tamb\u00e9m com o dado faltante, os gastos ser\u00e3o preenchidos com base na m\u00e9dia dos gastos nos outros estabelecimentos, afinal, n\u00e3o tem nenhum passageiro com todas as vari\u00e1veis de consumo vazias ao mesmo tempo.</p> In\u00a0[17]: Copied! <pre>col_consumo = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n\nhiberna_true = process_titanic_df['CryoSleep'] == True\nprocess_titanic_df.loc[hiberna_true, col_consumo] = process_titanic_df.loc[hiberna_true, col_consumo].fillna(0)\n\ndef fill_row_expenses(row):\n    row[col_consumo] = row[col_consumo].fillna(row[col_consumo].mean())\n    return row\n\nprocess_titanic_df.loc[~hiberna_true] = process_titanic_df.loc[~hiberna_true].apply(fill_row_expenses, axis=1)\n</pre> col_consumo = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']  hiberna_true = process_titanic_df['CryoSleep'] == True process_titanic_df.loc[hiberna_true, col_consumo] = process_titanic_df.loc[hiberna_true, col_consumo].fillna(0)  def fill_row_expenses(row):     row[col_consumo] = row[col_consumo].fillna(row[col_consumo].mean())     return row  process_titanic_df.loc[~hiberna_true] = process_titanic_df.loc[~hiberna_true].apply(fill_row_expenses, axis=1) In\u00a0[18]: Copied! <pre>y = process_titanic_df[\"Transported\"].astype(int)\nX = process_titanic_df.drop(columns=[\"Transported\", \"PassengerId\", \"Name\"], errors=\"ignore\")\n</pre> y = process_titanic_df[\"Transported\"].astype(int) X = process_titanic_df.drop(columns=[\"Transported\", \"PassengerId\", \"Name\"], errors=\"ignore\") In\u00a0[19]: Copied! <pre>categoricas = X.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\nnumericas = X.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n</pre> categoricas = X.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist() numericas = X.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist() In\u00a0[20]: Copied! <pre>X = pd.get_dummies(X, columns=categoricas, drop_first=True)\n</pre> X = pd.get_dummies(X, columns=categoricas, drop_first=True) In\u00a0[21]: Copied! <pre>def normaliza_numerica(df: pd.DataFrame, cols: list[str]) -&gt; pd.DataFrame:\n    df_copy = df.copy()\n    \n    for col in cols:\n        min_val = df_copy[col].min()\n        max_val = df_copy[col].max()\n\n        df_copy[col] = 2 * (df_copy[col] - min_val) / (max_val - min_val) - 1\n    \n    return df_copy\n</pre> def normaliza_numerica(df: pd.DataFrame, cols: list[str]) -&gt; pd.DataFrame:     df_copy = df.copy()          for col in cols:         min_val = df_copy[col].min()         max_val = df_copy[col].max()          df_copy[col] = 2 * (df_copy[col] - min_val) / (max_val - min_val) - 1          return df_copy <p>Aqui novamente, assim como foi aplicada a normaliza\u00e7\u00e3o nos exemplos anteriores, aplicou-se para todas as vari\u00e1veis n\u00famericas, justamente pela explora\u00e7\u00e3o simular que o dataset seria inputado em uma rede neural posteriormente. Rede neural essa que possui como fun\u00e7\u00e3o de ativa\u00e7\u00e3o,, a <code>tanh(x)</code>, cuja suas maiores derivadas est\u00e3o concentradas entre $[-1, 1]$. Logo, a normaliza\u00e7\u00e3o aplicada nesse caso n\u00e3o \u00e9 a mesma apresentada anteriormente, buscando uma distribui\u00e7\u00e3o de m\u00e9dia 0 e desvio padr\u00e3o. Nesse caso foi aplicada a normaliza\u00e7\u00e3o, minmax de segundo grau, que busca justamente a diposi\u00e7\u00e3o $[-1, 1]$, expressa por:</p> <p>$$ x'' = 2 \\cdot \\frac{x - \\min}{\\max - \\min} - 1 $$</p> In\u00a0[22]: Copied! <pre>X = normaliza_numerica(X, numericas)\n</pre> X = normaliza_numerica(X, numericas) <p>Pode-se perceber o efeito dessa normaliza\u00e7\u00e3o a partir de histogramas como:</p> In\u00a0[23]: Copied! <pre>fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\naxes[0].hist(titanic_df[\"Age\"], bins=30, color=\"skyblue\", edgecolor=\"black\", alpha=0.6, density=True)\ntitanic_df[\"Age\"].plot(kind=\"kde\", ax=axes[0], color=\"darkblue\")\naxes[0].set_title(\"Age - Antes\")\n\naxes[1].hist(X[\"Age\"], bins=30, color=\"salmon\", edgecolor=\"black\", alpha=0.6, density=True)\nX[\"Age\"].plot(kind=\"kde\", ax=axes[1], color=\"darkred\")\naxes[1].set_title(\"Age - Depois\")\n\nplt.tight_layout()\nplt.show()\n</pre> fig, axes = plt.subplots(1, 2, figsize=(12, 4))  axes[0].hist(titanic_df[\"Age\"], bins=30, color=\"skyblue\", edgecolor=\"black\", alpha=0.6, density=True) titanic_df[\"Age\"].plot(kind=\"kde\", ax=axes[0], color=\"darkblue\") axes[0].set_title(\"Age - Antes\")  axes[1].hist(X[\"Age\"], bins=30, color=\"salmon\", edgecolor=\"black\", alpha=0.6, density=True) X[\"Age\"].plot(kind=\"kde\", ax=axes[1], color=\"darkred\") axes[1].set_title(\"Age - Depois\")  plt.tight_layout() plt.show() In\u00a0[24]: Copied! <pre>fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\naxes[0].hist(titanic_df[\"FoodCourt\"], bins=30, color=\"skyblue\", edgecolor=\"black\", alpha=0.6, density=True)\ntitanic_df[\"FoodCourt\"].plot(kind=\"kde\", ax=axes[0], color=\"darkblue\")\naxes[0].set_title(\"FoodCourt - Antes\")\n\naxes[1].hist(X[\"FoodCourt\"], bins=30, color=\"salmon\", edgecolor=\"black\", alpha=0.6, density=True)\nX[\"FoodCourt\"].plot(kind=\"kde\", ax=axes[1], color=\"darkred\")\naxes[1].set_title(\"FoodCourt - Depois\")\n\nplt.tight_layout()\nplt.show()\n</pre> fig, axes = plt.subplots(1, 2, figsize=(12, 4))  axes[0].hist(titanic_df[\"FoodCourt\"], bins=30, color=\"skyblue\", edgecolor=\"black\", alpha=0.6, density=True) titanic_df[\"FoodCourt\"].plot(kind=\"kde\", ax=axes[0], color=\"darkblue\") axes[0].set_title(\"FoodCourt - Antes\")  axes[1].hist(X[\"FoodCourt\"], bins=30, color=\"salmon\", edgecolor=\"black\", alpha=0.6, density=True) X[\"FoodCourt\"].plot(kind=\"kde\", ax=axes[1], color=\"darkred\") axes[1].set_title(\"FoodCourt - Depois\")  plt.tight_layout() plt.show() <p>Como \u00e9 poss\u00edvel ver nos dois casos, as distribui\u00e7\u00f5es n\u00e3o foram afetadas ao aplicar a normaliza\u00e7\u00e3o, apenas as escalas das var\u00edaveis que foram alteradas o que evita com que n\u00fameros muito grandes ou desbalanceados causem satura\u00e7\u00e3o nos neur\u00f4nios por conta da derivada da fun\u00e7\u00e3o <code>tanh(x)</code> ser quase 0, o que prejudica o aprendizado. De modo geral, a noramliza\u00e7\u00e3o estabiliza o treinamento, melhora a converg\u00eancia do gradiente e ajuda a rede a aproveitar melhor a simetria da tanh em torno de zero, resultando em pesos mais bem distribu\u00eddos e em uma performance mais consistente.</p>"},{"location":"exercicios/dados/dados/#exploracao-de-dados","title":"Explora\u00e7\u00e3o de dados\u00b6","text":"<p>Nessa se\u00e7\u00e3o, foi explorado a natureza dos dados, como eles podem se comportar com classes separadas de forma linear e n\u00e3o linear, entendendo funcionamento e visualizando em formato de gr\u00e1ficos. Ao final, foi realizada, de forma breve, uma manipula\u00e7\u00e3o com base no dataset Spaceship Titanic, explorando suas vari\u00e1veis, a distribui\u00e7\u00e3o dos dados e como lidar com algumas observa\u00e7\u00f5es com dados faltantes. Al\u00e9m disso, foi explorado como faria para pr\u00e9 processar os dados, visando utiliz\u00e1-los como entrada em uma rede neural.</p>"},{"location":"exercicios/dados/dados/#separacao-de-dados-em-2d","title":"Separa\u00e7\u00e3o de dados em 2D\u00b6","text":"<p>Buscando explorar dados primeiramente em apenas duas dimens\u00f5es, foi gerado amostras de 100 observa\u00e7\u00f5es em cada, cujas distribui\u00e7\u00f5es eram ditadas pelas seguintes regras:</p> <ul> <li>Classe 0: Mean = $[2, 3]$, Standard Deviation = $[0.8, 2.5]$</li> <li>Classe 1: Mean = $[5, 6]$, Standard Deviation = $[1.2, 1.9]$</li> <li>Classe 2: Mean = $[8, 1]$, Standard Deviation = $[0.9, 0.9]$</li> <li>Classe 3: Mean = $[15, 4]$, Standard Deviation = $[0.5, 2.0]$</li> </ul> <p>Para isso, foi utilizado uma das bibliotecas mais cl\u00e1ssicas do Python, NumPy, para gerar cada uma das classes, com a sua respectiva distribui\u00e7\u00e3o. Tendo em vista a replicabilidade desse estudo, foi utilizado uma RANDOM SEED (42).</p>"},{"location":"exercicios/dados/dados/#a-nao-linearidade-em-mais-dimensoes","title":"A n\u00e3o linearidade em mais dimens\u00f5es\u00b6","text":"<p>Agora lidando com mais de diposi\u00e7\u00e3o de dados com mais dimens\u00f5es, isto \u00e9, com mais vari\u00e1veis a serem exploradas, foram geradas classes multivariadas que seguiram as seguintes distribui\u00e7\u00f5es:</p> <ul> <li><p>Class A:</p> <p>Mean vector:</p> <p>$$\\mu_A = [0, 0, 0, 0, 0]$$</p> <p>Covariance matrix:</p> <p>$$   \\Sigma_A = \\begin{pmatrix} 1.0 &amp; 0.8 &amp; 0.1 &amp; 0.0 &amp; 0.0 \\\\   0.8 &amp; 1.0 &amp; 0.3 &amp; 0.0 &amp; 0.0 \\\\   0.1 &amp; 0.3 &amp; 1.0 &amp; 0.5 &amp; 0.0 \\\\   0.0 &amp; 0.0 &amp; 0.5 &amp; 1.0 &amp; 0.2 \\\\   0.0 &amp; 0.0 &amp; 0.0 &amp; 0.2 &amp; 1.0   \\end{pmatrix}   $$</p> </li> <li><p>Class B:</p> <p>Mean vector:</p> <p>$$\\mu_B = [1.5, 1.5, 1.5, 1.5, 1.5]$$</p> <p>Covariance matrix:</p> <p>$$   \\Sigma_B = \\begin{pmatrix} 1.5 &amp; -0.7 &amp; 0.2 &amp; 0.0 &amp; 0.0 \\\\   -0.7 &amp; 1.5 &amp; 0.4 &amp; 0.0 &amp; 0.0 \\\\   0.2 &amp; 0.4 &amp; 1.5 &amp; 0.6 &amp; 0.0 \\\\   0.0 &amp; 0.0 &amp; 0.6 &amp; 1.5 &amp; 0.3 \\\\   0.0 &amp; 0.0 &amp; 0.0 &amp; 0.3 &amp; 1.5   \\end{pmatrix}   $$</p> </li> </ul> <p>Mantendo a replicabilidade, utiliza-se novamente a RANDOM SEED (42), e na gera\u00e7\u00e3o dos dados a lib NumPy.</p>"},{"location":"exercicios/dados/dados/#explorando-um-dataset-real","title":"Explorando um dataset real\u00b6","text":"<p>Nessa parte final, o desafio foi aplicar o que foi apreendido durante as \u00faltimas sec\u00e7\u00f5es em um dataset elaborado, no caso Spaceship Titanic do Kaggle. Para esse exerc\u00edcio de explora\u00e7\u00e3o, foi feito o download do dataset.</p>"},{"location":"exercicios/mpl/mlp/","title":"MPL (Multi Layer Perceptron)","text":"In\u00a0[1]: Copied! <pre>import numpy as np\n\nx = np.array([[0.5], \n              [-0.2], \n              [1]])\n\nW1 = np.array([[0.3, 0.2, 0.1],\n               [-0.1, 0.4, -0.2]])\n\nz1 = np.dot(W1, x)\nz1\n</pre> import numpy as np  x = np.array([[0.5],                [-0.2],                [1]])  W1 = np.array([[0.3, 0.2, 0.1],                [-0.1, 0.4, -0.2]])  z1 = np.dot(W1, x) z1 Out[1]: <pre>array([[ 0.21],\n       [-0.33]])</pre> <p>Desse modo, com a sa\u00edda do primeiro perceptron, \u00e9 necess\u00e1rio aplicar a fun\u00e7\u00e3o de ativa\u00e7\u00e3o, tanh().</p> <p>$$ \\mathbf{h}^{(1)}=\\tanh\\!\\big(\\mathbf{z}^{(1)}\\big) = \\begin{bmatrix} \\tanh(0.21)\\\\[2pt] \\tanh(-0.33) \\end{bmatrix} = \\begin{bmatrix} 0.2069665\\\\[2pt] -0.31852078 \\end{bmatrix} $$</p> In\u00a0[2]: Copied! <pre>h1 = np.tanh(z1)\nh1\n</pre> h1 = np.tanh(z1) h1 Out[2]: <pre>array([[ 0.2069665 ],\n       [-0.31852078]])</pre> <p>Utilizando $\\mathbf{h}^{(1)}$ como input para o segundo perceptron e os pesos novamente contando com o bias:</p> <p>$$ \\mathbf{h}^{(1)} = \\begin{bmatrix} 0.2069665\\\\[2pt] -0.31852078\\\\[2pt] 1 \\end{bmatrix}  \\qquad  \\mathbf{W}^{(2)} = \\begin{bmatrix} 0.5 &amp; -0.3 &amp; 0.2 \\end{bmatrix} $$</p> <p>$$ u^{(2)} \\;=\\; \\mathbf{W}^{(2)}\\,\\mathbf{h} \\;=\\; \\begin{bmatrix}0.5 &amp; -0.3 &amp; 0.2\\end{bmatrix} \\begin{bmatrix} 0.2069665\\\\[2pt] -0.31852078\\\\[2pt] 1 \\end{bmatrix} \\; =\\; 0.39903948 $$</p> <p>$$ u^{(2)} = 0.39903948 $$</p> In\u00a0[3]: Copied! <pre>h1_bias = np.vstack([h1, [[1]]])\n\nW2 = np.array([0.5, -0.3, 0.2])\n\nu2 = np.dot(W2, h1_bias)\nu2\n</pre> h1_bias = np.vstack([h1, [[1]]])  W2 = np.array([0.5, -0.3, 0.2])  u2 = np.dot(W2, h1_bias) u2 Out[3]: <pre>array([0.39903948])</pre> <p>Aplicando a fun\u00e7\u00e3o de ativa\u00e7\u00e3o na segunda sa\u00edda, encontra-se o resultado previsto pelo modelo para o y, no caso, $\\hat{y}$.</p> <p>$$ \\hat{y}=\\tanh\\ (u^{(2)}) = \\tanh\\ (0.39903948) = 0.37912681 $$</p> In\u00a0[4]: Copied! <pre>y_hat = np.tanh(u2)\ny_hat\n</pre> y_hat = np.tanh(u2) y_hat Out[4]: <pre>array([0.37912681])</pre> <p>Com isso, \u00e9 poss\u00edvel contabilizar o erro, que para o exemplo ser\u00e1 utilizado o MSE. Como no caso aplicado, N \u00e9 igual a 1, temos que o erro no caso \u00e9 dado por:</p> <p>$$L = (y - \\hat{y})^2$$</p> <p>$$L = (1 - 0.37912681)^2 = 0.38548352$$</p> In\u00a0[5]: Copied! <pre>y = 1\nmse = (y - y_hat) ** 2\nmse\n</pre> y = 1 mse = (y - y_hat) ** 2 mse Out[5]: <pre>array([0.38548352])</pre> <p>Com a computa\u00e7\u00e3o do erro, inicia-se o processo de atualiza\u00e7\u00e3o dos pesos, e ele funciona muito parecido com o formato do perceptron, no entanto \u00e9 necess\u00e1rio derivar o erro sobre todos os pesos e bias.</p> <p>Come\u00e7ando com $\\displaystyle \\frac{\\partial L}{\\partial \\hat{y}}$, e ent\u00e3o:</p> <p>$\\displaystyle \\frac{\\partial L}{\\partial u^{(2)}}$, tendo em vista que, a derivada de $tanh$ \u00e9 $\\displaystyle \\frac{d}{du} \\tanh(u) = 1 \\tanh^2(u)$</p> <p>Os gradientes para a camada de sa\u00edda sendo:</p> <p>$\\displaystyle \\frac{\\partial L}{\\partial \\mathbf{W}^{(2)}},\\displaystyle \\frac{\\partial L}{\\partial b^{(2)}}$</p> <p>Propagando para a primeira camada calculada, o que \u00e9 chamado de camada oculta.</p> <p>$\\displaystyle \\frac{\\partial L}{\\partial \\mathbf{h}^{(1)}}$, $\\displaystyle \\frac{\\partial L}{\\partial \\mathbf{z}^{(1)}}$</p> <p>E ent\u00e3o os gradientes da camada oculta:</p> <p>$\\displaystyle \\frac{\\partial L}{\\partial \\mathbf{W}^{(1)}}$ , $\\displaystyle \\frac{\\partial L}{\\partial \\mathbf{b}^{(1)}}$</p> <p>$ \\displaystyle \\frac{\\partial L}{\\partial \\hat{y}} = 2 \\cdot (\\hat{y}-y) = 2 \\cdot (0.37912681-1) = -1.24174639 $</p> In\u00a0[6]: Copied! <pre>dL_dy_hat = 2 * (y_hat - y)\ndL_dy_hat\n</pre> dL_dy_hat = 2 * (y_hat - y) dL_dy_hat Out[6]: <pre>array([-1.24174639])</pre> <p>$ \\displaystyle \\frac{\\partial L}{\\partial u^{(2)}} = \\underbrace{2\\cdot(\\hat{y}-y)}_{\\frac{\\partial L}{\\partial \\hat y}}\\;\\cdot\\underbrace{(1-\\hat{y}^2)}_{\\tanh'(u^{(2)})} = 2 \\cdot (0.37912681 - 1) \\cdot (1 - 0.37912681^2) =  -1.06326132 $</p> In\u00a0[7]: Copied! <pre>dL_du2 = 2 * (y_hat - y) * (1 - y_hat ** 2)\ndL_du2\n</pre> dL_du2 = 2 * (y_hat - y) * (1 - y_hat ** 2) dL_du2 Out[7]: <pre>array([-1.06326132])</pre> <p>Tendo,</p> <p>$\\displaystyle \\frac{\\partial L}{\\partial u^{(2)}} = \\ \\delta^{(2)}$</p> <p>Temos que:</p> <p>$ \\displaystyle \\frac{\\partial L}{\\partial W^{(2)}} = \\delta^{(2)}\\,\\big(h^{(1)}\\big)^\\top = -1.06326132 \\cdot \\begin{bmatrix} 0.2069665 &amp; -0.31852078 \\end{bmatrix} = \\begin{bmatrix} -0.22005947 &amp; 0.33867082 \\end{bmatrix} $</p> In\u00a0[8]: Copied! <pre>dL_dW2 = dL_du2 * h1.reshape(1,2)\ndL_dW2\n</pre> dL_dW2 = dL_du2 * h1.reshape(1,2) dL_dW2 Out[8]: <pre>array([[-0.22005947,  0.33867082]])</pre> <p>$\\displaystyle \\frac{\\partial L}{\\partial b^{(2)}} = \\delta^{(2)} = -1.06326132$</p> In\u00a0[9]: Copied! <pre>dL_db2 = dL_du2\ndL_db2\n</pre> dL_db2 = dL_du2 dL_db2 Out[9]: <pre>array([-1.06326132])</pre> <p>$ \\displaystyle \\frac{\\partial L}{\\partial h^{(1)}} \\;=\\; \\left(\\frac{\\partial u^{(2)}}{\\partial h^{(1)}}\\right)^\\top \\frac{\\partial L}{\\partial u^{(2)}} \\;=\\; \\big(W^{(2)}\\big)^\\top\\,\\delta^{(2)} =  \\begin{bmatrix} 0.5\\\\[2pt] -0.3 \\end{bmatrix} \\cdot -1.06326132 =  \\begin{bmatrix} -0.53163066\\\\[2pt] 0.3189784 \\end{bmatrix} $</p> In\u00a0[10]: Copied! <pre>W2t = np.array([[0.5],\n                [-0.3]])\n\ndL_dh1 = W2t * dL_du2\ndL_dh1\n</pre> W2t = np.array([[0.5],                 [-0.3]])  dL_dh1 = W2t * dL_du2 dL_dh1 Out[10]: <pre>array([[-0.53163066],\n       [ 0.3189784 ]])</pre> <p>$ \\displaystyle \\frac{\\partial L}{\\partial z^{(1)}} =\\ \\delta^{(1)} \\;=\\; \\frac{\\partial L}{\\partial h^{(1)}} \\;\\cdot\\;\\Big(1-\\big(h^{(1)}\\big)^{\\cdot 2}\\Big) \\;=\\; \\underbrace{\\big(W^{(2)}\\big)^\\top\\,\\cdot \\delta^{(2)}}_{\\frac{\\partial L}{\\partial h^{(1)}}} \\;\\cdot\\;\\Big(1-\\big(h^{(1)}\\big)^{\\cdot 2}\\Big) $</p> <p>Tendo,</p> <p>$ \\displaystyle \\Big(1-\\big(h^{(1)}\\big)^{2}\\Big) = \\begin{bmatrix} 0.95716487\\\\[2pt] 0.89854451 \\end{bmatrix} $</p> <p>Temos que,</p> <p>$ \\displaystyle \\frac{\\partial L}{\\partial z^{(1)}} \\ =  \\begin{bmatrix} -0.53163066\\\\[2pt] 0.3189784 \\end{bmatrix} \\cdot \\begin{bmatrix} 0.95716487\\\\[2pt] 0.89854451 \\end{bmatrix} = \\begin{bmatrix} -0.50885819\\\\[2pt] 0.28661629 \\end{bmatrix} $</p> In\u00a0[11]: Copied! <pre>dL_dz1 = dL_dh1 * (1 - h1 ** 2)\ndL_dz1\n</pre> dL_dz1 = dL_dh1 * (1 - h1 ** 2) dL_dz1 Out[11]: <pre>array([[-0.50885819],\n       [ 0.28661629]])</pre> <p>$ \\displaystyle \\frac{\\partial L}{\\partial W^{(1)}} = \\delta^{(1)}\\,x^\\top = \\begin{bmatrix} -0.50885819\\\\[2pt] 0.28661629 \\end{bmatrix} \\cdot \\begin{bmatrix} 0.5 &amp; -0.2 \\end{bmatrix} = \\begin{bmatrix} -0.25442909 &amp; 0.10177164\\\\ 0.14330814 &amp; -0.05732326 \\end{bmatrix} $</p> In\u00a0[12]: Copied! <pre>xT = np.array([0.5, -0.2])\ndL_dW1 = dL_dz1 * xT\ndL_dW1\n</pre> xT = np.array([0.5, -0.2]) dL_dW1 = dL_dz1 * xT dL_dW1 Out[12]: <pre>array([[-0.25442909,  0.10177164],\n       [ 0.14330814, -0.05732326]])</pre> <p>$ \\displaystyle \\frac{\\partial L}{\\partial b^{(1)}} = \\delta^{(1)} =  \\begin{bmatrix} -0.50885819\\\\[2pt] 0.28661629 \\end{bmatrix} $</p> In\u00a0[13]: Copied! <pre>dL_db1 = dL_dz1\ndL_db1\n</pre> dL_db1 = dL_dz1 dL_db1 Out[13]: <pre>array([[-0.50885819],\n       [ 0.28661629]])</pre> <p>Com todos os gradientes calculados, \u00e9 poss\u00edvel fazer a atualiza\u00e7\u00e3o dos pesos de acordo com o $\\eta$, que no caso aplicado $\\eta = 0.3$.</p> <p>$ \\displaystyle \\mathbf{W}^{(2)} \\leftarrow \\mathbf{W}^{(2)} - \\eta \\frac{\\partial L}{\\partial \\mathbf{W}^{(2)}} =  \\begin{bmatrix} 0.5 &amp; -0.3 \\end{bmatrix} -  0.3 \\cdot \\begin{bmatrix} -0.22005947 &amp; 0.33867082 \\end{bmatrix} =  \\begin{bmatrix} 0.56601784 &amp; -0.40160125 \\end{bmatrix} $</p> In\u00a0[14]: Copied! <pre>W2_s_bias = np.array([0.5, -0.3])\n\neta = 0.3\n\nW2_att = W2_s_bias - (eta * dL_dW2)\nW2_att\n</pre> W2_s_bias = np.array([0.5, -0.3])  eta = 0.3  W2_att = W2_s_bias - (eta * dL_dW2) W2_att Out[14]: <pre>array([[ 0.56601784, -0.40160125]])</pre> <p>$ \\displaystyle b^{(2)} \\leftarrow b^{(2)} - \\eta \\frac{\\partial L}{\\partial b^{(2)}} =  0.2 - (0.3 \\cdot -1.06326132) =  0.5189784 $</p> In\u00a0[15]: Copied! <pre>b2 = 0.2\nb2_att = b2 - (eta * dL_db2)\nb2_att\n</pre> b2 = 0.2 b2_att = b2 - (eta * dL_db2) b2_att Out[15]: <pre>array([0.5189784])</pre> <p>$ \\displaystyle \\mathbf{W}^{(1)} \\leftarrow \\mathbf{W}^{(1)} - \\eta \\frac{\\partial L}{\\partial \\mathbf{W}^{(1)}} = \\begin{bmatrix} 0.3 &amp; -0.1 \\\\ 0.2 &amp; 0.4 \\end{bmatrix} -  0.3 \\cdot \\begin{bmatrix} -0.25442909 &amp; 0.10177164\\\\ 0.14330814 &amp; -0.05732326 \\end{bmatrix} =  \\begin{bmatrix} 0.37632873 &amp; -0.13053149\\\\ 0.15700756 &amp; 0.41719698 \\end{bmatrix} $</p> In\u00a0[16]: Copied! <pre>W1_s_bias = np.array([[0.3, -0.1],\n               [0.2, 0.4]])\nW1_att = W1_s_bias - (eta * dL_dW1)\nW1_att\n</pre> W1_s_bias = np.array([[0.3, -0.1],                [0.2, 0.4]]) W1_att = W1_s_bias - (eta * dL_dW1) W1_att Out[16]: <pre>array([[ 0.37632873, -0.13053149],\n       [ 0.15700756,  0.41719698]])</pre> <p>$ \\displaystyle b^{(1)} \\leftarrow b^{(1)} - \\eta \\frac{\\partial L}{\\partial b^{(1)}} =  \\begin{bmatrix} 0.1 &amp; -0.2 \\end{bmatrix} - (0.3 \\cdot \\begin{bmatrix} -0.50885819 &amp; 0.28661629 \\end{bmatrix}) =  \\begin{bmatrix} 0.25265746 &amp; -0.28598489 \\end{bmatrix} $</p> In\u00a0[17]: Copied! <pre>b1 = np.array([0.1, -0.2])\nb1_att = b1 - (eta * dL_db1.reshape(1,2))\nb1_att\n</pre> b1 = np.array([0.1, -0.2]) b1_att = b1 - (eta * dL_db1.reshape(1,2)) b1_att Out[17]: <pre>array([[ 0.25265746, -0.28598489]])</pre> <p>Dessa forma, com todos os pesos atualizados \u00e9 poss\u00edvel fazer o comparativo:</p> <p>Pesos inicias:</p> <p>$\\mathbf{W}^{(1)} = \\begin{bmatrix} 0.3 &amp; -0.1 \\\\ 0.2 &amp; 0.4 \\end{bmatrix}$</p> <p>$\\mathbf{b}^{(1)} = [0.1, -0.2]$</p> <p>$\\mathbf{W}^{(2)} = [0.5, -0.3]$</p> <p>$b^{(2)} = 0.2$</p> <p>Pesos atualizados:</p> <p>$\\mathbf{W}^{(1)} = \\begin{bmatrix} 0.37632873 &amp; -0.13053149 \\\\ 0.15700756 &amp; 0.41719698 \\end{bmatrix}$</p> <p>$\\mathbf{b}^{(1)} = [0.25265746, -0.28598489]$</p> <p>$\\mathbf{W}^{(2)} = [0.56601784, -0.40160125]$</p> <p>$b^{(2)} = 0.5189784$</p> In\u00a0[18]: Copied! <pre>print(\"Pesos inicias\")\nprint(f\"W1: \\n{W1_s_bias}\\n\")\nprint(f\"b1: \\n{b1}\\n\")\nprint(f\"W2: \\n{W2_s_bias}\\n\")\nprint(f\"b2: \\n{b2}\\n\")\n\nprint(\"Pesos atualizados\")\nprint(f\"W1: \\n{W1_att}\\n\")\nprint(f\"b1: \\n{b1_att}\\n\")\nprint(f\"W2: \\n{W2_att}\\n\")\nprint(f\"b2: \\n{b2_att}\")\n</pre> print(\"Pesos inicias\") print(f\"W1: \\n{W1_s_bias}\\n\") print(f\"b1: \\n{b1}\\n\") print(f\"W2: \\n{W2_s_bias}\\n\") print(f\"b2: \\n{b2}\\n\")  print(\"Pesos atualizados\") print(f\"W1: \\n{W1_att}\\n\") print(f\"b1: \\n{b1_att}\\n\") print(f\"W2: \\n{W2_att}\\n\") print(f\"b2: \\n{b2_att}\") <pre>Pesos inicias\nW1: \n[[ 0.3 -0.1]\n [ 0.2  0.4]]\n\nb1: \n[ 0.1 -0.2]\n\nW2: \n[ 0.5 -0.3]\n\nb2: \n0.2\n\nPesos atualizados\nW1: \n[[ 0.37632873 -0.13053149]\n [ 0.15700756  0.41719698]]\n\nb1: \n[[ 0.25265746 -0.28598489]]\n\nW2: \n[[ 0.56601784 -0.40160125]]\n\nb2: \n[0.5189784]\n</pre> <ul> <li>N\u00famero de amostras <code>n_samples</code>: 1000</li> <li>N\u00famero de classes: 2</li> <li>N\u00famero de clusters por classe <code>n_clusters_per_class</code>: 1 em uma e 2 em outra</li> <li>N\u00famero de features <code>n_features</code>: 2<ul> <li>N\u00famero de features efetivas <code>n_informative</code>: 2</li> <li>N\u00famero de features redundantes <code>n_redundant</code>: 2</li> </ul> </li> <li>Dispers\u00e3o das classes <code>class_sep</code>: 1.6</li> <li>Ru\u00eddo das classes <code>flip_y</code>: 0.02</li> <li>Semente de aleatoriza\u00e7\u00e3o <code>random_state</code>: 42</li> </ul> <p>Para aplica\u00e7\u00e3o e estudo sobre os desafios propostos, foi necess\u00e1rio criar uma classe para calcular todos os passos de treino, teste, atualiza\u00e7\u00e3o dos pesos. Diante disso, foi constru\u00edda a seguinte classe.</p> In\u00a0[19]: Copied! <pre>import numpy as np\nfrom dataclasses import dataclass\nfrom typing import Iterable, List, Tuple, Optional, Dict\n\n@dataclass\nclass TrainingHistory:\n    epoch: list\n    train_loss: list\n    train_accuracy: list\n    val_loss: list\n    val_accuracy: list\n    grad_norm: list\n    weight_norm: list\n\n    def as_dict(self) -&gt; Dict[str, list]:\n        return {\n            \"epoch\": self.epoch,\n            \"train_loss\": self.train_loss,\n            \"train_accuracy\": self.train_accuracy,\n            \"val_loss\": self.val_loss,\n            \"val_accuracy\": self.val_accuracy,\n            \"grad_norm\": self.grad_norm,\n            \"weight_norm\": self.weight_norm,\n        }\n\nclass MLPClassifierScratch:\n    def __init__(\n        self,\n        x: np.ndarray,\n        y: np.ndarray,\n        hidden_layer_sizes: Iterable[int] = (16,),\n        activation: str = \"tanh\",\n        output_activation: Optional[str] = None,\n        loss: Optional[str] = None,\n        eta: float = 0.01,\n        batch_size: int = 32,\n        max_epochs: int = 200,\n        validation_fraction: float = 0.0,\n        patience: int = 20,\n        min_delta: float = 1e-4,\n        seed: int = 42,\n        weight_init: str = \"auto\",\n        bias_as_weight: bool = False,\n    ):\n        self.X = self._as_2d_array(x)\n        self.y_input = y\n        self.n_samples, self.n_features = self.X.shape\n\n        self.Y, self.n_classes, self.classes_, self.target_type = self._normalize_targets(y)\n\n        self.hidden_layer_sizes = tuple(int(h) for h in hidden_layer_sizes)\n        self.activation = activation.lower()\n        assert self.activation in {\"relu\",\"tanh\",\"sigmoid\",\"identity\"}\n\n        if output_activation is None:\n            output_activation = \"sigmoid\" if self.target_type == \"binary\" else (\"softmax\" if self.target_type == \"multiclass\" else \"tanh\")\n        if loss is None:\n            loss = \"bce\" if output_activation == \"sigmoid\" else (\"cce\" if output_activation == \"softmax\" else \"mse\")\n\n        self.output_activation = output_activation.lower()\n        assert self.output_activation in {\"sigmoid\",\"softmax\",\"tanh\",\"identity\"}\n        \n        self.loss_name = loss.lower()\n        assert self.loss_name in {\"bce\",\"cce\",\"mse\"}\n\n        self.eta = float(eta)\n        self.batch_size = int(batch_size)\n        self.max_epochs = int(max_epochs)\n        self.validation_fraction = float(validation_fraction)\n        self.es_patience = int(patience)\n        self.es_min_delta = float(min_delta)\n        self.seed = int(seed)\n        \n        self.weight_init = weight_init.lower()\n        assert self.weight_init in {\"auto\",\"xavier\",\"he\"}\n        \n        self.bias_as_weight = bool(bias_as_weight)\n\n        self.rng = np.random.default_rng(self.seed)\n\n        if self.validation_fraction &gt; 0.0:\n            n_val = max(1, int(self.n_samples * self.validation_fraction))\n            idx = self.rng.permutation(self.n_samples)\n            val_idx, tr_idx = idx[:n_val], idx[n_val:]\n            self.Xtr, self.Ytr = self.X[tr_idx], self.Y[tr_idx]\n            self.Xval, self.Yval = self.X[val_idx], self.Y[val_idx]\n        else:\n            self.Xtr, self.Ytr = self.X, self.Y\n            self.Xval, self.Yval = None, None\n\n        out_dim = self.n_classes if self.output_activation == \"softmax\" else 1\n\n        if self.loss_name == \"mse\" and self.output_activation in {\"tanh\",\"identity\"} and self.n_classes &gt; 1:\n            out_dim = self.n_classes\n\n        layer_sizes = [self.n_features] + list(self.hidden_layer_sizes) + [out_dim]\n        self.params = self._init_params(layer_sizes)\n\n        self.loss_per_epoch: List[float] = []\n        self.accuracy_per_epoch: List[float] = []\n        self.val_loss_per_epoch: List[float] = []\n        self.val_accuracy_per_epoch: List[float] = []\n        self.history = TrainingHistory(epoch=[], train_loss=[], train_accuracy=[], val_loss=[], val_accuracy=[], grad_norm=[], weight_norm=[])\n        self.converged: bool = False\n        self.stop_reason: str = \"max_epochs\"\n        self.epochs_run: int = 0\n\n    @staticmethod\n    def _as_2d_array(x: np.ndarray) -&gt; np.ndarray:\n        x = np.asarray(x, dtype=np.float64)\n        if x.ndim == 1: x = x.reshape(-1, 1)\n        assert x.ndim == 2\n        return x\n\n    @staticmethod\n    def _normalize_targets(y: np.ndarray) -&gt; Tuple[np.ndarray, int, np.ndarray, str]:\n        y_arr = np.asarray(y)\n        \n        if y_arr.ndim == 2 and y_arr.shape[1] &gt; 1:\n            n_classes = y_arr.shape[1]\n            return y_arr.astype(np.float64), n_classes, np.arange(n_classes), \"multiclass\"\n        \n        y_flat = y_arr.reshape(-1)\n        vals = np.unique(y_flat)\n        \n        if set(vals).issubset({0,1}) and len(vals) &lt;= 2:\n            return y_flat.astype(np.float64).reshape(-1,1), 2, np.array([0,1]), \"binary\"\n        \n        if np.issubdtype(y_flat.dtype, np.integer) and vals.min() &gt;= 0 and (vals == np.arange(vals.max()+1)).all():\n            K = int(vals.max()+1)\n            onehot = np.zeros((y_flat.shape[0], K), dtype=np.float64)\n            onehot[np.arange(y_flat.shape[0]), y_flat.astype(int)] = 1.0\n            return onehot, K, np.arange(K), \"multiclass\"\n        \n        return y_flat.astype(np.float64).reshape(-1,1), 1, np.array([0]), \"continuous\"\n\n    def _init_params(self, layer_sizes: List[int]) -&gt; Dict[str, np.ndarray]:\n        params: Dict[str, np.ndarray] = {}\n        for layer_idx in range(1, len(layer_sizes)):\n            fan_in = layer_sizes[layer_idx-1]\n            fan_out = layer_sizes[layer_idx]\n            fan_in_eff = fan_in + 1 if self.bias_as_weight else fan_in\n\n            if self.weight_init == \"auto\":\n                scale = np.sqrt(2.0/fan_in_eff) if self.activation == \"relu\" else np.sqrt(1.0/fan_in_eff)\n            elif self.weight_init == \"xavier\":\n                scale = np.sqrt(1.0/fan_in_eff)\n            else:\n                scale = np.sqrt(2.0/fan_in_eff)\n\n            W = self.rng.normal(0.0, scale, size=(fan_out, fan_in_eff))\n            params[f\"W{layer_idx}\"] = W\n\n            if not self.bias_as_weight:\n                params[f\"b{layer_idx}\"] = np.zeros((1, fan_out))\n\n        return params\n\n    # -------------------- ativa\u00e7\u00f5es --------------------\n    @staticmethod\n    def _sigmoid(z): return 1.0 / (1.0 + np.exp(-z))\n\n    @staticmethod\n    def _softmax(z):\n        z = z - np.max(z, axis=1, keepdims=True)\n        expz = np.exp(z)\n        return expz / np.sum(expz, axis=1, keepdims=True)\n\n    def _act(self, z):\n        if self.activation == \"relu\":\n            return np.maximum(0, z)\n        \n        if self.activation == \"tanh\":\n            return np.tanh(z)\n        \n        if self.activation == \"sigmoid\":\n            return self._sigmoid(z)\n        \n        return z\n\n    def _act_deriv(self, a, z):\n        if self.activation == \"relu\":\n            return (z &gt; 0).astype(z.dtype)\n        \n        if self.activation == \"tanh\":\n            return 1.0 - a**2\n        \n        if self.activation == \"sigmoid\":\n            return a * (1.0 - a)\n        \n        return np.ones_like(z)\n\n    def _forward(self, X: np.ndarray) -&gt; Tuple[List[np.ndarray], List[np.ndarray]]:\n        activations = [X]\n        preactivations: List[np.ndarray] = []\n        total_layers = len(self.hidden_layer_sizes) + 1\n\n        for layer_idx in range(1, total_layers):\n            A_prev = activations[-1]\n            \n            if self.bias_as_weight:\n                A_prev_aug = np.concatenate([A_prev, np.ones((A_prev.shape[0], 1))], axis=1)\n                z_l = A_prev_aug @ self.params[f\"W{layer_idx}\"].T\n            else:\n                z_l = A_prev @ self.params[f\"W{layer_idx}\"].T + self.params[f\"b{layer_idx}\"]\n            \n            a_l = self._act(z_l)\n            preactivations.append(z_l)\n            activations.append(a_l)\n\n        A_prev = activations[-1]\n\n        if self.bias_as_weight:\n            A_prev_aug = np.concatenate([A_prev, np.ones((A_prev.shape[0], 1))], axis=1)\n            z_out = A_prev_aug @ self.params[f\"W{total_layers}\"].T\n        else:\n            z_out = A_prev @ self.params[f\"W{total_layers}\"].T + self.params[f\"b{total_layers}\"]\n\n        if self.output_activation == \"sigmoid\":\n            a_out = self._sigmoid(z_out)\n\n        elif self.output_activation == \"softmax\":\n            a_out = self._softmax(z_out)\n\n        elif self.output_activation == \"tanh\":\n            a_out = np.tanh(z_out)\n\n        else:\n            a_out = z_out\n\n        preactivations.append(z_out)\n        activations.append(a_out)\n        \n        return preactivations, activations\n\n    def _loss_and_acc(self, Y_true: np.ndarray, Y_hat: np.ndarray) -&gt; Tuple[float, float]:\n        m = Y_true.shape[0]\n        eps = 1e-12\n\n        if self.loss_name == \"bce\":\n            p = np.clip(Y_hat.reshape(-1,1), eps, 1-eps)\n            loss = -(Y_true*np.log(p) + (1-Y_true)*np.log(1-p)).mean()\n\n        elif self.loss_name == \"cce\":\n            p = np.clip(Y_hat, eps, 1-eps)\n            loss = -np.sum(Y_true*np.log(p)) / m\n\n        else:\n            loss = np.mean((Y_true - Y_hat)**2)\n\n        if self.output_activation == \"softmax\":\n            y_pred = np.argmax(Y_hat, axis=1)\n            y_true = np.argmax(Y_true, axis=1)\n            acc = (y_pred == y_true).mean()\n\n        elif self.output_activation == \"sigmoid\":\n            y_pred = (Y_hat.reshape(-1) &gt;= 0.5).astype(int)\n            y_true = Y_true.reshape(-1).astype(int)\n            acc = (y_pred == y_true).mean()\n\n        else:\n            acc = np.nan\n\n        return float(loss), float(acc)\n\n    def _backward(self, preactivations: List[np.ndarray], activations: List[np.ndarray], Y_true: np.ndarray) -&gt; Dict[str, np.ndarray]:\n        grads: Dict[str, np.ndarray] = {}\n        m = Y_true.shape[0]\n        L = len(self.hidden_layer_sizes) + 1\n\n        A_out = activations[-1]\n        Z_out = preactivations[-1]\n        A_prev = activations[-2]\n\n        if self.loss_name == \"bce\" and self.output_activation == \"sigmoid\":\n            dZ = A_out - Y_true\n\n        elif self.loss_name == \"cce\" and self.output_activation == \"softmax\":\n            dZ = A_out - Y_true\n\n        elif self.loss_name == \"mse\":\n            if self.output_activation == \"tanh\":\n                gprime = 1.0 - np.tanh(Z_out)**2\n\n            elif self.output_activation == \"sigmoid\":\n                s = self._sigmoid(Z_out)\n                gprime = s*(1.0 - s)\n\n            else:\n                gprime = np.ones_like(Z_out)\n\n            dZ = 2.0*(A_out - Y_true)*gprime\n\n        else:\n            raise ValueError(\"Combina\u00e7\u00e3o de loss/sa\u00edda n\u00e3o suportada.\")\n\n        if self.bias_as_weight:\n            A_prev_aug = np.concatenate([A_prev, np.ones((m,1))], axis=1)\n            grad_W = (dZ.T @ A_prev_aug) / m\n            grads[f\"W{L}\"] = grad_W\n            dA_prev = dZ @ self.params[f\"W{L}\"][:, :-1]\n        \n        else:\n            grad_W = (dZ.T @ A_prev) / m\n            grad_b = dZ.mean(axis=0, keepdims=True)\n            grads[f\"W{L}\"] = grad_W\n            grads[f\"b{L}\"] = grad_b\n            dA_prev = dZ @ self.params[f\"W{L}\"]\n\n        for layer_idx in range(L-1, 0, -1):\n            Z_l = preactivations[layer_idx-1]\n            A_l = activations[layer_idx]\n            A_prev = activations[layer_idx-1]\n            dG = self._act_deriv(A_l, Z_l)\n            dZ = dA_prev * dG\n\n            if self.bias_as_weight:\n                A_prev_aug = np.concatenate([A_prev, np.ones((m,1))], axis=1)\n                grad_W = (dZ.T @ A_prev_aug) / m\n                grads[f\"W{layer_idx}\"] = grad_W\n                if layer_idx &gt; 1:\n                    dA_prev = dZ @ self.params[f\"W{layer_idx}\"][:, :-1]\n            \n            else:\n                grad_W = (dZ.T @ A_prev) / m\n                grad_b = dZ.mean(axis=0, keepdims=True)\n                grads[f\"W{layer_idx}\"] = grad_W\n                grads[f\"b{layer_idx}\"] = grad_b\n                if layer_idx &gt; 1:\n                    dA_prev = dZ @ self.params[f\"W{layer_idx}\"]\n\n        return grads\n\n    def _update(self, grads: Dict[str, np.ndarray]):\n        total_layers = len(self.hidden_layer_sizes) + 1\n        for layer_idx in range(1, total_layers+1):\n            self.params[f\"W{layer_idx}\"] -= self.eta * grads[f\"W{layer_idx}\"]\n            if not self.bias_as_weight:\n                self.params[f\"b{layer_idx}\"] -= self.eta * grads[f\"b{layer_idx}\"]\n\n    def train(self, patience: Optional[int] = None, min_delta: Optional[float] = None, verbose: bool = False):\n        if patience is None: patience = self.es_patience\n        if min_delta is None: min_delta = self.es_min_delta\n\n        best = np.inf\n        best_params = {k: v.copy() for k, v in self.params.items()}\n        patience_count = 0\n\n        self.loss_per_epoch.clear()\n        self.accuracy_per_epoch.clear()\n        self.val_loss_per_epoch.clear()\n        self.val_accuracy_per_epoch.clear()\n        \n        self.history = TrainingHistory(epoch=[], train_loss=[], train_accuracy=[], val_loss=[], val_accuracy=[], grad_norm=[], weight_norm=[])\n        \n        self.stop_reason = \"max_epochs\"; self.converged = False\n\n        Xtr, Ytr = self.Xtr, self.Ytr\n        for epoch in range(self.max_epochs):\n            idx = self.rng.permutation(len(Xtr))\n            Xs, Ys = Xtr[idx], Ytr[idx]\n\n            grad_norm_total = 0.0\n            for start in range(0, len(Xs), self.batch_size):\n                xb = Xs[start:start+self.batch_size]\n                yb = Ys[start:start+self.batch_size]\n                preacts, acts = self._forward(xb)\n                grads = self._backward(preacts, acts, yb)\n\n                for g in grads.values():\n                    grad_norm_total += float(np.linalg.norm(g))\n                self._update(grads)\n\n            _, act_tr = self._forward(Xtr)\n            loss_tr, acc_tr = self._loss_and_acc(Ytr, act_tr[-1])\n            self.loss_per_epoch.append(loss_tr)\n            self.accuracy_per_epoch.append(acc_tr if not np.isnan(acc_tr) else None)\n\n            if self.Xval is not None:\n                _, act_val = self._forward(self.Xval)\n                loss_val, acc_val = self._loss_and_acc(self.Yval, act_val[-1])\n                self.val_loss_per_epoch.append(loss_val)\n                self.val_accuracy_per_epoch.append(acc_val if not np.isnan(acc_val) else None)\n                monitor = loss_val\n            else:\n                loss_val = None\n                acc_val = None\n                monitor = loss_tr\n\n            weight_norm_total = 0.0\n            total_layers = len(self.hidden_layer_sizes) + 1\n\n            for l in range(1, total_layers+1):\n                W = self.params[f\"W{l}\"]\n                W_use = W[:, :-1] if self.bias_as_weight else W\n                weight_norm_total += float(np.linalg.norm(W_use))\n\n            self.history.epoch.append(epoch+1)\n            self.history.train_loss.append(loss_tr)\n            self.history.train_accuracy.append(acc_tr if not np.isnan(acc_tr) else None)\n            self.history.val_loss.append(loss_val)\n            self.history.val_accuracy.append(acc_val if not np.isnan(acc_val) else None)\n            self.history.grad_norm.append(grad_norm_total)\n            self.history.weight_norm.append(weight_norm_total)\n\n            if monitor + self.es_min_delta &lt; best:\n                best = float(monitor)\n                best_params = {k: v.copy() for k, v in self.params.items()}\n                patience_count = 0\n            else:\n                patience_count += 1\n\n            if verbose:\n                msg = f\"Epoch {epoch+1:4d} | loss={loss_tr:.4f}\"\n                if acc_tr is not None: msg += f\" acc={acc_tr:.3f}\"\n                if loss_val is not None:\n                    msg += f\" | val_loss={loss_val:.4f}\"\n                    if acc_val is not None: msg += f\" val_acc={acc_val:.3f}\"\n                print(msg)\n\n            if patience_count &gt;= self.es_patience:\n                self.stop_reason = f\"No improvement for {self.es_patience} epochs\"\n                break\n\n            self.epochs_run = epoch + 1\n\n        self.params = best_params\n        if patience_count &lt; self.es_patience and self.epochs_run &lt; self.max_epochs:\n            self.converged = True\n            self.stop_reason = \"Early stopping\"\n        elif self.epochs_run == self.max_epochs:\n            self.stop_reason = \"max_epochs\"\n\n    def get_history(self) -&gt; TrainingHistory:\n        return self.history\n\n    def history_as_dict(self) -&gt; Dict[str, list]:\n        return self.history.as_dict()\n\n    def predict_proba(self, X_test: np.ndarray) -&gt; np.ndarray:\n        X = self._as_2d_array(X_test)\n        _, activations = self._forward(X)\n        out = activations[-1]\n        if self.output_activation == \"sigmoid\":\n            return out.reshape(-1)\n        return out\n\n    def predict(self, X_test: np.ndarray, threshold: float = 0.5) -&gt; np.ndarray:\n        proba = self.predict_proba(X_test)\n        if self.output_activation == \"softmax\":\n            return np.argmax(proba, axis=1)\n        if self.output_activation == \"sigmoid\":\n            return (proba &gt;= threshold).astype(int)\n        return proba.reshape(-1)\n\n    def score(self, X_test: np.ndarray, y_test: np.ndarray) -&gt; float:\n        y_true = np.asarray(y_test).reshape(-1)\n        y_pred = self.predict(X_test)\n        \n        if y_pred.ndim == 1 and y_true.ndim == 1:\n            return float((y_pred == y_true).mean())\n        \n        return float('nan')\n</pre> import numpy as np from dataclasses import dataclass from typing import Iterable, List, Tuple, Optional, Dict  @dataclass class TrainingHistory:     epoch: list     train_loss: list     train_accuracy: list     val_loss: list     val_accuracy: list     grad_norm: list     weight_norm: list      def as_dict(self) -&gt; Dict[str, list]:         return {             \"epoch\": self.epoch,             \"train_loss\": self.train_loss,             \"train_accuracy\": self.train_accuracy,             \"val_loss\": self.val_loss,             \"val_accuracy\": self.val_accuracy,             \"grad_norm\": self.grad_norm,             \"weight_norm\": self.weight_norm,         }  class MLPClassifierScratch:     def __init__(         self,         x: np.ndarray,         y: np.ndarray,         hidden_layer_sizes: Iterable[int] = (16,),         activation: str = \"tanh\",         output_activation: Optional[str] = None,         loss: Optional[str] = None,         eta: float = 0.01,         batch_size: int = 32,         max_epochs: int = 200,         validation_fraction: float = 0.0,         patience: int = 20,         min_delta: float = 1e-4,         seed: int = 42,         weight_init: str = \"auto\",         bias_as_weight: bool = False,     ):         self.X = self._as_2d_array(x)         self.y_input = y         self.n_samples, self.n_features = self.X.shape          self.Y, self.n_classes, self.classes_, self.target_type = self._normalize_targets(y)          self.hidden_layer_sizes = tuple(int(h) for h in hidden_layer_sizes)         self.activation = activation.lower()         assert self.activation in {\"relu\",\"tanh\",\"sigmoid\",\"identity\"}          if output_activation is None:             output_activation = \"sigmoid\" if self.target_type == \"binary\" else (\"softmax\" if self.target_type == \"multiclass\" else \"tanh\")         if loss is None:             loss = \"bce\" if output_activation == \"sigmoid\" else (\"cce\" if output_activation == \"softmax\" else \"mse\")          self.output_activation = output_activation.lower()         assert self.output_activation in {\"sigmoid\",\"softmax\",\"tanh\",\"identity\"}                  self.loss_name = loss.lower()         assert self.loss_name in {\"bce\",\"cce\",\"mse\"}          self.eta = float(eta)         self.batch_size = int(batch_size)         self.max_epochs = int(max_epochs)         self.validation_fraction = float(validation_fraction)         self.es_patience = int(patience)         self.es_min_delta = float(min_delta)         self.seed = int(seed)                  self.weight_init = weight_init.lower()         assert self.weight_init in {\"auto\",\"xavier\",\"he\"}                  self.bias_as_weight = bool(bias_as_weight)          self.rng = np.random.default_rng(self.seed)          if self.validation_fraction &gt; 0.0:             n_val = max(1, int(self.n_samples * self.validation_fraction))             idx = self.rng.permutation(self.n_samples)             val_idx, tr_idx = idx[:n_val], idx[n_val:]             self.Xtr, self.Ytr = self.X[tr_idx], self.Y[tr_idx]             self.Xval, self.Yval = self.X[val_idx], self.Y[val_idx]         else:             self.Xtr, self.Ytr = self.X, self.Y             self.Xval, self.Yval = None, None          out_dim = self.n_classes if self.output_activation == \"softmax\" else 1          if self.loss_name == \"mse\" and self.output_activation in {\"tanh\",\"identity\"} and self.n_classes &gt; 1:             out_dim = self.n_classes          layer_sizes = [self.n_features] + list(self.hidden_layer_sizes) + [out_dim]         self.params = self._init_params(layer_sizes)          self.loss_per_epoch: List[float] = []         self.accuracy_per_epoch: List[float] = []         self.val_loss_per_epoch: List[float] = []         self.val_accuracy_per_epoch: List[float] = []         self.history = TrainingHistory(epoch=[], train_loss=[], train_accuracy=[], val_loss=[], val_accuracy=[], grad_norm=[], weight_norm=[])         self.converged: bool = False         self.stop_reason: str = \"max_epochs\"         self.epochs_run: int = 0      @staticmethod     def _as_2d_array(x: np.ndarray) -&gt; np.ndarray:         x = np.asarray(x, dtype=np.float64)         if x.ndim == 1: x = x.reshape(-1, 1)         assert x.ndim == 2         return x      @staticmethod     def _normalize_targets(y: np.ndarray) -&gt; Tuple[np.ndarray, int, np.ndarray, str]:         y_arr = np.asarray(y)                  if y_arr.ndim == 2 and y_arr.shape[1] &gt; 1:             n_classes = y_arr.shape[1]             return y_arr.astype(np.float64), n_classes, np.arange(n_classes), \"multiclass\"                  y_flat = y_arr.reshape(-1)         vals = np.unique(y_flat)                  if set(vals).issubset({0,1}) and len(vals) &lt;= 2:             return y_flat.astype(np.float64).reshape(-1,1), 2, np.array([0,1]), \"binary\"                  if np.issubdtype(y_flat.dtype, np.integer) and vals.min() &gt;= 0 and (vals == np.arange(vals.max()+1)).all():             K = int(vals.max()+1)             onehot = np.zeros((y_flat.shape[0], K), dtype=np.float64)             onehot[np.arange(y_flat.shape[0]), y_flat.astype(int)] = 1.0             return onehot, K, np.arange(K), \"multiclass\"                  return y_flat.astype(np.float64).reshape(-1,1), 1, np.array([0]), \"continuous\"      def _init_params(self, layer_sizes: List[int]) -&gt; Dict[str, np.ndarray]:         params: Dict[str, np.ndarray] = {}         for layer_idx in range(1, len(layer_sizes)):             fan_in = layer_sizes[layer_idx-1]             fan_out = layer_sizes[layer_idx]             fan_in_eff = fan_in + 1 if self.bias_as_weight else fan_in              if self.weight_init == \"auto\":                 scale = np.sqrt(2.0/fan_in_eff) if self.activation == \"relu\" else np.sqrt(1.0/fan_in_eff)             elif self.weight_init == \"xavier\":                 scale = np.sqrt(1.0/fan_in_eff)             else:                 scale = np.sqrt(2.0/fan_in_eff)              W = self.rng.normal(0.0, scale, size=(fan_out, fan_in_eff))             params[f\"W{layer_idx}\"] = W              if not self.bias_as_weight:                 params[f\"b{layer_idx}\"] = np.zeros((1, fan_out))          return params      # -------------------- ativa\u00e7\u00f5es --------------------     @staticmethod     def _sigmoid(z): return 1.0 / (1.0 + np.exp(-z))      @staticmethod     def _softmax(z):         z = z - np.max(z, axis=1, keepdims=True)         expz = np.exp(z)         return expz / np.sum(expz, axis=1, keepdims=True)      def _act(self, z):         if self.activation == \"relu\":             return np.maximum(0, z)                  if self.activation == \"tanh\":             return np.tanh(z)                  if self.activation == \"sigmoid\":             return self._sigmoid(z)                  return z      def _act_deriv(self, a, z):         if self.activation == \"relu\":             return (z &gt; 0).astype(z.dtype)                  if self.activation == \"tanh\":             return 1.0 - a**2                  if self.activation == \"sigmoid\":             return a * (1.0 - a)                  return np.ones_like(z)      def _forward(self, X: np.ndarray) -&gt; Tuple[List[np.ndarray], List[np.ndarray]]:         activations = [X]         preactivations: List[np.ndarray] = []         total_layers = len(self.hidden_layer_sizes) + 1          for layer_idx in range(1, total_layers):             A_prev = activations[-1]                          if self.bias_as_weight:                 A_prev_aug = np.concatenate([A_prev, np.ones((A_prev.shape[0], 1))], axis=1)                 z_l = A_prev_aug @ self.params[f\"W{layer_idx}\"].T             else:                 z_l = A_prev @ self.params[f\"W{layer_idx}\"].T + self.params[f\"b{layer_idx}\"]                          a_l = self._act(z_l)             preactivations.append(z_l)             activations.append(a_l)          A_prev = activations[-1]          if self.bias_as_weight:             A_prev_aug = np.concatenate([A_prev, np.ones((A_prev.shape[0], 1))], axis=1)             z_out = A_prev_aug @ self.params[f\"W{total_layers}\"].T         else:             z_out = A_prev @ self.params[f\"W{total_layers}\"].T + self.params[f\"b{total_layers}\"]          if self.output_activation == \"sigmoid\":             a_out = self._sigmoid(z_out)          elif self.output_activation == \"softmax\":             a_out = self._softmax(z_out)          elif self.output_activation == \"tanh\":             a_out = np.tanh(z_out)          else:             a_out = z_out          preactivations.append(z_out)         activations.append(a_out)                  return preactivations, activations      def _loss_and_acc(self, Y_true: np.ndarray, Y_hat: np.ndarray) -&gt; Tuple[float, float]:         m = Y_true.shape[0]         eps = 1e-12          if self.loss_name == \"bce\":             p = np.clip(Y_hat.reshape(-1,1), eps, 1-eps)             loss = -(Y_true*np.log(p) + (1-Y_true)*np.log(1-p)).mean()          elif self.loss_name == \"cce\":             p = np.clip(Y_hat, eps, 1-eps)             loss = -np.sum(Y_true*np.log(p)) / m          else:             loss = np.mean((Y_true - Y_hat)**2)          if self.output_activation == \"softmax\":             y_pred = np.argmax(Y_hat, axis=1)             y_true = np.argmax(Y_true, axis=1)             acc = (y_pred == y_true).mean()          elif self.output_activation == \"sigmoid\":             y_pred = (Y_hat.reshape(-1) &gt;= 0.5).astype(int)             y_true = Y_true.reshape(-1).astype(int)             acc = (y_pred == y_true).mean()          else:             acc = np.nan          return float(loss), float(acc)      def _backward(self, preactivations: List[np.ndarray], activations: List[np.ndarray], Y_true: np.ndarray) -&gt; Dict[str, np.ndarray]:         grads: Dict[str, np.ndarray] = {}         m = Y_true.shape[0]         L = len(self.hidden_layer_sizes) + 1          A_out = activations[-1]         Z_out = preactivations[-1]         A_prev = activations[-2]          if self.loss_name == \"bce\" and self.output_activation == \"sigmoid\":             dZ = A_out - Y_true          elif self.loss_name == \"cce\" and self.output_activation == \"softmax\":             dZ = A_out - Y_true          elif self.loss_name == \"mse\":             if self.output_activation == \"tanh\":                 gprime = 1.0 - np.tanh(Z_out)**2              elif self.output_activation == \"sigmoid\":                 s = self._sigmoid(Z_out)                 gprime = s*(1.0 - s)              else:                 gprime = np.ones_like(Z_out)              dZ = 2.0*(A_out - Y_true)*gprime          else:             raise ValueError(\"Combina\u00e7\u00e3o de loss/sa\u00edda n\u00e3o suportada.\")          if self.bias_as_weight:             A_prev_aug = np.concatenate([A_prev, np.ones((m,1))], axis=1)             grad_W = (dZ.T @ A_prev_aug) / m             grads[f\"W{L}\"] = grad_W             dA_prev = dZ @ self.params[f\"W{L}\"][:, :-1]                  else:             grad_W = (dZ.T @ A_prev) / m             grad_b = dZ.mean(axis=0, keepdims=True)             grads[f\"W{L}\"] = grad_W             grads[f\"b{L}\"] = grad_b             dA_prev = dZ @ self.params[f\"W{L}\"]          for layer_idx in range(L-1, 0, -1):             Z_l = preactivations[layer_idx-1]             A_l = activations[layer_idx]             A_prev = activations[layer_idx-1]             dG = self._act_deriv(A_l, Z_l)             dZ = dA_prev * dG              if self.bias_as_weight:                 A_prev_aug = np.concatenate([A_prev, np.ones((m,1))], axis=1)                 grad_W = (dZ.T @ A_prev_aug) / m                 grads[f\"W{layer_idx}\"] = grad_W                 if layer_idx &gt; 1:                     dA_prev = dZ @ self.params[f\"W{layer_idx}\"][:, :-1]                          else:                 grad_W = (dZ.T @ A_prev) / m                 grad_b = dZ.mean(axis=0, keepdims=True)                 grads[f\"W{layer_idx}\"] = grad_W                 grads[f\"b{layer_idx}\"] = grad_b                 if layer_idx &gt; 1:                     dA_prev = dZ @ self.params[f\"W{layer_idx}\"]          return grads      def _update(self, grads: Dict[str, np.ndarray]):         total_layers = len(self.hidden_layer_sizes) + 1         for layer_idx in range(1, total_layers+1):             self.params[f\"W{layer_idx}\"] -= self.eta * grads[f\"W{layer_idx}\"]             if not self.bias_as_weight:                 self.params[f\"b{layer_idx}\"] -= self.eta * grads[f\"b{layer_idx}\"]      def train(self, patience: Optional[int] = None, min_delta: Optional[float] = None, verbose: bool = False):         if patience is None: patience = self.es_patience         if min_delta is None: min_delta = self.es_min_delta          best = np.inf         best_params = {k: v.copy() for k, v in self.params.items()}         patience_count = 0          self.loss_per_epoch.clear()         self.accuracy_per_epoch.clear()         self.val_loss_per_epoch.clear()         self.val_accuracy_per_epoch.clear()                  self.history = TrainingHistory(epoch=[], train_loss=[], train_accuracy=[], val_loss=[], val_accuracy=[], grad_norm=[], weight_norm=[])                  self.stop_reason = \"max_epochs\"; self.converged = False          Xtr, Ytr = self.Xtr, self.Ytr         for epoch in range(self.max_epochs):             idx = self.rng.permutation(len(Xtr))             Xs, Ys = Xtr[idx], Ytr[idx]              grad_norm_total = 0.0             for start in range(0, len(Xs), self.batch_size):                 xb = Xs[start:start+self.batch_size]                 yb = Ys[start:start+self.batch_size]                 preacts, acts = self._forward(xb)                 grads = self._backward(preacts, acts, yb)                  for g in grads.values():                     grad_norm_total += float(np.linalg.norm(g))                 self._update(grads)              _, act_tr = self._forward(Xtr)             loss_tr, acc_tr = self._loss_and_acc(Ytr, act_tr[-1])             self.loss_per_epoch.append(loss_tr)             self.accuracy_per_epoch.append(acc_tr if not np.isnan(acc_tr) else None)              if self.Xval is not None:                 _, act_val = self._forward(self.Xval)                 loss_val, acc_val = self._loss_and_acc(self.Yval, act_val[-1])                 self.val_loss_per_epoch.append(loss_val)                 self.val_accuracy_per_epoch.append(acc_val if not np.isnan(acc_val) else None)                 monitor = loss_val             else:                 loss_val = None                 acc_val = None                 monitor = loss_tr              weight_norm_total = 0.0             total_layers = len(self.hidden_layer_sizes) + 1              for l in range(1, total_layers+1):                 W = self.params[f\"W{l}\"]                 W_use = W[:, :-1] if self.bias_as_weight else W                 weight_norm_total += float(np.linalg.norm(W_use))              self.history.epoch.append(epoch+1)             self.history.train_loss.append(loss_tr)             self.history.train_accuracy.append(acc_tr if not np.isnan(acc_tr) else None)             self.history.val_loss.append(loss_val)             self.history.val_accuracy.append(acc_val if not np.isnan(acc_val) else None)             self.history.grad_norm.append(grad_norm_total)             self.history.weight_norm.append(weight_norm_total)              if monitor + self.es_min_delta &lt; best:                 best = float(monitor)                 best_params = {k: v.copy() for k, v in self.params.items()}                 patience_count = 0             else:                 patience_count += 1              if verbose:                 msg = f\"Epoch {epoch+1:4d} | loss={loss_tr:.4f}\"                 if acc_tr is not None: msg += f\" acc={acc_tr:.3f}\"                 if loss_val is not None:                     msg += f\" | val_loss={loss_val:.4f}\"                     if acc_val is not None: msg += f\" val_acc={acc_val:.3f}\"                 print(msg)              if patience_count &gt;= self.es_patience:                 self.stop_reason = f\"No improvement for {self.es_patience} epochs\"                 break              self.epochs_run = epoch + 1          self.params = best_params         if patience_count &lt; self.es_patience and self.epochs_run &lt; self.max_epochs:             self.converged = True             self.stop_reason = \"Early stopping\"         elif self.epochs_run == self.max_epochs:             self.stop_reason = \"max_epochs\"      def get_history(self) -&gt; TrainingHistory:         return self.history      def history_as_dict(self) -&gt; Dict[str, list]:         return self.history.as_dict()      def predict_proba(self, X_test: np.ndarray) -&gt; np.ndarray:         X = self._as_2d_array(X_test)         _, activations = self._forward(X)         out = activations[-1]         if self.output_activation == \"sigmoid\":             return out.reshape(-1)         return out      def predict(self, X_test: np.ndarray, threshold: float = 0.5) -&gt; np.ndarray:         proba = self.predict_proba(X_test)         if self.output_activation == \"softmax\":             return np.argmax(proba, axis=1)         if self.output_activation == \"sigmoid\":             return (proba &gt;= threshold).astype(int)         return proba.reshape(-1)      def score(self, X_test: np.ndarray, y_test: np.ndarray) -&gt; float:         y_true = np.asarray(y_test).reshape(-1)         y_pred = self.predict(X_test)                  if y_pred.ndim == 1 and y_true.ndim == 1:             return float((y_pred == y_true).mean())                  return float('nan') <p>A principal diferen\u00e7a dessa classe, para a classe utilizada na sec\u00e7\u00e3o do algoritmo de Perceptron, \u00e9 a capacidade da classe lidar com as v\u00e1rias camadas do modelo. Isso \u00e9, a ideia de os dados entrarem, serem processados por neur\u00f4nios de uma camada, ter um output que \u00e9 utilizado em outra camada, e outra, at\u00e9 a \u00faltima que realmente tem um output para prever a vari\u00e1vel dependente naquela observa\u00e7\u00e3o.</p> <p>Para isso, a classe conta com a entrad: dos dados; da quantidade de camadas que o modelo ter\u00e1; qual fun\u00e7\u00e3o de ativa\u00e7\u00e3o vai ser utilizada; qual fun\u00e7\u00e3o de perda; a taxa de aprendizagem; o tamanho do batch de treinamento; a quantidade de \u00e9pocas para treinar; a parcela de valida\u00e7\u00e3o que ser\u00e1 utilizada; qual o patience aceito para o crit\u00e9rio de parada; a semente de aleatoriza\u00e7\u00e3o a ser utilizada; como os pessos devem ser gerados (aleat\u00f3rios) e como o bias deve ser interpretado, como um peso ou um argumento extra.</p> <p>Com rela\u00e7\u00e3o ao funcionamento matem\u00e1tico da classe, ela basicamente aplica todas as contas que foram feitas na parte A matem\u00e1tica da atualiza\u00e7\u00e3o dos pesos. Al\u00e9m dos c\u00e1lculos de predi\u00e7\u00e3o e atualiza\u00e7\u00e3o dos pesos, a classe conta com o armazenamento dos dados de treinamento e teste, para posterior an\u00e1lise, a partir da classe <code>TrainingHistory</code>.</p> <p>Partindo para implementa\u00e7\u00e3o da classe nesse primeiro conjunto de dados, esse pode ser feito da seguinte forma.</p> In\u00a0[20]: Copied! <pre>import numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nRANDOM_STATE = 42\n\nXA, yA = make_classification(\n    n_samples=1000,\n    n_features=2,\n    n_informative=2,\n    n_redundant=0,\n    n_classes=2,\n    n_clusters_per_class=1,\n    weights=[0.5, 0.5],\n    class_sep=1.6,\n    flip_y=0.05,\n    random_state=RANDOM_STATE\n)\n\nXA0  = XA[yA == 0]\n\nXB, yB = make_classification(\n    n_samples=1000,\n    n_features=2,\n    n_informative=2,\n    n_redundant=0,\n    n_classes=2,\n    n_clusters_per_class=2,\n    weights=[0.5, 0.5],\n    class_sep=1.6,\n    flip_y=0.05,\n    random_state=RANDOM_STATE\n)\n\nXB1b = XB[yB == 1]\n\nX = np.vstack([XA0, XB1b])\ny = np.concatenate([\n    np.zeros(len(XA0), dtype=int),\n    np.ones (len(XB1b), dtype=int)\n])\n</pre> import numpy as np from sklearn.datasets import make_classification from sklearn.model_selection import train_test_split import matplotlib.pyplot as plt  RANDOM_STATE = 42  XA, yA = make_classification(     n_samples=1000,     n_features=2,     n_informative=2,     n_redundant=0,     n_classes=2,     n_clusters_per_class=1,     weights=[0.5, 0.5],     class_sep=1.6,     flip_y=0.05,     random_state=RANDOM_STATE )  XA0  = XA[yA == 0]  XB, yB = make_classification(     n_samples=1000,     n_features=2,     n_informative=2,     n_redundant=0,     n_classes=2,     n_clusters_per_class=2,     weights=[0.5, 0.5],     class_sep=1.6,     flip_y=0.05,     random_state=RANDOM_STATE )  XB1b = XB[yB == 1]  X = np.vstack([XA0, XB1b]) y = np.concatenate([     np.zeros(len(XA0), dtype=int),     np.ones (len(XB1b), dtype=int) ]) <p>Para criar as duas classes com n\u00fameros de clusters diferentes, \u00e9 necess\u00e1rio criar duas classes de forma manual, uma vez que a fun\u00e7\u00e3o <code>make_classification()</code>, n\u00e3o aceita receber uma tupla para <code>n_clusters_per_class</code>, para fazer diferentes clusters, para diferentes classes. Uma vez feita as classes de forma separada e depois concatenada, \u00e9 necess\u00e1rio fazer os splits para o treinamento e teste.</p> In\u00a0[21]: Copied! <pre>Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\n</pre> Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE) <p>Seguindo a separa\u00e7\u00e3o proposta, foram utilizados 80% dos dados no treinamento, e 20% para o teste final</p> In\u00a0[22]: Copied! <pre>mlp = MLPClassifierScratch(\n    Xtr, ytr,\n    hidden_layer_sizes=(16,),\n    activation=\"tanh\",\n    output_activation=\"sigmoid\",\n    loss=\"bce\",\n    eta=0.05,\n    batch_size=32,\n    max_epochs=400,\n    validation_fraction=0.2,\n    patience=30,\n    seed=RANDOM_STATE,\n    bias_as_weight=True\n)\n\nmlp.train(verbose=False)\n</pre>  mlp = MLPClassifierScratch(     Xtr, ytr,     hidden_layer_sizes=(16,),     activation=\"tanh\",     output_activation=\"sigmoid\",     loss=\"bce\",     eta=0.05,     batch_size=32,     max_epochs=400,     validation_fraction=0.2,     patience=30,     seed=RANDOM_STATE,     bias_as_weight=True )  mlp.train(verbose=False) <p>Para o modelo em si, foi utilizado um MLP com apenas uma camada oculta, aquela que gerar\u00e1 informa\u00e7\u00f5es para a camada final gerar a predi\u00e7\u00e3o sobre o y, e essa contou com 16 neur\u00f4nios de procesamento. As fun\u00e7\u00f5es de ativa\u00e7\u00e3o aplicadas foram, tanh() nas camadas ocultas e sigmoid() na camada final. Al\u00e9m disso, a m\u00e9trica de perda utilizada foi a BCE. Os pontos fortes desse tipo de m\u00e9trica de erro \u00e9 a penaliza\u00e7\u00e3o das previs\u00f5es confiantes e erradas, exemplo: prever 0.99 quando o r\u00f3tulo \u00e9 0 gera perda alta. E al\u00e9m disso, incentiva probabilidades bem calibradas, quanto mais perto das verdadeiras, menor a perda.</p> <p>Como m\u00e9todo de parada antecipada, a quantidade de \u00e9pocas sem melhora na taxa de perda foram de 30 e para melhora computacional, os bias foram computados como um peso a mais na matriz de pesos.</p> In\u00a0[23]: Copied! <pre>print(\"Raz\u00e3o de parada:\", mlp.stop_reason)\nprint(\"Acur\u00e1cia de teste:\", mlp.score(Xte, yte) * 100)\n</pre> print(\"Raz\u00e3o de parada:\", mlp.stop_reason) print(\"Acur\u00e1cia de teste:\", mlp.score(Xte, yte) * 100) <pre>Raz\u00e3o de parada: No improvement for 30 epochs\nAcur\u00e1cia de teste: 98.50746268656717\n</pre> <p>Interessante observar sobre a aplica\u00e7\u00e3o do modelo \u00e9 de que, mesmo com duas classes para serem preditas e uma delas contendo mais de um cluster, o modelo convergiu rapidamente e apresentou uma acur\u00e1cia de 98,51% no conjunto de teste. Isso \u00e9 ruim, uma vez que o conjunto de dados estava facilmente separ\u00e1vel, e tamb\u00e9m o modelo provavelemnte overfittou, o que em uma situa\u00e7\u00e3o real de dados \u00e9 extreamente prejudicial para deployment.</p> In\u00a0[24]: Copied! <pre>hist = mlp.get_history().as_dict()\n\n# CURVA DE TREINAMENTO\nplt.figure(figsize=(6,4))\nplt.plot(hist[\"epoch\"], hist[\"train_loss\"], label=\"train_loss\")\n\nplt.plot(hist[\"epoch\"], [np.nan if v is None else v for v in hist[\"val_loss\"]], label=\"val_loss\")\n\nplt.xlabel(\"\u00c9poca\")\nplt.ylabel(\"Loss\")\nplt.title(\"Curva de treinamento\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> hist = mlp.get_history().as_dict()  # CURVA DE TREINAMENTO plt.figure(figsize=(6,4)) plt.plot(hist[\"epoch\"], hist[\"train_loss\"], label=\"train_loss\")  plt.plot(hist[\"epoch\"], [np.nan if v is None else v for v in hist[\"val_loss\"]], label=\"val_loss\")  plt.xlabel(\"\u00c9poca\") plt.ylabel(\"Loss\") plt.title(\"Curva de treinamento\") plt.legend() plt.tight_layout() plt.show() <p>Com rela\u00e7\u00e3o ao gr\u00e1fico de treinamento, \u00e9 poss\u00edvel perceber a melhora constante do modelo durante as \u00e9pocas, e que mesmo no conjunto de valida\u00e7\u00e3o, essa melhora acontece de forma linear.</p> In\u00a0[25]: Copied! <pre># FRONTEIRA DE DECIS\u00c3O TRA\u00c7ADA\nx_min = X[:,0].min()-0.5\nx_max = X[:,0].max()+0.5\n\ny_min = X[:,1].min()-0.5\ny_max = X[:,1].max()+0.5\n\nxx, yy = np.meshgrid(\n    np.arange(x_min, x_max, 0.2),\n    np.arange(y_min, y_max, 0.2)\n)\ngrid = np.c_[xx.ravel(), yy.ravel()]\nzz = mlp.predict(grid).reshape(xx.shape)\n\nplt.figure(figsize=(6,5))\nplt.contourf(xx, yy, zz, alpha=0.25)\n\nidx0 = (y == 0)\nidx1 = (y == 1)\n\nplt.scatter(X[idx0, 0], X[idx0, 1], s=25, edgecolor=\"k\", label=\"Classe 0\")\nplt.scatter(X[idx1, 0], X[idx1, 1], s=25, edgecolor=\"k\", label=\"Classe 1\")\n\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.title(\"Fronteira de decis\u00e3o\")\nplt.legend(title=\"Dados\", loc=\"upper right\")\nplt.tight_layout()\nplt.show()\n</pre> # FRONTEIRA DE DECIS\u00c3O TRA\u00c7ADA x_min = X[:,0].min()-0.5 x_max = X[:,0].max()+0.5  y_min = X[:,1].min()-0.5 y_max = X[:,1].max()+0.5  xx, yy = np.meshgrid(     np.arange(x_min, x_max, 0.2),     np.arange(y_min, y_max, 0.2) ) grid = np.c_[xx.ravel(), yy.ravel()] zz = mlp.predict(grid).reshape(xx.shape)  plt.figure(figsize=(6,5)) plt.contourf(xx, yy, zz, alpha=0.25)  idx0 = (y == 0) idx1 = (y == 1)  plt.scatter(X[idx0, 0], X[idx0, 1], s=25, edgecolor=\"k\", label=\"Classe 0\") plt.scatter(X[idx1, 0], X[idx1, 1], s=25, edgecolor=\"k\", label=\"Classe 1\")  plt.xlabel(\"x1\") plt.ylabel(\"x2\") plt.title(\"Fronteira de decis\u00e3o\") plt.legend(title=\"Dados\", loc=\"upper right\") plt.tight_layout() plt.show() <p>No entanto, j\u00e1 olhando para o conjunto de dados, e as fronteiras de decis\u00e3o em teoria propostas pelo modelo, \u00e9 interessante perceber que mesmo os ru\u00eddos adicionados pelo par\u00e2metro flip_y n\u00e3o foram o suficientes para afetar o modelo de convergir para uma fronteira muito concreta de decis\u00e3o. Outro ponto relevante \u00e9 perceber na classe 1 os dois clusters de dados, um com uma \"reta\" muito concentrada e outro com pontos mais dispersos formando uma elipse.</p> In\u00a0[26]: Copied! <pre>from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\nproba_te = mlp.predict_proba(Xte)\ny_pred = (proba_te &gt;= 0.5).astype(int)\n\ncm_norm = confusion_matrix(yte, y_pred, labels=[0,1], normalize=\"true\")\nConfusionMatrixDisplay(cm_norm, display_labels=[0,1]).plot(cmap=\"Blues\", colorbar=True)\n\nplt.title(\"Matriz de Confus\u00e3o (normalizada)\")\nplt.tight_layout()\nplt.show()\n</pre> from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  proba_te = mlp.predict_proba(Xte) y_pred = (proba_te &gt;= 0.5).astype(int)  cm_norm = confusion_matrix(yte, y_pred, labels=[0,1], normalize=\"true\") ConfusionMatrixDisplay(cm_norm, display_labels=[0,1]).plot(cmap=\"Blues\", colorbar=True)  plt.title(\"Matriz de Confus\u00e3o (normalizada)\") plt.tight_layout() plt.show() <p>Um aspecto extra que a matriz de confus\u00e3o traz \u00e9 onde o erro est\u00e1 localizado. No caso, por mais que o modelo tenha errado muito pouco, ele errou mais categorizando a classe 0 do que a 1, errando 2% dos casos da classe 0, prevendo como 1.</p> <ul> <li>N\u00famero de amostras <code>n_samples</code>: 1500</li> <li>N\u00famero de classes: 3</li> <li>N\u00famero de clusters por classe <code>n_clusters_per_class</code>: 2, em uma, 3 em outra e 4 na \u00faltima</li> <li>N\u00famero de features <code>n_features</code>: 4<ul> <li>N\u00famero de features efetivas <code>n_informative</code>: 4</li> <li>N\u00famero de features redundantes <code>n_redundant</code>: 0</li> </ul> </li> <li>Dispers\u00e3o das classes <code>class_sep</code>: 1.6</li> <li>Ru\u00eddo das classes <code>flip_y</code>: 0.02</li> <li>Semente de aleatoriza\u00e7\u00e3o <code>random_state</code>: 42</li> </ul> In\u00a0[27]: Copied! <pre>import numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nRANDOM_STATE = 42\n\nXA, yA = make_classification(\n    n_samples=1500,\n    n_features=4,\n    n_informative=4,\n    n_redundant=0,\n    n_classes=3,\n    n_clusters_per_class=2,\n    weights=[0.33, 0.33, 0.33],\n    class_sep=1.6,\n    flip_y=0.05,\n    random_state=RANDOM_STATE\n)\n\nXA0 = XA[yA==0]\n\nXB, yB = make_classification(\n    n_samples=1500,\n    n_features=4,\n    n_informative=4,\n    n_redundant=0,\n    n_classes=3,\n    n_clusters_per_class=3,\n    weights=[0.33, 0.33, 0.33],\n    class_sep=1.6,\n    flip_y=0.05,\n    random_state=RANDOM_STATE\n)\n\nXB1 = XB[yB==1]\n\nXC, yC = make_classification(\n    n_samples=1500,\n    n_features=4,\n    n_informative=4,\n    n_redundant=0,\n    n_classes=3,\n    n_clusters_per_class=4,\n    weights=[0.33, 0.33, 0.33],\n    class_sep=1.6,\n    flip_y=0.05,\n    random_state=RANDOM_STATE\n)\n\nXC2 = XC[yC==2]\n\nX = np.vstack([XA0, XB1, XC2])\ny = np.concatenate([\n    np.zeros(len(XA0), dtype=int),\n    np.ones (len(XB1), dtype=int),\n    np.ones (len(XC2), dtype=int) * 2\n])\n</pre> import numpy as np from sklearn.datasets import make_classification from sklearn.model_selection import train_test_split import matplotlib.pyplot as plt  RANDOM_STATE = 42  XA, yA = make_classification(     n_samples=1500,     n_features=4,     n_informative=4,     n_redundant=0,     n_classes=3,     n_clusters_per_class=2,     weights=[0.33, 0.33, 0.33],     class_sep=1.6,     flip_y=0.05,     random_state=RANDOM_STATE )  XA0 = XA[yA==0]  XB, yB = make_classification(     n_samples=1500,     n_features=4,     n_informative=4,     n_redundant=0,     n_classes=3,     n_clusters_per_class=3,     weights=[0.33, 0.33, 0.33],     class_sep=1.6,     flip_y=0.05,     random_state=RANDOM_STATE )  XB1 = XB[yB==1]  XC, yC = make_classification(     n_samples=1500,     n_features=4,     n_informative=4,     n_redundant=0,     n_classes=3,     n_clusters_per_class=4,     weights=[0.33, 0.33, 0.33],     class_sep=1.6,     flip_y=0.05,     random_state=RANDOM_STATE )  XC2 = XC[yC==2]  X = np.vstack([XA0, XB1, XC2]) y = np.concatenate([     np.zeros(len(XA0), dtype=int),     np.ones (len(XB1), dtype=int),     np.ones (len(XC2), dtype=int) * 2 ]) <p>Aqui novamente, para alcan\u00e7ar as classes com diferentes n\u00fameros de clusters, \u00e9 necess\u00e1rio criar as classes de forma separada e ap\u00f3s isso, juntar todas.</p> In\u00a0[28]: Copied! <pre>Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\n</pre> Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE) In\u00a0[29]: Copied! <pre>mlp = MLPClassifierScratch(\n    Xtr, ytr,\n    hidden_layer_sizes=(16,),\n    activation=\"tanh\",\n    output_activation=\"softmax\",\n    loss=\"cce\",\n    eta=0.05,\n    batch_size=32,\n    max_epochs=400,\n    validation_fraction=0.2,\n    patience=30,\n    seed=RANDOM_STATE,\n    bias_as_weight=True\n)\n\nmlp.train(verbose=False)\n</pre> mlp = MLPClassifierScratch(     Xtr, ytr,     hidden_layer_sizes=(16,),     activation=\"tanh\",     output_activation=\"softmax\",     loss=\"cce\",     eta=0.05,     batch_size=32,     max_epochs=400,     validation_fraction=0.2,     patience=30,     seed=RANDOM_STATE,     bias_as_weight=True )  mlp.train(verbose=False) <p>Uma mudan\u00e7a que se faz necess\u00e1ria nesse caso, \u00e9 a m\u00e9trica de erro utilizada para atualizar os pesos. Como nesse caso, os dados s\u00e3o multi-classe, o BCE n\u00e3o \u00e9 mais poss\u00edvel de ser utilizado. Diante disso, foi implementado o CCE e o softmax pois, para problemas multiclasse com r\u00f3tulos mutuamente exclusivos a softmax transforma os \u201clogits\u201d em uma distribui\u00e7\u00e3o de probabilidade sobre as K classes condi\u00e7\u00e3o necess\u00e1ria quando h\u00e1 mais de duas classes. E com isso, o CCE \u00e9 o negativo do log-verossimilhan\u00e7a do modelo multinomial, Otimiz\u00e1-la equivale a maximizar a probabilidade da classe correta e a minimizar a diverg\u00eancia entre a distribui\u00e7\u00e3o alvo e a distribui\u00e7\u00e3o prevista.</p> In\u00a0[30]: Copied! <pre>print(\"Raz\u00e3o de parada:\", mlp.stop_reason)\nprint(\"Acur\u00e1cia de teste:\", mlp.score(Xte, yte) * 100)\n</pre> print(\"Raz\u00e3o de parada:\", mlp.stop_reason) print(\"Acur\u00e1cia de teste:\", mlp.score(Xte, yte) * 100) <pre>Raz\u00e3o de parada: No improvement for 30 epochs\nAcur\u00e1cia de teste: 79.40199335548172\n</pre> <p>Novamente, mesmo com mais classes e mais clusters em cada classe, o modelo convergiu. No entanto, interessante pontuar que a acur\u00e1cia aqui diminuiu consideravelmente. Isso acontece provavelmente por conta da quantidade de clusters adicionados entre as classes, o que criou um emaranhado de dados sobrepostos, aumentando a dificultade de separa\u00e7\u00e3o destes. No gr\u00e1fico de dispers\u00e3o dos dados abaixo, \u00e9 poss\u00edvel ver que os dados ficaram bastante sobrepostos e de dif\u00edcil separa\u00e7\u00e3o.</p> In\u00a0[31]: Copied! <pre>hist = mlp.get_history().as_dict()\n\nplt.figure(figsize=(6,4))\nplt.plot(hist[\"epoch\"], hist[\"train_loss\"], label=\"train_loss\")\n\nplt.plot(hist[\"epoch\"], [np.nan if v is None else v for v in hist[\"val_loss\"]], label=\"val_loss\")\n\nplt.xlabel(\"\u00c9poca\")\nplt.ylabel(\"Loss\")\nplt.title(\"Curva de treinamento\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> hist = mlp.get_history().as_dict()  plt.figure(figsize=(6,4)) plt.plot(hist[\"epoch\"], hist[\"train_loss\"], label=\"train_loss\")  plt.plot(hist[\"epoch\"], [np.nan if v is None else v for v in hist[\"val_loss\"]], label=\"val_loss\")  plt.xlabel(\"\u00c9poca\") plt.ylabel(\"Loss\") plt.title(\"Curva de treinamento\") plt.legend() plt.tight_layout() plt.show() <p>Com rela\u00e7\u00e3o a curva de aprendizado no conjunto de treinamento, o modelo novamente apresenta um aprendizado cont\u00ednuo. Por\u00e9m, \u00e9 um ponto relevante perceber a variabilidade dos resultados, com diversos spikes durante o processo de treinamento, por mais que num olhar macro o erro estivesse descendo.</p> In\u00a0[32]: Copied! <pre>feat_x, feat_y = 0, 1\n\nx_min, x_max = X[:, feat_x].min() - 0.5, X[:, feat_x].max() + 0.5\ny_min, y_max = X[:, feat_y].min() - 0.5, X[:, feat_y].max() + 0.5\n\nxx, yy = np.meshgrid(\n    np.linspace(x_min, x_max, 300),\n    np.linspace(y_min, y_max, 300)\n)\n\nX_means = Xtr.mean(axis=0)\ngrid_full = np.tile(X_means, (xx.size, 1))\n\ngrid_full[:, feat_x] = xx.ravel()\ngrid_full[:, feat_y] = yy.ravel()\n\nzz = mlp.predict(grid_full).reshape(xx.shape)\n\nplt.figure(figsize=(6,5))\nplt.contourf(xx, yy, zz, alpha=0.25)\n\nfor cls in np.unique(y):\n    idx = (y == cls)\n    plt.scatter(X[idx, feat_x], X[idx, feat_y], s=25, edgecolor=\"k\", label=f\"Classe {cls}\")\n\nplt.xlabel(f\"x{feat_x+1}\")\nplt.ylabel(f\"x{feat_y+1}\")\nplt.title(\"Fronteira de decis\u00e3o (slice 2D com demais features na m\u00e9dia)\")\nplt.legend(title=\"Dados\", loc=\"upper right\")\nplt.tight_layout()\nplt.show()\n</pre> feat_x, feat_y = 0, 1  x_min, x_max = X[:, feat_x].min() - 0.5, X[:, feat_x].max() + 0.5 y_min, y_max = X[:, feat_y].min() - 0.5, X[:, feat_y].max() + 0.5  xx, yy = np.meshgrid(     np.linspace(x_min, x_max, 300),     np.linspace(y_min, y_max, 300) )  X_means = Xtr.mean(axis=0) grid_full = np.tile(X_means, (xx.size, 1))  grid_full[:, feat_x] = xx.ravel() grid_full[:, feat_y] = yy.ravel()  zz = mlp.predict(grid_full).reshape(xx.shape)  plt.figure(figsize=(6,5)) plt.contourf(xx, yy, zz, alpha=0.25)  for cls in np.unique(y):     idx = (y == cls)     plt.scatter(X[idx, feat_x], X[idx, feat_y], s=25, edgecolor=\"k\", label=f\"Classe {cls}\")  plt.xlabel(f\"x{feat_x+1}\") plt.ylabel(f\"x{feat_y+1}\") plt.title(\"Fronteira de decis\u00e3o (slice 2D com demais features na m\u00e9dia)\") plt.legend(title=\"Dados\", loc=\"upper right\") plt.tight_layout() plt.show() <p>Sobre a disposi\u00e7\u00e3o dos dados, ao utilizar 3 classes e v\u00e1rios clusters em cada uma, at\u00e9 a olho nu \u00e9 dif\u00edcil de separar as classes, por conta da alta sobreposi\u00e7\u00e3o dos valores. Al\u00e9m disso, pelo fato de o conjunto de vari\u00e1veis independentes contarem com 4 features, a visualiza\u00e7\u00e3o dos dados tamb\u00e9m fica prejudicada, uma vez que \u00e9 poss\u00edvel apenas visualizar de forma simples e pr\u00e1tica em at\u00e9 3 dimens\u00f5es e n\u00e3o quatro.</p> In\u00a0[33]: Copied! <pre>from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport numpy as np\n\ny_pred = mlp.predict(Xte)\n\nlabels = np.unique(yte)\n\ncm_norm = confusion_matrix(yte, y_pred, labels=labels, normalize=\"true\")\nConfusionMatrixDisplay(cm_norm, display_labels=labels).plot(cmap=\"Purples\", colorbar=True)\n\nplt.title(\"Matriz de Confus\u00e3o (normalizada)\")\nplt.tight_layout()\nplt.show()\n</pre> from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay import numpy as np  y_pred = mlp.predict(Xte)  labels = np.unique(yte)  cm_norm = confusion_matrix(yte, y_pred, labels=labels, normalize=\"true\") ConfusionMatrixDisplay(cm_norm, display_labels=labels).plot(cmap=\"Purples\", colorbar=True)  plt.title(\"Matriz de Confus\u00e3o (normalizada)\") plt.tight_layout() plt.show() <p>Sobre a matriz de confus\u00e3o, o cruzamento de classes com maior erro por parte do modelo, foi entre a classe 1 e a 0. Nesse espa\u00e7o, o modelo categorizou 21% das observa\u00e7\u00f5es de forma errada, assumindo que a classe 1, na verdade era a 0. A grandeza desse erro \u00e9 interessante, uma vez que \u00e9 muito mais relevante do que nos dados explorados anteriormente, no caso bin\u00e1rio, onde o maior erro foi pr\u00f3ximo de 2%.</p> <ul> <li>N\u00famero de amostras <code>n_samples</code>: 1500</li> <li>N\u00famero de classes: 3</li> <li>N\u00famero de clusters por classe <code>n_clusters_per_class</code>: 2, em uma, 3 em outra e 4 na \u00faltima</li> <li>N\u00famero de features <code>n_features</code>: 4<ul> <li>N\u00famero de features efetivas <code>n_informative</code>: 4</li> <li>N\u00famero de features redundantes <code>n_redundant</code>: 0</li> </ul> </li> <li>Dispers\u00e3o das classes <code>class_sep</code>: 1.6</li> <li>Ru\u00eddo das classes <code>flip_y</code>: 0.02</li> <li>Semente de aleatoriza\u00e7\u00e3o <code>random_state</code>: 42</li> </ul> In\u00a0[34]: Copied! <pre>import numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nRANDOM_STATE = 42\n\nXA, yA = make_classification(\n    n_samples=1500,\n    n_features=4,\n    n_informative=4,\n    n_redundant=0,\n    n_classes=3,\n    n_clusters_per_class=2,\n    weights=[0.33, 0.33, 0.33],\n    class_sep=1.6,\n    flip_y=0.05,\n    random_state=RANDOM_STATE\n)\n\nXA0 = XA[yA==0]\n\nXB, yB = make_classification(\n    n_samples=1500,\n    n_features=4,\n    n_informative=4,\n    n_redundant=0,\n    n_classes=3,\n    n_clusters_per_class=3,\n    weights=[0.33, 0.33, 0.33],\n    class_sep=1.6,\n    flip_y=0.05,\n    random_state=RANDOM_STATE\n)\n\nXB1 = XB[yB==1]\n\nXC, yC = make_classification(\n    n_samples=1500,\n    n_features=4,\n    n_informative=4,\n    n_redundant=0,\n    n_classes=3,\n    n_clusters_per_class=4,\n    weights=[0.33, 0.33, 0.33],\n    class_sep=1.6,\n    flip_y=0.05,\n    random_state=RANDOM_STATE\n)\n\nXC2 = XC[yC==2]\n\nX = np.vstack([XA0, XB1, XC2])\ny = np.concatenate([\n    np.zeros(len(XA0), dtype=int),\n    np.ones (len(XB1), dtype=int),\n    np.ones (len(XC2), dtype=int) * 2\n])\n</pre> import numpy as np from sklearn.datasets import make_classification from sklearn.model_selection import train_test_split import matplotlib.pyplot as plt  RANDOM_STATE = 42  XA, yA = make_classification(     n_samples=1500,     n_features=4,     n_informative=4,     n_redundant=0,     n_classes=3,     n_clusters_per_class=2,     weights=[0.33, 0.33, 0.33],     class_sep=1.6,     flip_y=0.05,     random_state=RANDOM_STATE )  XA0 = XA[yA==0]  XB, yB = make_classification(     n_samples=1500,     n_features=4,     n_informative=4,     n_redundant=0,     n_classes=3,     n_clusters_per_class=3,     weights=[0.33, 0.33, 0.33],     class_sep=1.6,     flip_y=0.05,     random_state=RANDOM_STATE )  XB1 = XB[yB==1]  XC, yC = make_classification(     n_samples=1500,     n_features=4,     n_informative=4,     n_redundant=0,     n_classes=3,     n_clusters_per_class=4,     weights=[0.33, 0.33, 0.33],     class_sep=1.6,     flip_y=0.05,     random_state=RANDOM_STATE )  XC2 = XC[yC==2]  X = np.vstack([XA0, XB1, XC2]) y = np.concatenate([     np.zeros(len(XA0), dtype=int),     np.ones (len(XB1), dtype=int),     np.ones (len(XC2), dtype=int) * 2 ]) In\u00a0[35]: Copied! <pre>Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\n</pre> Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE) In\u00a0[36]: Copied! <pre>mlp = MLPClassifierScratch(\n    Xtr, ytr,\n    hidden_layer_sizes=(128, 64, 32, 16),\n    activation=\"tanh\",\n    output_activation=\"softmax\",\n    loss=\"cce\",\n    eta=0.05,\n    batch_size=32,\n    max_epochs=400,\n    validation_fraction=0.2,\n    patience=30,\n    seed=RANDOM_STATE,\n    bias_as_weight=True\n)\n\nmlp.train(verbose=False)\n</pre> mlp = MLPClassifierScratch(     Xtr, ytr,     hidden_layer_sizes=(128, 64, 32, 16),     activation=\"tanh\",     output_activation=\"softmax\",     loss=\"cce\",     eta=0.05,     batch_size=32,     max_epochs=400,     validation_fraction=0.2,     patience=30,     seed=RANDOM_STATE,     bias_as_weight=True )  mlp.train(verbose=False) <p>Como citado, foram implementadas 4 camadas ocultas, com diferentes quantidade de neur\u00f4nios em cada uma. No restante dos par\u00e2metros, nada foi alterado, para justamente ser poss\u00edvel a compara\u00e7\u00e3o puramente em quantidade de camadas ocultas aplicadas.</p> In\u00a0[37]: Copied! <pre>print(\"Raz\u00e3o de parada:\", mlp.stop_reason)\nprint(\"Acur\u00e1cia de teste:\", mlp.score(Xte, yte) * 100)\n</pre> print(\"Raz\u00e3o de parada:\", mlp.stop_reason) print(\"Acur\u00e1cia de teste:\", mlp.score(Xte, yte) * 100) <pre>Raz\u00e3o de parada: No improvement for 30 epochs\nAcur\u00e1cia de teste: 81.72757475083057\n</pre> <p>O resutado encontrado nesse experimento \u00e9 de longe o mais interessante, uma vez que, por mais que foram implementadas 3 novas camadas ocultas, o uso dessas no mesmo conjunto de dados anterior foi capaz de melhorar a acur\u00e1cia de teste em apenas aproximadamente 2 pontos percentuais. Claro que 2 p.p. em alguns casos \u00e9 um grande avan\u00e7o, mas tendo em vista de que se trata de um conjunto de dados sint\u00e9tico, o resultado de certa forma \u00e9 ruim, pois os dados n\u00e3o possuem tamanha complexidade e poderiam ser melhor categorizados.</p> In\u00a0[38]: Copied! <pre>hist = mlp.get_history().as_dict()\n\nplt.figure(figsize=(6,4))\nplt.plot(hist[\"epoch\"], hist[\"train_loss\"], label=\"train_loss\")\n\nplt.plot(hist[\"epoch\"], [np.nan if v is None else v for v in hist[\"val_loss\"]], label=\"val_loss\")\n\nplt.xlabel(\"\u00c9poca\")\nplt.ylabel(\"Loss\")\nplt.title(\"Curva de treinamento\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> hist = mlp.get_history().as_dict()  plt.figure(figsize=(6,4)) plt.plot(hist[\"epoch\"], hist[\"train_loss\"], label=\"train_loss\")  plt.plot(hist[\"epoch\"], [np.nan if v is None else v for v in hist[\"val_loss\"]], label=\"val_loss\")  plt.xlabel(\"\u00c9poca\") plt.ylabel(\"Loss\") plt.title(\"Curva de treinamento\") plt.legend() plt.tight_layout() plt.show() <p>Com rela\u00e7\u00e3o ao progesso de treinamento, esse \u00e9 bem divergente dos anteriormente vistos, uma vez que do ponto inicial at\u00e9 o final, o erro diminuiu, no entanto, a grandeza de redu\u00e7\u00e3o \u00e9 muito pequena, al\u00e9m de que essa conta com diversos spikes durante o percurso, retomando o erro para valores maiores inclusive que o inicial.</p> In\u00a0[39]: Copied! <pre>feat_x, feat_y = 0, 1\n\nx_min, x_max = X[:, feat_x].min() - 0.5, X[:, feat_x].max() + 0.5\ny_min, y_max = X[:, feat_y].min() - 0.5, X[:, feat_y].max() + 0.5\n\nxx, yy = np.meshgrid(\n    np.linspace(x_min, x_max, 300),\n    np.linspace(y_min, y_max, 300)\n)\n\nX_means = Xtr.mean(axis=0)\ngrid_full = np.tile(X_means, (xx.size, 1))\n\ngrid_full[:, feat_x] = xx.ravel()\ngrid_full[:, feat_y] = yy.ravel()\n\nzz = mlp.predict(grid_full).reshape(xx.shape)\n\nplt.figure(figsize=(6,5))\nplt.contourf(xx, yy, zz, alpha=0.25)\n\nfor cls in np.unique(y):\n    idx = (y == cls)\n    plt.scatter(X[idx, feat_x], X[idx, feat_y], s=25, edgecolor=\"k\", label=f\"Classe {cls}\")\n\nplt.xlabel(f\"x{feat_x+1}\")\nplt.ylabel(f\"x{feat_y+1}\")\nplt.title(\"Fronteira de decis\u00e3o (slice 2D com demais features na m\u00e9dia)\")\nplt.legend(title=\"Dados\", loc=\"upper right\")\nplt.tight_layout()\nplt.show()\n</pre> feat_x, feat_y = 0, 1  x_min, x_max = X[:, feat_x].min() - 0.5, X[:, feat_x].max() + 0.5 y_min, y_max = X[:, feat_y].min() - 0.5, X[:, feat_y].max() + 0.5  xx, yy = np.meshgrid(     np.linspace(x_min, x_max, 300),     np.linspace(y_min, y_max, 300) )  X_means = Xtr.mean(axis=0) grid_full = np.tile(X_means, (xx.size, 1))  grid_full[:, feat_x] = xx.ravel() grid_full[:, feat_y] = yy.ravel()  zz = mlp.predict(grid_full).reshape(xx.shape)  plt.figure(figsize=(6,5)) plt.contourf(xx, yy, zz, alpha=0.25)  for cls in np.unique(y):     idx = (y == cls)     plt.scatter(X[idx, feat_x], X[idx, feat_y], s=25, edgecolor=\"k\", label=f\"Classe {cls}\")  plt.xlabel(f\"x{feat_x+1}\") plt.ylabel(f\"x{feat_y+1}\") plt.title(\"Fronteira de decis\u00e3o (slice 2D com demais features na m\u00e9dia)\") plt.legend(title=\"Dados\", loc=\"upper right\") plt.tight_layout() plt.show() <p>Comparando como ficaram as fronteiras de decis\u00e3o no \u00fatlimo caso e nesse, \u00e9 poss\u00edvel compreender que a maior quantidade de camadas alterou principalmente como o modelo percebe as fronteiras em x2 &lt; 0. Uma vez que a fronteira amarela quase n\u00e3o foi alterada, e apenas houve uma maior separa\u00e7\u00e3o nas fronteiras azul e lil\u00e1s, em que a azul predomoniou x1 &lt; -1 e a lil\u00e1s x1 &gt; -1.</p> In\u00a0[40]: Copied! <pre>from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport numpy as np\n\ny_pred = mlp.predict(Xte)\n\nlabels = np.unique(yte)\n\ncm_norm = confusion_matrix(yte, y_pred, labels=labels, normalize=\"true\")\nConfusionMatrixDisplay(cm_norm, display_labels=labels).plot(cmap=\"Purples\", colorbar=True)\n\nplt.title(\"Matriz de Confus\u00e3o (normalizada)\")\nplt.tight_layout()\nplt.show()\n</pre> from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay import numpy as np  y_pred = mlp.predict(Xte)  labels = np.unique(yte)  cm_norm = confusion_matrix(yte, y_pred, labels=labels, normalize=\"true\") ConfusionMatrixDisplay(cm_norm, display_labels=labels).plot(cmap=\"Purples\", colorbar=True)  plt.title(\"Matriz de Confus\u00e3o (normalizada)\") plt.tight_layout() plt.show() <p>Por fim, com rela\u00e7\u00e3o a matriz de confus\u00e3o, o maior avan\u00e7o sobre o \u00faltimo exemplo foi focado no cruzamento de classes com maior confus\u00e3o e tamb\u00e9m na grandeza dessa confus\u00e3o. Anteriormente o maior erro era entre as classes 0 e 1, com 21% das classifica\u00e7\u00f5es da classe 1, erradas como 0. Agora o modelo errou mais entre as classes 1 e 2, com 16% das classifica\u00e7\u00f5es da classe 2, erradas como 1.</p>"},{"location":"exercicios/mpl/mlp/#mpl-multi-layer-perceptron","title":"MPL (Multi Layer Perceptron)\u00b6","text":"<p>O conte\u00fado dessa se\u00e7\u00e3o \u00e9 uma continua\u00e7\u00e3o do explorado em Perceptron. O MPL, nada mais \u00e9 do que v\u00e1rios perceptrons juntos, com o que \u00e9 chamado de camadas, onde cada perceptron processa o dado, gera um output e esse \u00e9 inserido em outro perceptron, com outros pesos e talvez outras fun\u00e7\u00f5es de ativa\u00e7\u00e3o. De modo bem resumido, um MPL \u00e9 uma combina\u00e7\u00e3o de diversas formas, de v\u00e1rios perceptrons diferentes.</p> <p>Ser\u00e1 apresentado primeiramente a parte matem\u00e1tica da atualiza\u00e7\u00e3o dos v\u00e1rios pesos internos do modelo, e posteriormente, a explora\u00e7\u00e3o da capacidade extra do MPL perante ao perceptron, a possibilidade de classifica\u00e7\u00e3o de dados multi classe.</p>"},{"location":"exercicios/mpl/mlp/#a-matematica-da-atualizacao-dos-pesos","title":"A matem\u00e1tica da atualiza\u00e7\u00e3o dos pesos\u00b6","text":"<p>Para o exerc\u00edcio sobre a atualiza\u00e7\u00e3o dos pesos, os dados utilizados foram:</p> <p>Dados de input:</p> <p>$\\mathbf{x} = [0.5, -0.2]$</p> <p>$y = 1.0$</p> <p>Pesos da camada interna:</p> <p>$\\mathbf{W}^{(1)} = \\begin{bmatrix} 0.3 &amp; -0.1 \\\\ 0.2 &amp; 0.4 \\end{bmatrix}$</p> <p>$\\mathbf{b}^{(1)} = [0.1, -0.2]$</p> <p>Pesos da camada de output:</p> <p>$\\mathbf{W}^{(2)} = [0.5, -0.3]$</p> <p>$b^{(2)} = 0.2$</p> <p>Taxa de apredizado: $\\eta = 0.3$</p> <p>Fun\u00e7\u00e3o de ativa\u00e7\u00e3o das camadas: $\\tanh()$</p> <p>Contabiliza\u00e7\u00e3o erro: $ L = \\frac{1}{N} (y - \\hat{y})^2$</p> <p>Como j\u00e1 foi dito, o MLP \u00e9 um conjunto de perceptrons, ent\u00e3o a ideia aqui presente \u00e9 utilizar o x de input no \"primeiro perceptron\" e com a sa\u00edda desse, aplicar no \"segundo perceptron\". Um ponto interessante de se ressaltar \u00e9 que no bias para fins de melhora e otimiza\u00e7\u00e3o computacional, pode ser entendido como uma outra entrada, no entanto com o valor de 1, assim o seu valor sempre ser\u00e1 o valor do seu respectivo peso. Tendo assim o vetor de entrada e seus respectivos pesos ($\\mathbf{W}^{(1)}$):</p> <p>$$ \\mathbf{x} = \\begin{bmatrix} 0.5\\\\[2pt] -0.2\\\\[2pt] 1 \\end{bmatrix}  \\qquad  \\mathbf{W}^{(1)} = \\begin{bmatrix} 0.3 &amp; 0.2 &amp; 0.1\\\\ -0.1 &amp; 0.4 &amp; -0.2 \\end{bmatrix} $$</p> <p>$$ \\mathbf{z}^{(1)} = \\mathbf{W}^{(1)}\\,\\mathbf{x} = \\begin{bmatrix} 0.3 &amp; 0.2 &amp; 0.1\\\\ -0.1 &amp; 0.4 &amp; -0.2 \\end{bmatrix} \\begin{bmatrix} 0.5\\\\[2pt] -0.2\\\\[2pt] \\end{bmatrix} = \\begin{bmatrix} 0.21\\\\[2pt] -0.33 \\end{bmatrix} $$</p> <p>$$ \\mathbf{z}^{(1)} = \\begin{bmatrix} 0.21\\\\[2pt] -0.33 \\end{bmatrix} $$</p>"},{"location":"exercicios/mpl/mlp/#classificacao-binaria-com-mlp","title":"Classifica\u00e7\u00e3o bin\u00e1ria com MLP\u00b6","text":"<p>Seguindo adiante na explora\u00e7\u00e3o do poder do MLP, o exerc\u00edcio de analisar dados sint\u00e9ticos, por\u00e9m buscando uma maior complexidade sobre os dados, isto \u00e9, a aproxima\u00e7\u00e3o de dados reais, nesse momento foi utilizada a fun\u00e7\u00e3o <code>make_classification()</code> da biblioteca Scikit-Learn. Isso pois, assim, \u00e9 poss\u00edvel criar clusters de dados com maiores min\u00fancias, o que traz um aspecto diferente para a explora\u00e7\u00e3o. Diante disso, os par\u00e2metros utilizados na gera\u00e7\u00e3o dos dados foram os seguintes:</p>"},{"location":"exercicios/mpl/mlp/#classificacao-multi-classe-com-mlp","title":"Classifica\u00e7\u00e3o multi-classe com MLP\u00b6","text":"<p>Com um novo desafio, e um aspecto ainda n\u00e3o abordado nesse projeto, esse trecho dessa sec\u00e7\u00e3o trar\u00e1 o desafio do modelo de lidar com a classifi\u00e7\u00e3o al\u00e9m dos \"Sim\" e \"N\u00e3o\", com a ades\u00e3o de mais uma classe ao conjunto de dados. A ideia aqui, \u00e9 entender como que um MLP lida com o fato de ao final de cada observa\u00e7\u00e3o ele ter que decidir entre [0, 1, 2]. Para esse conjunto de dados, foram reformulados os par\u00e2metros utilizados para construir as classes.</p>"},{"location":"exercicios/mpl/mlp/#classificacao-multi-classe-com-deep-mlp","title":"Classifica\u00e7\u00e3o multi-classe com Deep MLP\u00b6","text":"<p>Por fim, o \u00fatlimo experimento realizado foi utilizando o maior poder do MLP, a possibilidade de expandir infinitamente a quantidade de camadas de \"Perceptrons\" dentro do modelo, o que traz uma vantagem e tanta no momento de se adaptar a conjuntos de dados complexos e com alta sobreposi\u00e7\u00e3o, como foi o caso anterior. Com rela\u00e7\u00e3o a gera\u00e7\u00e3o dos dados em si, essa n\u00e3o ser\u00e1 alterada, pois a ideia \u00e9 justamente comparar um MLP com apenas duas camadas (uma oculta e outra de sa\u00edda) e outro com v\u00e1rias camadas ocultas. Dessa forma, o conjunto de dados continua respeitando os mesmos par\u00e2metros.</p>"},{"location":"exercicios/mpl/utils/mlp/","title":"Mlp","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nfrom dataclasses import dataclass\nfrom typing import Iterable, List, Tuple, Optional, Dict\n</pre> import numpy as np from dataclasses import dataclass from typing import Iterable, List, Tuple, Optional, Dict In\u00a0[2]: Copied! <pre>@dataclass\nclass TrainingHistory:\n    epoch: list\n    train_loss: list\n    train_accuracy: list\n    val_loss: list\n    val_accuracy: list\n    grad_norm: list\n    weight_norm: list\n\n    def as_dict(self) -&gt; Dict[str, list]:\n        return {\n            \"epoch\": self.epoch,\n            \"train_loss\": self.train_loss,\n            \"train_accuracy\": self.train_accuracy,\n            \"val_loss\": self.val_loss,\n            \"val_accuracy\": self.val_accuracy,\n            \"grad_norm\": self.grad_norm,\n            \"weight_norm\": self.weight_norm,\n        }\n</pre> @dataclass class TrainingHistory:     epoch: list     train_loss: list     train_accuracy: list     val_loss: list     val_accuracy: list     grad_norm: list     weight_norm: list      def as_dict(self) -&gt; Dict[str, list]:         return {             \"epoch\": self.epoch,             \"train_loss\": self.train_loss,             \"train_accuracy\": self.train_accuracy,             \"val_loss\": self.val_loss,             \"val_accuracy\": self.val_accuracy,             \"grad_norm\": self.grad_norm,             \"weight_norm\": self.weight_norm,         } In\u00a0[3]: Copied! <pre>class MLPClassifierScratch:\n    def __init__(\n        self,\n        x: np.ndarray,\n        y: np.ndarray,\n        hidden_layer_sizes: Iterable[int] = (16,),\n        activation: str = \"tanh\",\n        output_activation: Optional[str] = None,\n        loss: Optional[str] = None,\n        eta: float = 0.01,\n        batch_size: int = 32,\n        max_epochs: int = 200,\n        validation_fraction: float = 0.0,\n        patience: int = 20,\n        min_delta: float = 1e-4,\n        seed: int = 42,\n        weight_init: str = \"auto\",\n        bias_as_weight: bool = False,\n    ):\n        self.X = self._as_2d_array(x)\n        self.y_input = y\n        self.n_samples, self.n_features = self.X.shape\n\n        self.Y, self.n_classes, self.classes_, self.target_type = self._normalize_targets(y)\n\n        self.hidden_layer_sizes = tuple(int(h) for h in hidden_layer_sizes)\n        self.activation = activation.lower()\n        assert self.activation in {\"relu\",\"tanh\",\"sigmoid\",\"identity\"}\n\n        if output_activation is None:\n            output_activation = \"sigmoid\" if self.target_type == \"binary\" else (\"softmax\" if self.target_type == \"multiclass\" else \"tanh\")\n        if loss is None:\n            loss = \"bce\" if output_activation == \"sigmoid\" else (\"cce\" if output_activation == \"softmax\" else \"mse\")\n\n        self.output_activation = output_activation.lower()\n        assert self.output_activation in {\"sigmoid\",\"softmax\",\"tanh\",\"identity\"}\n        \n        self.loss_name = loss.lower()\n        assert self.loss_name in {\"bce\",\"cce\",\"mse\"}\n\n        self.eta = float(eta)\n        self.batch_size = int(batch_size)\n        self.max_epochs = int(max_epochs)\n        self.validation_fraction = float(validation_fraction)\n        self.es_patience = int(patience)\n        self.es_min_delta = float(min_delta)\n        self.seed = int(seed)\n        \n        self.weight_init = weight_init.lower()\n        assert self.weight_init in {\"auto\",\"xavier\",\"he\"}\n        \n        self.bias_as_weight = bool(bias_as_weight)\n\n        self.rng = np.random.default_rng(self.seed)\n\n        if self.validation_fraction &gt; 0.0:\n            n_val = max(1, int(self.n_samples * self.validation_fraction))\n            idx = self.rng.permutation(self.n_samples)\n            val_idx, tr_idx = idx[:n_val], idx[n_val:]\n            self.Xtr, self.Ytr = self.X[tr_idx], self.Y[tr_idx]\n            self.Xval, self.Yval = self.X[val_idx], self.Y[val_idx]\n        else:\n            self.Xtr, self.Ytr = self.X, self.Y\n            self.Xval, self.Yval = None, None\n\n        out_dim = self.n_classes if self.output_activation == \"softmax\" else 1\n\n        if self.loss_name == \"mse\" and self.output_activation in {\"tanh\",\"identity\"} and self.n_classes &gt; 1:\n            out_dim = self.n_classes\n\n        layer_sizes = [self.n_features] + list(self.hidden_layer_sizes) + [out_dim]\n        self.params = self._init_params(layer_sizes)\n\n        self.loss_per_epoch: List[float] = []\n        self.accuracy_per_epoch: List[float] = []\n        self.val_loss_per_epoch: List[float] = []\n        self.val_accuracy_per_epoch: List[float] = []\n        self.history = TrainingHistory(epoch=[], train_loss=[], train_accuracy=[], val_loss=[], val_accuracy=[], grad_norm=[], weight_norm=[])\n        self.converged: bool = False\n        self.stop_reason: str = \"max_epochs\"\n        self.epochs_run: int = 0\n\n    @staticmethod\n    def _as_2d_array(x: np.ndarray) -&gt; np.ndarray:\n        x = np.asarray(x, dtype=np.float64)\n        if x.ndim == 1: x = x.reshape(-1, 1)\n        assert x.ndim == 2\n        return x\n\n    @staticmethod\n    def _normalize_targets(y: np.ndarray) -&gt; Tuple[np.ndarray, int, np.ndarray, str]:\n        y_arr = np.asarray(y)\n        \n        if y_arr.ndim == 2 and y_arr.shape[1] &gt; 1:\n            n_classes = y_arr.shape[1]\n            return y_arr.astype(np.float64), n_classes, np.arange(n_classes), \"multiclass\"\n        \n        y_flat = y_arr.reshape(-1)\n        vals = np.unique(y_flat)\n        \n        if set(vals).issubset({0,1}) and len(vals) &lt;= 2:\n            return y_flat.astype(np.float64).reshape(-1,1), 2, np.array([0,1]), \"binary\"\n        \n        if np.issubdtype(y_flat.dtype, np.integer) and vals.min() &gt;= 0 and (vals == np.arange(vals.max()+1)).all():\n            K = int(vals.max()+1)\n            onehot = np.zeros((y_flat.shape[0], K), dtype=np.float64)\n            onehot[np.arange(y_flat.shape[0]), y_flat.astype(int)] = 1.0\n            return onehot, K, np.arange(K), \"multiclass\"\n        \n        return y_flat.astype(np.float64).reshape(-1,1), 1, np.array([0]), \"continuous\"\n\n    def _init_params(self, layer_sizes: List[int]) -&gt; Dict[str, np.ndarray]:\n        params: Dict[str, np.ndarray] = {}\n        for layer_idx in range(1, len(layer_sizes)):\n            fan_in = layer_sizes[layer_idx-1]\n            fan_out = layer_sizes[layer_idx]\n            fan_in_eff = fan_in + 1 if self.bias_as_weight else fan_in\n\n            if self.weight_init == \"auto\":\n                scale = np.sqrt(2.0/fan_in_eff) if self.activation == \"relu\" else np.sqrt(1.0/fan_in_eff)\n            elif self.weight_init == \"xavier\":\n                scale = np.sqrt(1.0/fan_in_eff)\n            else:\n                scale = np.sqrt(2.0/fan_in_eff)\n\n            W = self.rng.normal(0.0, scale, size=(fan_out, fan_in_eff))\n            params[f\"W{layer_idx}\"] = W\n\n            if not self.bias_as_weight:\n                params[f\"b{layer_idx}\"] = np.zeros((1, fan_out))\n\n        return params\n\n    # -------------------- ativa\u00e7\u00f5es --------------------\n    @staticmethod\n    def _sigmoid(z): return 1.0 / (1.0 + np.exp(-z))\n\n    @staticmethod\n    def _softmax(z):\n        z = z - np.max(z, axis=1, keepdims=True)\n        expz = np.exp(z)\n        return expz / np.sum(expz, axis=1, keepdims=True)\n\n    def _act(self, z):\n        if self.activation == \"relu\":\n            return np.maximum(0, z)\n        \n        if self.activation == \"tanh\":\n            return np.tanh(z)\n        \n        if self.activation == \"sigmoid\":\n            return self._sigmoid(z)\n        \n        return z\n\n    def _act_deriv(self, a, z):\n        if self.activation == \"relu\":\n            return (z &gt; 0).astype(z.dtype)\n        \n        if self.activation == \"tanh\":\n            return 1.0 - a**2\n        \n        if self.activation == \"sigmoid\":\n            return a * (1.0 - a)\n        \n        return np.ones_like(z)\n\n    def _forward(self, X: np.ndarray) -&gt; Tuple[List[np.ndarray], List[np.ndarray]]:\n        activations = [X]\n        preactivations: List[np.ndarray] = []\n        total_layers = len(self.hidden_layer_sizes) + 1\n\n        for layer_idx in range(1, total_layers):\n            A_prev = activations[-1]\n            \n            if self.bias_as_weight:\n                A_prev_aug = np.concatenate([A_prev, np.ones((A_prev.shape[0], 1))], axis=1)\n                z_l = A_prev_aug @ self.params[f\"W{layer_idx}\"].T\n            else:\n                z_l = A_prev @ self.params[f\"W{layer_idx}\"].T + self.params[f\"b{layer_idx}\"]\n            \n            a_l = self._act(z_l)\n            preactivations.append(z_l)\n            activations.append(a_l)\n\n        A_prev = activations[-1]\n\n        if self.bias_as_weight:\n            A_prev_aug = np.concatenate([A_prev, np.ones((A_prev.shape[0], 1))], axis=1)\n            z_out = A_prev_aug @ self.params[f\"W{total_layers}\"].T\n        else:\n            z_out = A_prev @ self.params[f\"W{total_layers}\"].T + self.params[f\"b{total_layers}\"]\n\n        if self.output_activation == \"sigmoid\":\n            a_out = self._sigmoid(z_out)\n\n        elif self.output_activation == \"softmax\":\n            a_out = self._softmax(z_out)\n\n        elif self.output_activation == \"tanh\":\n            a_out = np.tanh(z_out)\n\n        else:\n            a_out = z_out\n\n        preactivations.append(z_out)\n        activations.append(a_out)\n        \n        return preactivations, activations\n\n    def _loss_and_acc(self, Y_true: np.ndarray, Y_hat: np.ndarray) -&gt; Tuple[float, float]:\n        m = Y_true.shape[0]\n        eps = 1e-12\n\n        if self.loss_name == \"bce\":\n            p = np.clip(Y_hat.reshape(-1,1), eps, 1-eps)\n            loss = -(Y_true*np.log(p) + (1-Y_true)*np.log(1-p)).mean()\n\n        elif self.loss_name == \"cce\":\n            p = np.clip(Y_hat, eps, 1-eps)\n            loss = -np.sum(Y_true*np.log(p)) / m\n\n        else:\n            loss = np.mean((Y_true - Y_hat)**2)\n\n        if self.output_activation == \"softmax\":\n            y_pred = np.argmax(Y_hat, axis=1)\n            y_true = np.argmax(Y_true, axis=1)\n            acc = (y_pred == y_true).mean()\n\n        elif self.output_activation == \"sigmoid\":\n            y_pred = (Y_hat.reshape(-1) &gt;= 0.5).astype(int)\n            y_true = Y_true.reshape(-1).astype(int)\n            acc = (y_pred == y_true).mean()\n\n        else:\n            acc = np.nan\n\n        return float(loss), float(acc)\n\n    def _backward(self, preactivations: List[np.ndarray], activations: List[np.ndarray], Y_true: np.ndarray) -&gt; Dict[str, np.ndarray]:\n        grads: Dict[str, np.ndarray] = {}\n        m = Y_true.shape[0]\n        L = len(self.hidden_layer_sizes) + 1\n\n        A_out = activations[-1]\n        Z_out = preactivations[-1]\n        A_prev = activations[-2]\n\n        if self.loss_name == \"bce\" and self.output_activation == \"sigmoid\":\n            dZ = A_out - Y_true\n\n        elif self.loss_name == \"cce\" and self.output_activation == \"softmax\":\n            dZ = A_out - Y_true\n\n        elif self.loss_name == \"mse\":\n            if self.output_activation == \"tanh\":\n                gprime = 1.0 - np.tanh(Z_out)**2\n\n            elif self.output_activation == \"sigmoid\":\n                s = self._sigmoid(Z_out)\n                gprime = s*(1.0 - s)\n\n            else:\n                gprime = np.ones_like(Z_out)\n\n            dZ = 2.0*(A_out - Y_true)*gprime\n\n        else:\n            raise ValueError(\"Combina\u00e7\u00e3o de loss/sa\u00edda n\u00e3o suportada.\")\n\n        if self.bias_as_weight:\n            A_prev_aug = np.concatenate([A_prev, np.ones((m,1))], axis=1)\n            grad_W = (dZ.T @ A_prev_aug) / m\n            grads[f\"W{L}\"] = grad_W\n            dA_prev = dZ @ self.params[f\"W{L}\"][:, :-1]\n        \n        else:\n            grad_W = (dZ.T @ A_prev) / m\n            grad_b = dZ.mean(axis=0, keepdims=True)\n            grads[f\"W{L}\"] = grad_W\n            grads[f\"b{L}\"] = grad_b\n            dA_prev = dZ @ self.params[f\"W{L}\"]\n\n        for layer_idx in range(L-1, 0, -1):\n            Z_l = preactivations[layer_idx-1]\n            A_l = activations[layer_idx]\n            A_prev = activations[layer_idx-1]\n            dG = self._act_deriv(A_l, Z_l)\n            dZ = dA_prev * dG\n\n            if self.bias_as_weight:\n                A_prev_aug = np.concatenate([A_prev, np.ones((m,1))], axis=1)\n                grad_W = (dZ.T @ A_prev_aug) / m\n                grads[f\"W{layer_idx}\"] = grad_W\n                if layer_idx &gt; 1:\n                    dA_prev = dZ @ self.params[f\"W{layer_idx}\"][:, :-1]\n            \n            else:\n                grad_W = (dZ.T @ A_prev) / m\n                grad_b = dZ.mean(axis=0, keepdims=True)\n                grads[f\"W{layer_idx}\"] = grad_W\n                grads[f\"b{layer_idx}\"] = grad_b\n                if layer_idx &gt; 1:\n                    dA_prev = dZ @ self.params[f\"W{layer_idx}\"]\n\n        return grads\n\n    def _update(self, grads: Dict[str, np.ndarray]):\n        total_layers = len(self.hidden_layer_sizes) + 1\n        for layer_idx in range(1, total_layers+1):\n            self.params[f\"W{layer_idx}\"] -= self.eta * grads[f\"W{layer_idx}\"]\n            if not self.bias_as_weight:\n                self.params[f\"b{layer_idx}\"] -= self.eta * grads[f\"b{layer_idx}\"]\n\n    def train(self, patience: Optional[int] = None, min_delta: Optional[float] = None, verbose: bool = False):\n        if patience is None: patience = self.es_patience\n        if min_delta is None: min_delta = self.es_min_delta\n\n        best = np.inf\n        best_params = {k: v.copy() for k, v in self.params.items()}\n        patience_count = 0\n\n        self.loss_per_epoch.clear()\n        self.accuracy_per_epoch.clear()\n        self.val_loss_per_epoch.clear()\n        self.val_accuracy_per_epoch.clear()\n        \n        self.history = TrainingHistory(epoch=[], train_loss=[], train_accuracy=[], val_loss=[], val_accuracy=[], grad_norm=[], weight_norm=[])\n        \n        self.stop_reason = \"max_epochs\"; self.converged = False\n\n        Xtr, Ytr = self.Xtr, self.Ytr\n        for epoch in range(self.max_epochs):\n            idx = self.rng.permutation(len(Xtr))\n            Xs, Ys = Xtr[idx], Ytr[idx]\n\n            grad_norm_total = 0.0\n            for start in range(0, len(Xs), self.batch_size):\n                xb = Xs[start:start+self.batch_size]\n                yb = Ys[start:start+self.batch_size]\n                preacts, acts = self._forward(xb)\n                grads = self._backward(preacts, acts, yb)\n\n                for g in grads.values():\n                    grad_norm_total += float(np.linalg.norm(g))\n                self._update(grads)\n\n            _, act_tr = self._forward(Xtr)\n            loss_tr, acc_tr = self._loss_and_acc(Ytr, act_tr[-1])\n            self.loss_per_epoch.append(loss_tr)\n            self.accuracy_per_epoch.append(acc_tr if not np.isnan(acc_tr) else None)\n\n            if self.Xval is not None:\n                _, act_val = self._forward(self.Xval)\n                loss_val, acc_val = self._loss_and_acc(self.Yval, act_val[-1])\n                self.val_loss_per_epoch.append(loss_val)\n                self.val_accuracy_per_epoch.append(acc_val if not np.isnan(acc_val) else None)\n                monitor = loss_val\n            else:\n                loss_val = None\n                acc_val = None\n                monitor = loss_tr\n\n            weight_norm_total = 0.0\n            total_layers = len(self.hidden_layer_sizes) + 1\n\n            for l in range(1, total_layers+1):\n                W = self.params[f\"W{l}\"]\n                W_use = W[:, :-1] if self.bias_as_weight else W\n                weight_norm_total += float(np.linalg.norm(W_use))\n\n            self.history.epoch.append(epoch+1)\n            self.history.train_loss.append(loss_tr)\n            self.history.train_accuracy.append(acc_tr if not np.isnan(acc_tr) else None)\n            self.history.val_loss.append(loss_val)\n            self.history.val_accuracy.append(acc_val if not np.isnan(acc_val) else None)\n            self.history.grad_norm.append(grad_norm_total)\n            self.history.weight_norm.append(weight_norm_total)\n\n            if monitor + self.es_min_delta &lt; best:\n                best = float(monitor)\n                best_params = {k: v.copy() for k, v in self.params.items()}\n                patience_count = 0\n            else:\n                patience_count += 1\n\n            if verbose:\n                msg = f\"Epoch {epoch+1:4d} | loss={loss_tr:.4f}\"\n                if acc_tr is not None: msg += f\" acc={acc_tr:.3f}\"\n                if loss_val is not None:\n                    msg += f\" | val_loss={loss_val:.4f}\"\n                    if acc_val is not None: msg += f\" val_acc={acc_val:.3f}\"\n                print(msg)\n\n            if patience_count &gt;= self.es_patience:\n                self.stop_reason = f\"No improvement for {self.es_patience} epochs\"\n                break\n\n            self.epochs_run = epoch + 1\n\n        self.params = best_params\n        if patience_count &lt; self.es_patience and self.epochs_run &lt; self.max_epochs:\n            self.converged = True\n            self.stop_reason = \"Early stopping\"\n        elif self.epochs_run == self.max_epochs:\n            self.stop_reason = \"max_epochs\"\n\n    def get_history(self) -&gt; TrainingHistory:\n        return self.history\n\n    def history_as_dict(self) -&gt; Dict[str, list]:\n        return self.history.as_dict()\n\n    def predict_proba(self, X_test: np.ndarray) -&gt; np.ndarray:\n        X = self._as_2d_array(X_test)\n        _, activations = self._forward(X)\n        out = activations[-1]\n        if self.output_activation == \"sigmoid\":\n            return out.reshape(-1)\n        return out\n\n    def predict(self, X_test: np.ndarray, threshold: float = 0.5) -&gt; np.ndarray:\n        proba = self.predict_proba(X_test)\n        if self.output_activation == \"softmax\":\n            return np.argmax(proba, axis=1)\n        if self.output_activation == \"sigmoid\":\n            return (proba &gt;= threshold).astype(int)\n        return proba.reshape(-1)\n\n    def score(self, X_test: np.ndarray, y_test: np.ndarray) -&gt; float:\n        y_true = np.asarray(y_test).reshape(-1)\n        y_pred = self.predict(X_test)\n        \n        if y_pred.ndim == 1 and y_true.ndim == 1:\n            return float((y_pred == y_true).mean())\n        \n        return float('nan')\n</pre> class MLPClassifierScratch:     def __init__(         self,         x: np.ndarray,         y: np.ndarray,         hidden_layer_sizes: Iterable[int] = (16,),         activation: str = \"tanh\",         output_activation: Optional[str] = None,         loss: Optional[str] = None,         eta: float = 0.01,         batch_size: int = 32,         max_epochs: int = 200,         validation_fraction: float = 0.0,         patience: int = 20,         min_delta: float = 1e-4,         seed: int = 42,         weight_init: str = \"auto\",         bias_as_weight: bool = False,     ):         self.X = self._as_2d_array(x)         self.y_input = y         self.n_samples, self.n_features = self.X.shape          self.Y, self.n_classes, self.classes_, self.target_type = self._normalize_targets(y)          self.hidden_layer_sizes = tuple(int(h) for h in hidden_layer_sizes)         self.activation = activation.lower()         assert self.activation in {\"relu\",\"tanh\",\"sigmoid\",\"identity\"}          if output_activation is None:             output_activation = \"sigmoid\" if self.target_type == \"binary\" else (\"softmax\" if self.target_type == \"multiclass\" else \"tanh\")         if loss is None:             loss = \"bce\" if output_activation == \"sigmoid\" else (\"cce\" if output_activation == \"softmax\" else \"mse\")          self.output_activation = output_activation.lower()         assert self.output_activation in {\"sigmoid\",\"softmax\",\"tanh\",\"identity\"}                  self.loss_name = loss.lower()         assert self.loss_name in {\"bce\",\"cce\",\"mse\"}          self.eta = float(eta)         self.batch_size = int(batch_size)         self.max_epochs = int(max_epochs)         self.validation_fraction = float(validation_fraction)         self.es_patience = int(patience)         self.es_min_delta = float(min_delta)         self.seed = int(seed)                  self.weight_init = weight_init.lower()         assert self.weight_init in {\"auto\",\"xavier\",\"he\"}                  self.bias_as_weight = bool(bias_as_weight)          self.rng = np.random.default_rng(self.seed)          if self.validation_fraction &gt; 0.0:             n_val = max(1, int(self.n_samples * self.validation_fraction))             idx = self.rng.permutation(self.n_samples)             val_idx, tr_idx = idx[:n_val], idx[n_val:]             self.Xtr, self.Ytr = self.X[tr_idx], self.Y[tr_idx]             self.Xval, self.Yval = self.X[val_idx], self.Y[val_idx]         else:             self.Xtr, self.Ytr = self.X, self.Y             self.Xval, self.Yval = None, None          out_dim = self.n_classes if self.output_activation == \"softmax\" else 1          if self.loss_name == \"mse\" and self.output_activation in {\"tanh\",\"identity\"} and self.n_classes &gt; 1:             out_dim = self.n_classes          layer_sizes = [self.n_features] + list(self.hidden_layer_sizes) + [out_dim]         self.params = self._init_params(layer_sizes)          self.loss_per_epoch: List[float] = []         self.accuracy_per_epoch: List[float] = []         self.val_loss_per_epoch: List[float] = []         self.val_accuracy_per_epoch: List[float] = []         self.history = TrainingHistory(epoch=[], train_loss=[], train_accuracy=[], val_loss=[], val_accuracy=[], grad_norm=[], weight_norm=[])         self.converged: bool = False         self.stop_reason: str = \"max_epochs\"         self.epochs_run: int = 0      @staticmethod     def _as_2d_array(x: np.ndarray) -&gt; np.ndarray:         x = np.asarray(x, dtype=np.float64)         if x.ndim == 1: x = x.reshape(-1, 1)         assert x.ndim == 2         return x      @staticmethod     def _normalize_targets(y: np.ndarray) -&gt; Tuple[np.ndarray, int, np.ndarray, str]:         y_arr = np.asarray(y)                  if y_arr.ndim == 2 and y_arr.shape[1] &gt; 1:             n_classes = y_arr.shape[1]             return y_arr.astype(np.float64), n_classes, np.arange(n_classes), \"multiclass\"                  y_flat = y_arr.reshape(-1)         vals = np.unique(y_flat)                  if set(vals).issubset({0,1}) and len(vals) &lt;= 2:             return y_flat.astype(np.float64).reshape(-1,1), 2, np.array([0,1]), \"binary\"                  if np.issubdtype(y_flat.dtype, np.integer) and vals.min() &gt;= 0 and (vals == np.arange(vals.max()+1)).all():             K = int(vals.max()+1)             onehot = np.zeros((y_flat.shape[0], K), dtype=np.float64)             onehot[np.arange(y_flat.shape[0]), y_flat.astype(int)] = 1.0             return onehot, K, np.arange(K), \"multiclass\"                  return y_flat.astype(np.float64).reshape(-1,1), 1, np.array([0]), \"continuous\"      def _init_params(self, layer_sizes: List[int]) -&gt; Dict[str, np.ndarray]:         params: Dict[str, np.ndarray] = {}         for layer_idx in range(1, len(layer_sizes)):             fan_in = layer_sizes[layer_idx-1]             fan_out = layer_sizes[layer_idx]             fan_in_eff = fan_in + 1 if self.bias_as_weight else fan_in              if self.weight_init == \"auto\":                 scale = np.sqrt(2.0/fan_in_eff) if self.activation == \"relu\" else np.sqrt(1.0/fan_in_eff)             elif self.weight_init == \"xavier\":                 scale = np.sqrt(1.0/fan_in_eff)             else:                 scale = np.sqrt(2.0/fan_in_eff)              W = self.rng.normal(0.0, scale, size=(fan_out, fan_in_eff))             params[f\"W{layer_idx}\"] = W              if not self.bias_as_weight:                 params[f\"b{layer_idx}\"] = np.zeros((1, fan_out))          return params      # -------------------- ativa\u00e7\u00f5es --------------------     @staticmethod     def _sigmoid(z): return 1.0 / (1.0 + np.exp(-z))      @staticmethod     def _softmax(z):         z = z - np.max(z, axis=1, keepdims=True)         expz = np.exp(z)         return expz / np.sum(expz, axis=1, keepdims=True)      def _act(self, z):         if self.activation == \"relu\":             return np.maximum(0, z)                  if self.activation == \"tanh\":             return np.tanh(z)                  if self.activation == \"sigmoid\":             return self._sigmoid(z)                  return z      def _act_deriv(self, a, z):         if self.activation == \"relu\":             return (z &gt; 0).astype(z.dtype)                  if self.activation == \"tanh\":             return 1.0 - a**2                  if self.activation == \"sigmoid\":             return a * (1.0 - a)                  return np.ones_like(z)      def _forward(self, X: np.ndarray) -&gt; Tuple[List[np.ndarray], List[np.ndarray]]:         activations = [X]         preactivations: List[np.ndarray] = []         total_layers = len(self.hidden_layer_sizes) + 1          for layer_idx in range(1, total_layers):             A_prev = activations[-1]                          if self.bias_as_weight:                 A_prev_aug = np.concatenate([A_prev, np.ones((A_prev.shape[0], 1))], axis=1)                 z_l = A_prev_aug @ self.params[f\"W{layer_idx}\"].T             else:                 z_l = A_prev @ self.params[f\"W{layer_idx}\"].T + self.params[f\"b{layer_idx}\"]                          a_l = self._act(z_l)             preactivations.append(z_l)             activations.append(a_l)          A_prev = activations[-1]          if self.bias_as_weight:             A_prev_aug = np.concatenate([A_prev, np.ones((A_prev.shape[0], 1))], axis=1)             z_out = A_prev_aug @ self.params[f\"W{total_layers}\"].T         else:             z_out = A_prev @ self.params[f\"W{total_layers}\"].T + self.params[f\"b{total_layers}\"]          if self.output_activation == \"sigmoid\":             a_out = self._sigmoid(z_out)          elif self.output_activation == \"softmax\":             a_out = self._softmax(z_out)          elif self.output_activation == \"tanh\":             a_out = np.tanh(z_out)          else:             a_out = z_out          preactivations.append(z_out)         activations.append(a_out)                  return preactivations, activations      def _loss_and_acc(self, Y_true: np.ndarray, Y_hat: np.ndarray) -&gt; Tuple[float, float]:         m = Y_true.shape[0]         eps = 1e-12          if self.loss_name == \"bce\":             p = np.clip(Y_hat.reshape(-1,1), eps, 1-eps)             loss = -(Y_true*np.log(p) + (1-Y_true)*np.log(1-p)).mean()          elif self.loss_name == \"cce\":             p = np.clip(Y_hat, eps, 1-eps)             loss = -np.sum(Y_true*np.log(p)) / m          else:             loss = np.mean((Y_true - Y_hat)**2)          if self.output_activation == \"softmax\":             y_pred = np.argmax(Y_hat, axis=1)             y_true = np.argmax(Y_true, axis=1)             acc = (y_pred == y_true).mean()          elif self.output_activation == \"sigmoid\":             y_pred = (Y_hat.reshape(-1) &gt;= 0.5).astype(int)             y_true = Y_true.reshape(-1).astype(int)             acc = (y_pred == y_true).mean()          else:             acc = np.nan          return float(loss), float(acc)      def _backward(self, preactivations: List[np.ndarray], activations: List[np.ndarray], Y_true: np.ndarray) -&gt; Dict[str, np.ndarray]:         grads: Dict[str, np.ndarray] = {}         m = Y_true.shape[0]         L = len(self.hidden_layer_sizes) + 1          A_out = activations[-1]         Z_out = preactivations[-1]         A_prev = activations[-2]          if self.loss_name == \"bce\" and self.output_activation == \"sigmoid\":             dZ = A_out - Y_true          elif self.loss_name == \"cce\" and self.output_activation == \"softmax\":             dZ = A_out - Y_true          elif self.loss_name == \"mse\":             if self.output_activation == \"tanh\":                 gprime = 1.0 - np.tanh(Z_out)**2              elif self.output_activation == \"sigmoid\":                 s = self._sigmoid(Z_out)                 gprime = s*(1.0 - s)              else:                 gprime = np.ones_like(Z_out)              dZ = 2.0*(A_out - Y_true)*gprime          else:             raise ValueError(\"Combina\u00e7\u00e3o de loss/sa\u00edda n\u00e3o suportada.\")          if self.bias_as_weight:             A_prev_aug = np.concatenate([A_prev, np.ones((m,1))], axis=1)             grad_W = (dZ.T @ A_prev_aug) / m             grads[f\"W{L}\"] = grad_W             dA_prev = dZ @ self.params[f\"W{L}\"][:, :-1]                  else:             grad_W = (dZ.T @ A_prev) / m             grad_b = dZ.mean(axis=0, keepdims=True)             grads[f\"W{L}\"] = grad_W             grads[f\"b{L}\"] = grad_b             dA_prev = dZ @ self.params[f\"W{L}\"]          for layer_idx in range(L-1, 0, -1):             Z_l = preactivations[layer_idx-1]             A_l = activations[layer_idx]             A_prev = activations[layer_idx-1]             dG = self._act_deriv(A_l, Z_l)             dZ = dA_prev * dG              if self.bias_as_weight:                 A_prev_aug = np.concatenate([A_prev, np.ones((m,1))], axis=1)                 grad_W = (dZ.T @ A_prev_aug) / m                 grads[f\"W{layer_idx}\"] = grad_W                 if layer_idx &gt; 1:                     dA_prev = dZ @ self.params[f\"W{layer_idx}\"][:, :-1]                          else:                 grad_W = (dZ.T @ A_prev) / m                 grad_b = dZ.mean(axis=0, keepdims=True)                 grads[f\"W{layer_idx}\"] = grad_W                 grads[f\"b{layer_idx}\"] = grad_b                 if layer_idx &gt; 1:                     dA_prev = dZ @ self.params[f\"W{layer_idx}\"]          return grads      def _update(self, grads: Dict[str, np.ndarray]):         total_layers = len(self.hidden_layer_sizes) + 1         for layer_idx in range(1, total_layers+1):             self.params[f\"W{layer_idx}\"] -= self.eta * grads[f\"W{layer_idx}\"]             if not self.bias_as_weight:                 self.params[f\"b{layer_idx}\"] -= self.eta * grads[f\"b{layer_idx}\"]      def train(self, patience: Optional[int] = None, min_delta: Optional[float] = None, verbose: bool = False):         if patience is None: patience = self.es_patience         if min_delta is None: min_delta = self.es_min_delta          best = np.inf         best_params = {k: v.copy() for k, v in self.params.items()}         patience_count = 0          self.loss_per_epoch.clear()         self.accuracy_per_epoch.clear()         self.val_loss_per_epoch.clear()         self.val_accuracy_per_epoch.clear()                  self.history = TrainingHistory(epoch=[], train_loss=[], train_accuracy=[], val_loss=[], val_accuracy=[], grad_norm=[], weight_norm=[])                  self.stop_reason = \"max_epochs\"; self.converged = False          Xtr, Ytr = self.Xtr, self.Ytr         for epoch in range(self.max_epochs):             idx = self.rng.permutation(len(Xtr))             Xs, Ys = Xtr[idx], Ytr[idx]              grad_norm_total = 0.0             for start in range(0, len(Xs), self.batch_size):                 xb = Xs[start:start+self.batch_size]                 yb = Ys[start:start+self.batch_size]                 preacts, acts = self._forward(xb)                 grads = self._backward(preacts, acts, yb)                  for g in grads.values():                     grad_norm_total += float(np.linalg.norm(g))                 self._update(grads)              _, act_tr = self._forward(Xtr)             loss_tr, acc_tr = self._loss_and_acc(Ytr, act_tr[-1])             self.loss_per_epoch.append(loss_tr)             self.accuracy_per_epoch.append(acc_tr if not np.isnan(acc_tr) else None)              if self.Xval is not None:                 _, act_val = self._forward(self.Xval)                 loss_val, acc_val = self._loss_and_acc(self.Yval, act_val[-1])                 self.val_loss_per_epoch.append(loss_val)                 self.val_accuracy_per_epoch.append(acc_val if not np.isnan(acc_val) else None)                 monitor = loss_val             else:                 loss_val = None                 acc_val = None                 monitor = loss_tr              weight_norm_total = 0.0             total_layers = len(self.hidden_layer_sizes) + 1              for l in range(1, total_layers+1):                 W = self.params[f\"W{l}\"]                 W_use = W[:, :-1] if self.bias_as_weight else W                 weight_norm_total += float(np.linalg.norm(W_use))              self.history.epoch.append(epoch+1)             self.history.train_loss.append(loss_tr)             self.history.train_accuracy.append(acc_tr if not np.isnan(acc_tr) else None)             self.history.val_loss.append(loss_val)             self.history.val_accuracy.append(acc_val if not np.isnan(acc_val) else None)             self.history.grad_norm.append(grad_norm_total)             self.history.weight_norm.append(weight_norm_total)              if monitor + self.es_min_delta &lt; best:                 best = float(monitor)                 best_params = {k: v.copy() for k, v in self.params.items()}                 patience_count = 0             else:                 patience_count += 1              if verbose:                 msg = f\"Epoch {epoch+1:4d} | loss={loss_tr:.4f}\"                 if acc_tr is not None: msg += f\" acc={acc_tr:.3f}\"                 if loss_val is not None:                     msg += f\" | val_loss={loss_val:.4f}\"                     if acc_val is not None: msg += f\" val_acc={acc_val:.3f}\"                 print(msg)              if patience_count &gt;= self.es_patience:                 self.stop_reason = f\"No improvement for {self.es_patience} epochs\"                 break              self.epochs_run = epoch + 1          self.params = best_params         if patience_count &lt; self.es_patience and self.epochs_run &lt; self.max_epochs:             self.converged = True             self.stop_reason = \"Early stopping\"         elif self.epochs_run == self.max_epochs:             self.stop_reason = \"max_epochs\"      def get_history(self) -&gt; TrainingHistory:         return self.history      def history_as_dict(self) -&gt; Dict[str, list]:         return self.history.as_dict()      def predict_proba(self, X_test: np.ndarray) -&gt; np.ndarray:         X = self._as_2d_array(X_test)         _, activations = self._forward(X)         out = activations[-1]         if self.output_activation == \"sigmoid\":             return out.reshape(-1)         return out      def predict(self, X_test: np.ndarray, threshold: float = 0.5) -&gt; np.ndarray:         proba = self.predict_proba(X_test)         if self.output_activation == \"softmax\":             return np.argmax(proba, axis=1)         if self.output_activation == \"sigmoid\":             return (proba &gt;= threshold).astype(int)         return proba.reshape(-1)      def score(self, X_test: np.ndarray, y_test: np.ndarray) -&gt; float:         y_true = np.asarray(y_test).reshape(-1)         y_pred = self.predict(X_test)                  if y_pred.ndim == 1 and y_true.ndim == 1:             return float((y_pred == y_true).mean())                  return float('nan')"},{"location":"exercicios/perceptron/perceptron/","title":"Perceptron","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nRANDOM_SEED = 42\nN = 1000\nnp.random.seed(RANDOM_SEED)\nclasses = [0, 1]\n\nmean = [[1.5,1.5], [5,5]]\nsigma = [\n    [\n        [0.5,0],\n        [0,0.5],\n    ],\n    [\n        [0.5,0],\n        [0,0.5],\n    ]\n]\n\nlabel_features = []\nlabel_class = []\n\nfor classe in classes:\n    features = np.random.multivariate_normal(mean[classe], sigma[classe], size=N)\n\n    label_features.append(features)\n    label_class.append([classe] * N)\n</pre> import numpy as np RANDOM_SEED = 42 N = 1000 np.random.seed(RANDOM_SEED) classes = [0, 1]  mean = [[1.5,1.5], [5,5]] sigma = [     [         [0.5,0],         [0,0.5],     ],     [         [0.5,0],         [0,0.5],     ] ]  label_features = [] label_class = []  for classe in classes:     features = np.random.multivariate_normal(mean[classe], sigma[classe], size=N)      label_features.append(features)     label_class.append([classe] * N) <p>Utilizando a biblioteca Matplotlib.PyPlot para visualizar como ficaram as distribui\u00e7\u00f5es de cada uma das classes, podemos observar:</p> In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\n\nplt.scatter(label_features[0][:,0], label_features[0][:,1], label='0', alpha=0.6)\nplt.scatter(label_features[1][:,0], label_features[1][:,1], label='1', alpha=0.6)\nplt.title('Distribui\u00e7\u00e3o das Classes 0 e 1')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.legend()\nplt.show()\n</pre> import matplotlib.pyplot as plt  plt.scatter(label_features[0][:,0], label_features[0][:,1], label='0', alpha=0.6) plt.scatter(label_features[1][:,0], label_features[1][:,1], label='1', alpha=0.6) plt.title('Distribui\u00e7\u00e3o das Classes 0 e 1') plt.xlabel('X') plt.ylabel('Y') plt.legend() plt.show() <p>Analisando o gr\u00e1fico, \u00e9 facilmente precept\u00edvel que as classes 0 e 1 s\u00e3o pass\u00edveis de serem separadas por uma linha reta. N\u00e3o \u00e9 observada uma sobreposi\u00e7\u00e3o dos dados, o que torna poss\u00edvel uma solu\u00e7\u00e3o linear para a separa\u00e7\u00e3o. At\u00e9 existem alguns pontos das classes bem pr\u00f3ximos um do outro, por\u00e9m nada que impossibilite a solu\u00e7ao linear.</p> <p>Para a implementa\u00e7\u00e3o do algoritmo de Perceptron, foi necess\u00e1rio agrupar ambas as classes em um vetor s\u00f3, tanto para as vari\u00e1veis independentes, como para a vari\u00e1vel dependente. Essa manipula\u00e7\u00e3o foi feita utilizando a biblioteca NumPy.</p> In\u00a0[3]: Copied! <pre>X = np.vstack(label_features)\ny = np.hstack(label_class)\n</pre> X = np.vstack(label_features) y = np.hstack(label_class) <p>Uma vez que Perceptron \u00e9 um modelo que necessita de treinamento, como todo processo de treino e teste do modelo, \u00e9 importante separar o dataset de implementa\u00e7\u00e3o entre amostras de treino e teste, evitando overfitting. Para isso, foi utilizada a fun\u00e7\u00e3o <code>train_test_split</code> da biblioteca Scikit-Learn, que separa essas amostras com o cuidado de n\u00e3o embaralhar os pares (X,y) de cada observa\u00e7\u00e3o, o que tornaria completamente inv\u00e1lidas as amostras.</p> In\u00a0[4]: Copied! <pre>from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.3,\n    random_state=RANDOM_SEED,\n    shuffle=True\n)\n</pre> from sklearn.model_selection import train_test_split  X_train, X_test, y_train, y_test = train_test_split(     X, y,     test_size=0.3,     random_state=RANDOM_SEED,     shuffle=True ) <p>Com rela\u00e7\u00e3o especificamente ao algoritmo Perceptron, o que foi feito aqui \u00e9 uma implementa\u00e7\u00e3o desse algoritmo matem\u00e1tico a partir de uma classe. Existem implementa\u00e7\u00f5es do mesmo algoritmo prontas em bibliotecas famosas, como a Scikit-Learn <code>sklearn.linear_model.Perceptron()</code>. No entanto, como j\u00e1 apresentado, a ideia desse projeto como um todo \u00e9 explorar o funcionamento base de uma rede neural, para entendimento completo do modelo, e tamb\u00e9m, aprendizado de implementa\u00e7\u00e3o de linguagem de programa\u00e7\u00e3o. Por isso, foi constru\u00edda a seguinte classe:</p> In\u00a0[5]: Copied! <pre>np.random.seed(RANDOM_SEED)\n\nclass Perceptron:\n    def __init__(\n        self,\n        x,\n        y,\n        weights=None,\n        bias=None,\n        eta: float = 0.01,\n        att_bias: bool = False,\n        max_epochs: int = 100\n    ):\n        self.x = x\n        self.y = y\n        \n        n_features = x.shape[1]\n\n        if weights is None:\n            self.weights = np.random.random(n_features)\n        else:\n            self.weights = weights\n\n        if bias is None:\n            self.bias = np.random.random()\n        else:\n            self.bias = bias\n        \n        self.eta = eta\n        self.att_bias = att_bias\n        self.max_epochs = max_epochs\n\n        self.accuracy_per_epoch = []\n        self.updates_per_epoch = []\n        self.converged = False\n        self.epochs_run = 0\n\n    def train(self, use_patience: bool = True, patience: int = 10, min_delta: int = 0):\n        best_updates = np.inf\n        best_weights = self.weights.copy()\n        best_bias = float(self.bias)\n        patience_count = 0\n        early_stopped = False\n\n        self.stop_reason = \"max_epochs\"\n        self.converged = False\n        self.accuracy_per_epoch = []\n        self.updates_per_epoch = []\n\n        for epoch in range(self.max_epochs):\n            updates = 0\n\n            indices = np.random.permutation(len(self.x))\n            x_shuffled = self.x[indices]\n            y_shuffled = self.y[indices]\n\n            for x_i, y_i in zip(x_shuffled, y_shuffled):\n                y_pred = 1 if (np.dot(x_i, self.weights) + self.bias) &gt;= 0 else 0\n                error = y_i - y_pred\n                if error != 0:\n                    updates += 1\n                    self._rebalance(x=x_i, error=error)\n\n            acc = 1.0 - (updates / len(self.y))\n            self.accuracy_per_epoch.append(acc)\n            self.updates_per_epoch.append(updates)\n            self.epochs_run = epoch + 1\n\n            if updates == 0:\n                self.converged = True\n                self.stop_reason = \"Sem erros (linearmente separ\u00e1vel)\"\n                best_updates = 0\n                best_weights = self.weights.copy()\n                best_bias = float(self.bias)\n                break\n\n            if use_patience:\n                improvement = best_updates - updates\n                if improvement &gt;= min_delta:\n                    best_updates = updates\n                    best_weights = self.weights.copy()\n                    best_bias = float(self.bias)\n                    patience_count = 0\n                else:\n                    patience_count += 1\n                    if patience_count &gt;= patience:\n                        self.stop_reason = (\n                            f\"Parada adiantada (sem melhora \u2265 {min_delta} por {patience} \u00e9pocas)\"\n                        )\n                        early_stopped = True\n                        break\n\n        if use_patience and early_stopped and best_updates &lt; np.inf:\n            self.weights = best_weights\n            self.bias = best_bias\n    \n    def predict(self, X_test=None, y_test=None):\n        if X_test is None:\n            raise ValueError(\"Entre com o X_test\")\n\n        scores = X_test @ self.weights + self.bias\n        y_pred = (scores &gt;= 0).astype(int)\n\n        if y_test is not None:\n            acc = (y_pred == y_test).mean()\n            return y_pred, acc\n        return y_pred\n\n    def _rebalance(self, x, error):\n        if error != 0:\n            self.weights += self.eta * error * x\n            if self.att_bias:\n                self.bias += self.eta * error\n</pre> np.random.seed(RANDOM_SEED)  class Perceptron:     def __init__(         self,         x,         y,         weights=None,         bias=None,         eta: float = 0.01,         att_bias: bool = False,         max_epochs: int = 100     ):         self.x = x         self.y = y                  n_features = x.shape[1]          if weights is None:             self.weights = np.random.random(n_features)         else:             self.weights = weights          if bias is None:             self.bias = np.random.random()         else:             self.bias = bias                  self.eta = eta         self.att_bias = att_bias         self.max_epochs = max_epochs          self.accuracy_per_epoch = []         self.updates_per_epoch = []         self.converged = False         self.epochs_run = 0      def train(self, use_patience: bool = True, patience: int = 10, min_delta: int = 0):         best_updates = np.inf         best_weights = self.weights.copy()         best_bias = float(self.bias)         patience_count = 0         early_stopped = False          self.stop_reason = \"max_epochs\"         self.converged = False         self.accuracy_per_epoch = []         self.updates_per_epoch = []          for epoch in range(self.max_epochs):             updates = 0              indices = np.random.permutation(len(self.x))             x_shuffled = self.x[indices]             y_shuffled = self.y[indices]              for x_i, y_i in zip(x_shuffled, y_shuffled):                 y_pred = 1 if (np.dot(x_i, self.weights) + self.bias) &gt;= 0 else 0                 error = y_i - y_pred                 if error != 0:                     updates += 1                     self._rebalance(x=x_i, error=error)              acc = 1.0 - (updates / len(self.y))             self.accuracy_per_epoch.append(acc)             self.updates_per_epoch.append(updates)             self.epochs_run = epoch + 1              if updates == 0:                 self.converged = True                 self.stop_reason = \"Sem erros (linearmente separ\u00e1vel)\"                 best_updates = 0                 best_weights = self.weights.copy()                 best_bias = float(self.bias)                 break              if use_patience:                 improvement = best_updates - updates                 if improvement &gt;= min_delta:                     best_updates = updates                     best_weights = self.weights.copy()                     best_bias = float(self.bias)                     patience_count = 0                 else:                     patience_count += 1                     if patience_count &gt;= patience:                         self.stop_reason = (                             f\"Parada adiantada (sem melhora \u2265 {min_delta} por {patience} \u00e9pocas)\"                         )                         early_stopped = True                         break          if use_patience and early_stopped and best_updates &lt; np.inf:             self.weights = best_weights             self.bias = best_bias          def predict(self, X_test=None, y_test=None):         if X_test is None:             raise ValueError(\"Entre com o X_test\")          scores = X_test @ self.weights + self.bias         y_pred = (scores &gt;= 0).astype(int)          if y_test is not None:             acc = (y_pred == y_test).mean()             return y_pred, acc         return y_pred      def _rebalance(self, x, error):         if error != 0:             self.weights += self.eta * error * x             if self.att_bias:                 self.bias += self.eta * error <p>De modo geral, o funcionamento do Perceptron nada mais \u00e9 do que um modelo linear como a Regress\u00e3o Linear. Existem as vari\u00e1veis de entrada, independentes (features) e a vari\u00e1vel de sa\u00edda, dependente (target). Para cada feature utilizada na entrada do perceptron, um peso \u00e9 criado para ela dentro do modelo. Al\u00e9m dos pesos das features, o modelo tamb\u00e9m possui um bias, ou seja, um peso que ajusta de certa forma o resultado linear dos pesos e features. Para cada observa\u00e7\u00e3o apresentada para o algoritmo, esse faz um produto linear entre as vari\u00e1veis independentes e os pesos, e soma o bias. Ap\u00f3s isso, ele compara o resultado encontrado, com o esperado no target, e a partir disso, atualiza os pesos buscando reduzir o erro em uma pr\u00f3xima exposi\u00e7\u00e3o a uma observa\u00e7\u00e3o.</p> <p>O formato de atualiza\u00e7\u00e3o dos pesos, no modelo de Percetron, possui uma peculiaridade, pois a atualiza\u00e7\u00e3o dos seus pesos n\u00e3o necessariamente busca a equidade entre o target previsto e o target esperado naquela observa\u00e7\u00e3o, uma vez que os pesos s\u00e3o ponderados/atualizados tanto baseados no erro calculado, como tamb\u00e9m em um hiperpar\u00e2metro, a taxa de aprendizado (\u03b7). A atualiza\u00e7\u00e3o dos pesos de acordo com o erro encontrado em uma determinada observa\u00e7\u00e3o \u00e9 atualizado por:</p> <p>$$ \\mathbf{w} \\leftarrow \\mathbf{w} + \\eta \\cdot \\text{error} \\cdot \\mathbf{x}^{(i)} $$</p> <p>$$ b \\leftarrow b + \\eta \\cdot \\text{error} $$</p> <p>Ap\u00f3s o treinamento com observa\u00e7\u00e3o, outra \u00e9 submetida para predi\u00e7\u00e3o, e assim \u00e9 percorrida toda a amostra de treinamento dispon\u00edvel. Ao acabar o conjunto de treinamento, esse tem a ordem das observa\u00e7\u00f5es embaralhada, e uma nova \u00e9poca de treinamento \u00e9 iniciada. Ou seja, a cada passagem completa pelo conjunto de treinamento, \u00e9 contabilizada o que \u00e9 denominado \u00e9poca.</p> <p>Com rela\u00e7\u00e3o ao crit\u00e9rio de parada do treinamento, esse pode ser feito de duas formas: uma sendo quando o modelo convergir no conjunto de treinamento, isto \u00e9, quando o modelo passar por uma \u00e9poca inteira e n\u00e3o tiver nenhuma atualiza\u00e7\u00e3o dos pessos, uma vez que ele previu todos os targets corretamente; a outra forma \u00e9 estabelecendo um crit\u00e9rio de parada arbitr\u00e1rio. No primeiro caso analisado, o conjunto de dados \u00e9 linearmente separ\u00e1vel, logo, o modelo converge no conjunto de treinamento, parando esse. No entanto, no segundo momento de an\u00e1lise, quando foi aplicado o modelo sobre um conjunto de dados imposs\u00edvel de ser separado de forma linear, foi necess\u00e1rio implementar um m\u00e9todo de decis\u00e3o de parada no treinamento. A classe apresentada conta com o m\u00e9todo conhecido como patience. Nesse esquema, define-se um n\u00famero $K$ de \u00e9pocas de \u201cpaci\u00eancia\u201d e uma m\u00e9trica de melhoria, por exemplo, menor n\u00famero de atualiza\u00e7\u00f5es na \u00e9poca. A cada \u00e9poca sem melhoria, incrementa-se um contador; quando h\u00e1 melhoria, o contador \u00e9 zerado. O treinamento \u00e9 interrompido ao atingir $K$ \u00e9pocas sem avan\u00e7o.</p> In\u00a0[6]: Copied! <pre>np.random.seed(RANDOM_SEED)\nweights = np.random.random(2)\nbias = np.random.random(1)\n\nprint(f\"Initial weights: {weights}\")\nprint(f\"Initial bias: {bias}\")\n</pre> np.random.seed(RANDOM_SEED) weights = np.random.random(2) bias = np.random.random(1)  print(f\"Initial weights: {weights}\") print(f\"Initial bias: {bias}\") <pre>Initial weights: [0.37454012 0.95071431]\nInitial bias: [0.73199394]\n</pre> <p>Aqui ent\u00e3o, foram sorteados dois pesos, por conta da distribui\u00e7\u00e3o utilizada, possuir 2 dimens\u00f5es, e tamb\u00e9m um bias. Novamente, foi utilizada a seed (42).</p> In\u00a0[7]: Copied! <pre>import warnings\nwarnings.simplefilter(\"ignore\", DeprecationWarning)\nnp.random.seed(RANDOM_SEED)\n\nprcpt_linear = Perceptron(x=X_train, y=y_train, weights=weights, bias=bias, eta=0.01, att_bias=True)\nprcpt_linear.train()\n\nprint(\"Convergiu:\", prcpt_linear.converged)\nprint(\"\u00c9pocas:\", prcpt_linear.epochs_run)\nprint(\"Acur\u00e1cia por \u00e9poca:\", prcpt_linear.accuracy_per_epoch)\nprint(\"Atualiza\u00e7\u00f5es por \u00e9poca:\", prcpt_linear.updates_per_epoch)\n</pre> import warnings warnings.simplefilter(\"ignore\", DeprecationWarning) np.random.seed(RANDOM_SEED)  prcpt_linear = Perceptron(x=X_train, y=y_train, weights=weights, bias=bias, eta=0.01, att_bias=True) prcpt_linear.train()  print(\"Convergiu:\", prcpt_linear.converged) print(\"\u00c9pocas:\", prcpt_linear.epochs_run) print(\"Acur\u00e1cia por \u00e9poca:\", prcpt_linear.accuracy_per_epoch) print(\"Atualiza\u00e7\u00f5es por \u00e9poca:\", prcpt_linear.updates_per_epoch) <pre>Convergiu: True\n\u00c9pocas: 3\nAcur\u00e1cia por \u00e9poca: [0.8821428571428571, 0.9885714285714285, 1.0]\nAtualiza\u00e7\u00f5es por \u00e9poca: [165, 16, 0]\n</pre> <p>Ao inicializar a classe do Perceptron com o conjunto de treinamento e os pesos sorteados, o m\u00e9todo de <code>.train()</code> executa o passo a passo de treinamento explicado anteriormente. Como era esperado, nessa distribui\u00e7\u00e3o o modelo convergiu e convergiu r\u00e1pido. Ap\u00f3s 2 \u00e9pocas de treinamento, o modelo j\u00e1 estava acertando todos os targets. Ao aplicar esse modelo treinado no dataset como um todo, foi obtida uma acur\u00e1cia de 99,9% o que \u00e9 muito bom, por\u00e9m de certa forma pode apresentar um certo overfitting.</p> In\u00a0[8]: Copied! <pre>y_pred_full, acc_full = prcpt_linear.predict(X_test=X, y_test=y)\nprint(f\"Acur\u00e1cia no dataset completo: {acc_full * 100:.4f}%\")\n</pre> y_pred_full, acc_full = prcpt_linear.predict(X_test=X, y_test=y) print(f\"Acur\u00e1cia no dataset completo: {acc_full * 100:.4f}%\") <pre>Acur\u00e1cia no dataset completo: 99.9000%\n</pre> <p>Al\u00e9m de analisar a acur\u00e1cia, pode-se observar como os dados est\u00e3o sendo separados literalmente pela linha formada pelos pesos do modelo.</p> In\u00a0[9]: Copied! <pre>w = prcpt_linear.weights\nb = float(np.squeeze(prcpt_linear.bias))\n\nx_min = X[:, 0].min() - 0.5\nx_max = X[:, 0].max() + 0.5\nxs = np.linspace(x_min, x_max, 400)\n</pre> w = prcpt_linear.weights b = float(np.squeeze(prcpt_linear.bias))  x_min = X[:, 0].min() - 0.5 x_max = X[:, 0].max() + 0.5 xs = np.linspace(x_min, x_max, 400) In\u00a0[10]: Copied! <pre>plt.figure(figsize=(7, 6))\n\nif abs(w[1]) &gt; 1e-12:\n    ys = -(w[0] / w[1]) * xs - b / w[1]\n    plt.plot(xs, ys, '--', linewidth=2, label=\"Fronteira de decis\u00e3o\", c='black')\nelse:\n    x_v = -b / w[0]\n    plt.axvline(x_v, linewidth=2, label=\"Fronteira de decis\u00e3o\", c='black', linestyle='--')\n\nmis = (y_pred_full != y)\n\nplt.scatter(\n    X[~mis, 0], X[~mis, 1],\n    c=y[~mis],\n    cmap=plt.get_cmap(\"tab10\", 2),\n    marker=\"o\", s=40, alpha=0.6,\n    label=\"Corretos\"\n)\n\nplt.scatter(\n    X[mis, 0], X[mis, 1],\n    c=y[mis],\n    cmap=plt.get_cmap(\"tab10\", 2),\n    marker=\"x\", s=70, alpha=0.9,\n    label=\"Misclass\"\n)\n\nplt.title(f\"Perceptron \u2014 Fronteira e pontos lineares (acc={acc_full:.4f})\")\nplt.xlabel(\"X1\")\nplt.ylabel(\"X2\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> plt.figure(figsize=(7, 6))  if abs(w[1]) &gt; 1e-12:     ys = -(w[0] / w[1]) * xs - b / w[1]     plt.plot(xs, ys, '--', linewidth=2, label=\"Fronteira de decis\u00e3o\", c='black') else:     x_v = -b / w[0]     plt.axvline(x_v, linewidth=2, label=\"Fronteira de decis\u00e3o\", c='black', linestyle='--')  mis = (y_pred_full != y)  plt.scatter(     X[~mis, 0], X[~mis, 1],     c=y[~mis],     cmap=plt.get_cmap(\"tab10\", 2),     marker=\"o\", s=40, alpha=0.6,     label=\"Corretos\" )  plt.scatter(     X[mis, 0], X[mis, 1],     c=y[mis],     cmap=plt.get_cmap(\"tab10\", 2),     marker=\"x\", s=70, alpha=0.9,     label=\"Misclass\" )  plt.title(f\"Perceptron \u2014 Fronteira e pontos lineares (acc={acc_full:.4f})\") plt.xlabel(\"X1\") plt.ylabel(\"X2\") plt.legend() plt.tight_layout() plt.show() In\u00a0[11]: Copied! <pre>plt.figure(figsize=(6, 4))\nplt.plot(np.arange(1, prcpt_linear.epochs_run + 1), prcpt_linear.accuracy_per_epoch, linewidth=2)\nplt.xlabel(\"\u00c9poca\")\nplt.ylabel(\"Acur\u00e1cia (treino)\")\nplt.title(\"Acur\u00e1cia por \u00e9poca\")\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n</pre> plt.figure(figsize=(6, 4)) plt.plot(np.arange(1, prcpt_linear.epochs_run + 1), prcpt_linear.accuracy_per_epoch, linewidth=2) plt.xlabel(\"\u00c9poca\") plt.ylabel(\"Acur\u00e1cia (treino)\") plt.title(\"Acur\u00e1cia por \u00e9poca\") plt.grid(True, alpha=0.3) plt.tight_layout() plt.show() <p>Pela an\u00e1lise gr\u00e1fica, \u00e9 poss\u00edvel compreender que apenas dois pontos foram classificados de forma errada, e como j\u00e1 era previsto, os dados eram poss\u00edveis de serem separados linearmente. Por fatos como esse que \u00e9 poss\u00edvel explicar o modelo alcan\u00e7ar uma taxa de erro zero no conjunto de treinamento t\u00e3o r\u00e1pido, apenas duas \u00e9pocas de treinamento. Essa facilidade e taxa alta de acerto no conjunto de dados como um todo n\u00e3o \u00e9 observado em distribui\u00e7\u00f5es de dados mais complexas. \u00c9 nessa condi\u00e7\u00e3o que a pr\u00f3xima an\u00e1lise trabalha.</p> In\u00a0[12]: Copied! <pre>np.random.seed(RANDOM_SEED)\nclasses = [0, 1]\n\nmean = [[3,3], [4,4]]\nsigma = [\n    [\n        [1.5,0],\n        [0,1.5],\n    ],\n    [\n        [1.5,0],\n        [0,1.5],\n    ]\n]\n\nlabel_features_non_linear = []\nlabel_class_non_linear = []\n\nfor classe in classes:\n    features = np.random.multivariate_normal(mean[classe], sigma[classe], size=N)\n\n    label_features_non_linear.append(features)\n    label_class_non_linear.append([classe] * N)\n</pre> np.random.seed(RANDOM_SEED) classes = [0, 1]  mean = [[3,3], [4,4]] sigma = [     [         [1.5,0],         [0,1.5],     ],     [         [1.5,0],         [0,1.5],     ] ]  label_features_non_linear = [] label_class_non_linear = []  for classe in classes:     features = np.random.multivariate_normal(mean[classe], sigma[classe], size=N)      label_features_non_linear.append(features)     label_class_non_linear.append([classe] * N) <p>Utilizando a biblioteca Matplotlib.PyPlot para visualizar como ficaram as distribui\u00e7\u00f5es de cada uma das classes, podemos observar:</p> In\u00a0[13]: Copied! <pre>plt.scatter(label_features_non_linear[0][:,0], label_features_non_linear[0][:,1], label='0', alpha=.6)\nplt.scatter(label_features_non_linear[1][:,0], label_features_non_linear[1][:,1], label='1', alpha=.6)\nplt.title('Distribui\u00e7\u00e3o das Classes 0 e 1')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.legend()\nplt.show()\n</pre> plt.scatter(label_features_non_linear[0][:,0], label_features_non_linear[0][:,1], label='0', alpha=.6) plt.scatter(label_features_non_linear[1][:,0], label_features_non_linear[1][:,1], label='1', alpha=.6) plt.title('Distribui\u00e7\u00e3o das Classes 0 e 1') plt.xlabel('X') plt.ylabel('Y') plt.legend() plt.show() <p>Analisando o gr\u00e1fico, fica claro que nesse segundo caso as classes est\u00e3o completamente sobrepostas, inviabilizando a separa\u00e7\u00e3o puramente linear. Por esse fato que o m\u00e9todo de parada no treinamento do algoritmo Perceptron foi necess\u00e1rio. Novamente para implementa\u00e7\u00e3o \u00e9 necess\u00e1rio agrupar as classes.</p> In\u00a0[14]: Copied! <pre>X_non_linear = np.vstack(label_features_non_linear)\ny_non_linear = np.hstack(label_class_non_linear)\n</pre> X_non_linear = np.vstack(label_features_non_linear) y_non_linear = np.hstack(label_class_non_linear) <p>Foi feita da mesma forma a separa\u00e7\u00e3o dos conjuntos de treino e teste, justamente para ser poss\u00edvel a compara\u00e7\u00e3o dos desempenhos.</p> In\u00a0[15]: Copied! <pre>X_train_non_linear, X_test_non_linear, y_train_non_linear, y_test_non_linear = train_test_split(\n    X_non_linear, y_non_linear,\n    test_size=0.3,\n    random_state=RANDOM_SEED,\n    shuffle=True\n)\n</pre> X_train_non_linear, X_test_non_linear, y_train_non_linear, y_test_non_linear = train_test_split(     X_non_linear, y_non_linear,     test_size=0.3,     random_state=RANDOM_SEED,     shuffle=True )  <p>Na gera\u00e7\u00e3o dos pesos, foi utilizada a mesma seed, logo era de se esperar que os pesos iniciais em ambos os modelos fosse id\u00eanticos, incluindo o bias.</p> In\u00a0[16]: Copied! <pre>np.random.seed(RANDOM_SEED)\nweights = np.random.random(2)\nbias = np.random.random(1)\n\nprint(f\"Initial weights: {weights}\")\nprint(f\"Initial bias: {bias}\")\n</pre> np.random.seed(RANDOM_SEED) weights = np.random.random(2) bias = np.random.random(1)  print(f\"Initial weights: {weights}\") print(f\"Initial bias: {bias}\") <pre>Initial weights: [0.37454012 0.95071431]\nInitial bias: [0.73199394]\n</pre> <p>Como j\u00e1 discutido no gr\u00e1fico, os dados s\u00e3o imposs\u00edveis de serem separados de forma linear, e portanto, caso o modelo seja treinado sem um m\u00e9todo de parada antecipada, ele vai percorrer as 100 \u00e9pocas de limite e pausar o treinamento sem convergir. Isto pois, em nenhum momento ele vai percorrer uma \u00e9poca inteira sem errar.</p> In\u00a0[17]: Copied! <pre>import warnings\nwarnings.simplefilter(\"ignore\", DeprecationWarning)\nnp.random.seed(RANDOM_SEED)\n\nprcpt_non_linear_1 = Perceptron(x=X_train_non_linear, y=y_train_non_linear, weights=weights, bias=bias, eta=0.01, att_bias=True)\nprcpt_non_linear_1.train(use_patience=False)\n\nprint(\"Convergiu:\", prcpt_non_linear_1.converged)\nprint(\"\u00c9pocas:\", prcpt_non_linear_1.epochs_run)\n\nif not prcpt_non_linear_1.converged:\n    print(prcpt_non_linear_1.stop_reason)\n\nprint(\"Acur\u00e1cia por \u00c9poca:\", prcpt_non_linear_1.accuracy_per_epoch)\nprint(\"Atualiza\u00e7\u00f5es por \u00c9poca:\", prcpt_non_linear_1.updates_per_epoch)\n</pre> import warnings warnings.simplefilter(\"ignore\", DeprecationWarning) np.random.seed(RANDOM_SEED)  prcpt_non_linear_1 = Perceptron(x=X_train_non_linear, y=y_train_non_linear, weights=weights, bias=bias, eta=0.01, att_bias=True) prcpt_non_linear_1.train(use_patience=False)  print(\"Convergiu:\", prcpt_non_linear_1.converged) print(\"\u00c9pocas:\", prcpt_non_linear_1.epochs_run)  if not prcpt_non_linear_1.converged:     print(prcpt_non_linear_1.stop_reason)  print(\"Acur\u00e1cia por \u00c9poca:\", prcpt_non_linear_1.accuracy_per_epoch) print(\"Atualiza\u00e7\u00f5es por \u00c9poca:\", prcpt_non_linear_1.updates_per_epoch) <pre>Convergiu: False\n\u00c9pocas: 100\nmax_epochs\nAcur\u00e1cia por \u00c9poca: [0.49142857142857144, 0.6035714285714286, 0.6057142857142856, 0.6278571428571429, 0.635, 0.6135714285714285, 0.6335714285714286, 0.6328571428571428, 0.6185714285714285, 0.6085714285714285, 0.62, 0.6071428571428572, 0.6478571428571429, 0.6242857142857143, 0.6242857142857143, 0.6278571428571429, 0.6435714285714286, 0.6292857142857142, 0.6428571428571428, 0.6135714285714285, 0.6192857142857142, 0.635, 0.615, 0.6178571428571429, 0.6235714285714286, 0.6185714285714285, 0.6264285714285714, 0.6107142857142858, 0.6028571428571429, 0.615, 0.6121428571428571, 0.6064285714285714, 0.6057142857142856, 0.6321428571428571, 0.6214285714285714, 0.6021428571428571, 0.6057142857142856, 0.5957142857142856, 0.6128571428571429, 0.6321428571428571, 0.6207142857142858, 0.5871428571428572, 0.6207142857142858, 0.63, 0.6392857142857142, 0.6192857142857142, 0.6235714285714286, 0.6207142857142858, 0.6242857142857143, 0.6092857142857142, 0.6321428571428571, 0.6107142857142858, 0.6221428571428571, 0.6228571428571428, 0.6271428571428572, 0.6242857142857143, 0.6314285714285715, 0.6285714285714286, 0.6342857142857143, 0.6514285714285715, 0.6128571428571429, 0.6185714285714285, 0.6121428571428571, 0.625, 0.6207142857142858, 0.5942857142857143, 0.6314285714285715, 0.6085714285714285, 0.6328571428571428, 0.6328571428571428, 0.6164285714285714, 0.6107142857142858, 0.6071428571428572, 0.6521428571428571, 0.6114285714285714, 0.6128571428571429, 0.625, 0.6092857142857142, 0.6221428571428571, 0.6171428571428572, 0.6207142857142858, 0.6057142857142856, 0.6435714285714286, 0.6135714285714285, 0.6064285714285714, 0.6057142857142856, 0.6035714285714286, 0.6271428571428572, 0.6242857142857143, 0.6271428571428572, 0.5992857142857143, 0.6157142857142857, 0.6307142857142858, 0.6185714285714285, 0.6378571428571429, 0.6242857142857143, 0.6314285714285715, 0.6342857142857143, 0.6221428571428571, 0.6192857142857142]\nAtualiza\u00e7\u00f5es por \u00c9poca: [712, 555, 552, 521, 511, 541, 513, 514, 534, 548, 532, 550, 493, 526, 526, 521, 499, 519, 500, 541, 533, 511, 539, 535, 527, 534, 523, 545, 556, 539, 543, 551, 552, 515, 530, 557, 552, 566, 542, 515, 531, 578, 531, 518, 505, 533, 527, 531, 526, 547, 515, 545, 529, 528, 522, 526, 516, 520, 512, 488, 542, 534, 543, 525, 531, 568, 516, 548, 514, 514, 537, 545, 550, 487, 544, 542, 525, 547, 529, 536, 531, 552, 499, 541, 551, 552, 555, 522, 526, 522, 561, 538, 517, 534, 507, 526, 516, 512, 529, 533]\n</pre> <p>Caso seja aplicado o m\u00e9todo de parada patience, explicado anteriormente, o modelo parar\u00e1 de treina caso ele exceda o limite de rodadas sem melhora na m\u00e9trica de an\u00e1lise. No caso dessa aplica\u00e7\u00e3o, a m\u00e9trica utilizada foi a quantidade de atualiza\u00e7\u00f5es feitas na \u00e9poca e a quantidade de \u00e9pocas sem melhora nessa m\u00e9trica foram de 30. Ou seja, o modelo parar\u00e1 de treinar caso ele passe 30 \u00e9pocas com o n\u00famero de atualiza\u00e7\u00f5es feitas sendo maiores que as \u00faltimas 29 \u00e9pocas.</p> <p>Com esse m\u00e9todo de parada implementado, o que acontece \u00e9 que o modelo para de treinar ap\u00f3os 49 \u00e9pocas. Isto \u00e9, n\u00e3o existiram \u00e9pocas com menos atualiza\u00e7\u00f5es desde a 19\u00aa rodada.</p> In\u00a0[18]: Copied! <pre>import warnings\nwarnings.simplefilter(\"ignore\", DeprecationWarning)\nnp.random.seed(RANDOM_SEED)\n\nprcpt_non_linear_2 = Perceptron(x=X_train_non_linear, y=y_train_non_linear, weights=weights, bias=bias, eta=0.01, att_bias=True)\nprcpt_non_linear_2.train(use_patience=True, patience=30)\n\nprint(\"Convergiu:\", prcpt_non_linear_2.converged)\nprint(\"\u00c9pocas:\", prcpt_non_linear_2.epochs_run)\n\nif not prcpt_non_linear_2.converged:\n    print(prcpt_non_linear_2.stop_reason)\n\nprint(\"Acur\u00e1cia por \u00c9poca:\", prcpt_non_linear_2.accuracy_per_epoch)\nprint(\"Atualiza\u00e7\u00f5es por \u00c9poca:\", prcpt_non_linear_2.updates_per_epoch)\n</pre> import warnings warnings.simplefilter(\"ignore\", DeprecationWarning) np.random.seed(RANDOM_SEED)  prcpt_non_linear_2 = Perceptron(x=X_train_non_linear, y=y_train_non_linear, weights=weights, bias=bias, eta=0.01, att_bias=True) prcpt_non_linear_2.train(use_patience=True, patience=30)  print(\"Convergiu:\", prcpt_non_linear_2.converged) print(\"\u00c9pocas:\", prcpt_non_linear_2.epochs_run)  if not prcpt_non_linear_2.converged:     print(prcpt_non_linear_2.stop_reason)  print(\"Acur\u00e1cia por \u00c9poca:\", prcpt_non_linear_2.accuracy_per_epoch) print(\"Atualiza\u00e7\u00f5es por \u00c9poca:\", prcpt_non_linear_2.updates_per_epoch) <pre>Convergiu: False\n\u00c9pocas: 49\nParada adiantada (sem melhora \u2265 0 por 30 \u00e9pocas)\nAcur\u00e1cia por \u00c9poca: [0.6021428571428571, 0.6307142857142858, 0.6135714285714285, 0.6378571428571429, 0.6385714285714286, 0.6114285714285714, 0.6221428571428571, 0.6228571428571428, 0.6307142857142858, 0.6042857142857143, 0.6292857142857142, 0.6178571428571429, 0.6335714285714286, 0.6021428571428571, 0.6178571428571429, 0.6257142857142857, 0.6435714285714286, 0.6285714285714286, 0.6464285714285714, 0.6278571428571429, 0.6228571428571428, 0.6328571428571428, 0.6028571428571429, 0.6135714285714285, 0.6185714285714285, 0.6257142857142857, 0.6285714285714286, 0.6057142857142856, 0.6128571428571429, 0.62, 0.62, 0.6114285714285714, 0.6007142857142858, 0.6271428571428572, 0.6428571428571428, 0.6121428571428571, 0.6228571428571428, 0.5971428571428572, 0.6128571428571429, 0.6164285714285714, 0.6214285714285714, 0.6035714285714286, 0.6257142857142857, 0.6307142857142858, 0.6264285714285714, 0.6085714285714285, 0.6264285714285714, 0.61, 0.6228571428571428]\nAtualiza\u00e7\u00f5es por \u00c9poca: [557, 517, 541, 507, 506, 544, 529, 528, 517, 554, 519, 535, 513, 557, 535, 524, 499, 520, 495, 521, 528, 514, 556, 541, 534, 524, 520, 552, 542, 532, 532, 544, 559, 522, 500, 543, 528, 564, 542, 537, 530, 555, 524, 517, 523, 548, 523, 546, 528]\n</pre> In\u00a0[19]: Copied! <pre>y_pred_full_non_linear, acc_full_non_linear = prcpt_non_linear_2.predict(X_test=X_non_linear, y_test=y_non_linear)\nprint(f\"Acur\u00e1cia no dataset completo: {acc_full_non_linear * 100:.4f}\")\n</pre> y_pred_full_non_linear, acc_full_non_linear = prcpt_non_linear_2.predict(X_test=X_non_linear, y_test=y_non_linear) print(f\"Acur\u00e1cia no dataset completo: {acc_full_non_linear * 100:.4f}\") <pre>Acur\u00e1cia no dataset completo: 64.6500\n</pre> <p>Por ser um conjunto de dados com mais sobreposi\u00e7\u00e3o \u00e9 poss\u00edvel perceber uma piora na acur\u00e1cia como um todo, tanto nos treinamentos como no teste sob o conjunto de dados inteiro. Enquanto no primeiro exemplo foi poss\u00edvel alca\u00e7ar 99,9% de acur\u00e1cia no dataset completo, nesse segundo, foi obtido apenas 64,65%</p> In\u00a0[20]: Copied! <pre>w = prcpt_non_linear_2.weights\nb = float(np.squeeze(prcpt_non_linear_2.bias))\n\nx_min = X_non_linear[:, 0].min() - 0.5\nx_max = X_non_linear[:, 0].max() + 0.5\nxs = np.linspace(x_min, x_max, 400)\n</pre> w = prcpt_non_linear_2.weights b = float(np.squeeze(prcpt_non_linear_2.bias))  x_min = X_non_linear[:, 0].min() - 0.5 x_max = X_non_linear[:, 0].max() + 0.5 xs = np.linspace(x_min, x_max, 400) In\u00a0[21]: Copied! <pre>plt.figure(figsize=(7, 6))\n\nif abs(w[1]) &gt; 1e-12:\n    ys = -(w[0] / w[1]) * xs - b / w[1]\n    plt.plot(xs, ys, '--', linewidth=2, label=\"Fronteira de decis\u00e3o\", c='black')\nelse:\n    x_v = -b / w[0]\n    plt.axvline(x_v, linewidth=2, label=\"Fronteira de decis\u00e3o\", c='black', linestyle='--')\n\nmis = (y_pred_full_non_linear != y_non_linear)\n\nplt.scatter(\n    X_non_linear[~mis, 0], X_non_linear[~mis, 1],\n    c=y[~mis],\n    cmap=plt.get_cmap(\"tab10\", 2),\n    marker=\"o\", s=40, alpha=0.6,\n    label=\"Corretos\"\n)\n\nplt.scatter(\n    X_non_linear[mis, 0], X_non_linear[mis, 1],\n    c=y[mis],\n    cmap=plt.get_cmap(\"tab10\", 2),\n    marker=\"x\", s=70, alpha=0.9,\n    label=\"Misclass\"\n)\n\nplt.title(f\"Perceptron \u2014 Fronteira e pontos n\u00e3o lineares (acc={acc_full_non_linear:.4f})\")\nplt.xlabel(\"X1\")\nplt.ylabel(\"X2\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> plt.figure(figsize=(7, 6))  if abs(w[1]) &gt; 1e-12:     ys = -(w[0] / w[1]) * xs - b / w[1]     plt.plot(xs, ys, '--', linewidth=2, label=\"Fronteira de decis\u00e3o\", c='black') else:     x_v = -b / w[0]     plt.axvline(x_v, linewidth=2, label=\"Fronteira de decis\u00e3o\", c='black', linestyle='--')  mis = (y_pred_full_non_linear != y_non_linear)  plt.scatter(     X_non_linear[~mis, 0], X_non_linear[~mis, 1],     c=y[~mis],     cmap=plt.get_cmap(\"tab10\", 2),     marker=\"o\", s=40, alpha=0.6,     label=\"Corretos\" )  plt.scatter(     X_non_linear[mis, 0], X_non_linear[mis, 1],     c=y[mis],     cmap=plt.get_cmap(\"tab10\", 2),     marker=\"x\", s=70, alpha=0.9,     label=\"Misclass\" )  plt.title(f\"Perceptron \u2014 Fronteira e pontos n\u00e3o lineares (acc={acc_full_non_linear:.4f})\") plt.xlabel(\"X1\") plt.ylabel(\"X2\") plt.legend() plt.tight_layout() plt.show() In\u00a0[22]: Copied! <pre>plt.figure(figsize=(6, 4))\nplt.plot(np.arange(1, prcpt_non_linear_2.epochs_run + 1), prcpt_non_linear_2.accuracy_per_epoch, linewidth=2)\nplt.xlabel(\"\u00c9poca\")\nplt.ylabel(\"Acur\u00e1cia (treino)\")\nplt.title(\"Acur\u00e1cia por \u00e9poca\")\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n</pre> plt.figure(figsize=(6, 4)) plt.plot(np.arange(1, prcpt_non_linear_2.epochs_run + 1), prcpt_non_linear_2.accuracy_per_epoch, linewidth=2) plt.xlabel(\"\u00c9poca\") plt.ylabel(\"Acur\u00e1cia (treino)\") plt.title(\"Acur\u00e1cia por \u00e9poca\") plt.grid(True, alpha=0.3) plt.tight_layout() plt.show() <p>Diferentemente do primeiro exemplo, nesse conjunto de casos, v\u00e1rios pontos foram classificados de forma errada. Al\u00e9m disso, analisando a acur\u00e1cia ao longo dos treinamentos, percebe-se que: o modelo n\u00e3o convergiu; existiu uma maior variabilidade de resutlados, n\u00e3o sendo um progresso linear de melhora da acur\u00e1cia. Logo, conclui-se que o Percetron realmente n\u00e3o consegue trabalhar com dados n\u00e3o lineares. Em meio a essa dificuldade, de lidar com dados n\u00e3o lineares, que surge a ideia do MPL (Multi-Layer Perceptron), um algoritmo capaz de combinar v\u00e1rios Perceptrons em diferentes camadas, o que transforma a capacidade de aprendizado e previs\u00e3o dos dados do Perceptron.</p>"},{"location":"exercicios/perceptron/perceptron/#perceptron","title":"Perceptron\u00b6","text":"<p>Nessa se\u00e7\u00e3o, o conte\u00fado a ser explorado \u00e9 o in\u00edcio do que pode ser nomeado, Rede Neural. O algoritmo Perceptron, criado por Frank Rosenblatt, em 1958, \u00e9 o ponto de partida para todo o desenvolvimento feito at\u00e9 hoje em intelig\u00eancia artificial. Por mais que hoje em dia os algoritmos s\u00e3o muito mais complexos, a ideia central de funcionamento pode ser entendida com o algoritmo Perceptron. Por isso, esse cap\u00edtulo mergulha na explica\u00e7\u00e3o do funcionamento desse algoritmo.</p> <p>A din\u00e2mica apresentada aqui, aborda novamente duas distribui\u00e7\u00f5es de dados. O primeiro caso que cont\u00e9m uma distribui\u00e7\u00e3o linearmente separ\u00e1vel, e outra linearmente n\u00e3o separ\u00e1vel, da mesma forma que foi discutida as distribui\u00e7\u00f5es na se\u00e7\u00e3o Explora\u00e7\u00e3o de dados.</p>"},{"location":"exercicios/perceptron/perceptron/#distribuicao-linearmente-separavel","title":"Distribui\u00e7\u00e3o linearmente separ\u00e1vel\u00b6","text":"<p>Para a investiga\u00e7\u00e3o de dados linearmente separados, foram criadas duas classes de dados, com 1000 observa\u00e7\u00f5es em cada, seguindo as seguintes distribui\u00e7\u00f5es:</p> <ul> <li><p>Class 0:</p> <p>Mean = $[1.5, 1.5]$,</p> <p>Covariance matrix = $[[0.5, 0], [0, 0.5]]$ (i.e., variance of $0.5$ along each dimension, no covariance).</p> </li> <li><p>Class 1:</p> <p>Mean = $[5, 5]$,</p> <p>Covariance matrix = $[[0.5, 0], [0, 0.5]]$.</p> </li> </ul> <p>Novamente, para poss\u00edvel reprodutibilidade, na gera\u00e7\u00e3o dos dados/distribui\u00e7\u00f5es, foi utilizada a fun\u00e7\u00e3o <code>np.random.seed()</code>, com a RANDOM_SEED (42).</p>"},{"location":"exercicios/perceptron/perceptron/#distribuicao-linearmente-inseparavel","title":"Distribui\u00e7\u00e3o linearmente insepar\u00e1vel\u00b6","text":"<p>Para a investiga\u00e7\u00e3o de dados linearmente insepar\u00e1veis, foram criadas duas classes de dados, com 1000 observa\u00e7\u00f5es em cada, seguindo as seguintes distribui\u00e7\u00f5es:</p> <ul> <li><p>Class 0:</p> <p>Mean = $[3, 3]$,</p> <p>Covariance matrix = $[[1.5, 0], [0, 1.5]]$ (i.e., higher variance of 1.5 along each dimension).</p> </li> <li><p>Class 1:</p> <p>Mean = $[4, 4]$,</p> <p>Covariance matrix = $[[1.5, 0], [0, 1.5]]$.</p> </li> </ul> <p>Novamente, para poss\u00edvel reprodutibilidade, na gera\u00e7\u00e3o dos dados/distribui\u00e7\u00f5es, foi utilizada a fun\u00e7\u00e3o <code>np.random.seed()</code>, com a RANDOM_SEED (42).</p>"},{"location":"exercicios/perceptron/utils/perceptron/","title":"Perceptron","text":"In\u00a0[1]: Copied! <pre>import numpy as np\n</pre> import numpy as np In\u00a0[2]: Copied! <pre>RANDOM_SEED = 42\n</pre> RANDOM_SEED = 42 In\u00a0[3]: Copied! <pre>np.random.seed(RANDOM_SEED)\nclass Perceptron:\n    def __init__(\n        self,\n        x,\n        y,\n        weights=None,\n        bias=None,\n        eta: float = 0.01,\n        att_bias: bool = False,\n        max_epochs: int = 100\n    ):\n        self.x = x\n        self.y = y\n        \n        n_features = x.shape[1]\n\n        if weights is None:\n            self.weights = np.random.random(n_features)\n        else:\n            self.weights = weights\n\n        if bias is None:\n            self.bias = np.random.random()\n        else:\n            self.bias = bias\n        \n        self.eta = eta\n        self.att_bias = att_bias\n        self.max_epochs = max_epochs\n\n        self.accuracy_per_epoch = []\n        self.updates_per_epoch = []\n        self.converged = False\n        self.epochs_run = 0\n\n    def train(self, patience: int = 10, min_delta: int = 0):\n        best_updates = np.inf\n        best_weights = self.weights.copy()\n        best_bias = float(self.bias)\n        patience_count = 0\n\n        self.stop_reason = \"max_epochs\"\n        self.converged = False\n        self.accuracy_per_epoch = []\n        self.updates_per_epoch = []\n\n        for epoch in range(self.max_epochs):\n            updates = 0\n\n            indices = np.random.permutation(len(self.x))\n            x_shuffled = self.x[indices]\n            y_shuffled = self.y[indices]\n\n            for x_i, y_i in zip(x_shuffled, y_shuffled):\n                y_pred = 1 if (np.dot(x_i, self.weights) + self.bias) &gt;= 0 else 0\n                error = y_i - y_pred\n                if error != 0:\n                    updates += 1\n                    self._rebalance(x=x_i, error=error)\n\n            acc = 1.0 - (updates / len(self.y))\n            self.accuracy_per_epoch.append(acc)\n            self.updates_per_epoch.append(updates)\n            self.epochs_run = epoch + 1\n\n            if updates == 0:\n                self.converged = True\n                self.stop_reason = \"No errors (linearly separable)\"\n\n                best_updates = 0\n                best_weights = self.weights.copy()\n                best_bias = float(self.bias)\n                break\n\n            if updates + min_delta &lt; best_updates:\n                best_updates = updates\n                best_weights = self.weights.copy()\n                best_bias = float(self.bias)\n                patience_count = 0  # reset paci\u00eancia\n            else:\n                patience_count += 1\n\n            if patience_count &gt;= patience:\n                self.stop_reason = f\"No improvement for {patience} epochs\"\n                break\n\n        self.weights = best_weights\n        self.bias = best_bias\n        self.best_updates = best_updates\n\n    \n    def predict(self, X_test=None, y_test=None):\n        if X_test is None:\n            raise ValueError(\"Entre com o X_test\")\n\n        scores = X_test @ self.weights + self.bias\n        y_pred = (scores &gt;= 0).astype(int)\n\n        if y_test is not None:\n            acc = (y_pred == y_test).mean()\n            return y_pred, acc\n        return y_pred\n\n    def _rebalance(self, x, error):\n        if error != 0:\n            self.weights += self.eta * error * x\n            if self.att_bias:\n                self.bias += self.eta * error\n</pre> np.random.seed(RANDOM_SEED) class Perceptron:     def __init__(         self,         x,         y,         weights=None,         bias=None,         eta: float = 0.01,         att_bias: bool = False,         max_epochs: int = 100     ):         self.x = x         self.y = y                  n_features = x.shape[1]          if weights is None:             self.weights = np.random.random(n_features)         else:             self.weights = weights          if bias is None:             self.bias = np.random.random()         else:             self.bias = bias                  self.eta = eta         self.att_bias = att_bias         self.max_epochs = max_epochs          self.accuracy_per_epoch = []         self.updates_per_epoch = []         self.converged = False         self.epochs_run = 0      def train(self, patience: int = 10, min_delta: int = 0):         best_updates = np.inf         best_weights = self.weights.copy()         best_bias = float(self.bias)         patience_count = 0          self.stop_reason = \"max_epochs\"         self.converged = False         self.accuracy_per_epoch = []         self.updates_per_epoch = []          for epoch in range(self.max_epochs):             updates = 0              indices = np.random.permutation(len(self.x))             x_shuffled = self.x[indices]             y_shuffled = self.y[indices]              for x_i, y_i in zip(x_shuffled, y_shuffled):                 y_pred = 1 if (np.dot(x_i, self.weights) + self.bias) &gt;= 0 else 0                 error = y_i - y_pred                 if error != 0:                     updates += 1                     self._rebalance(x=x_i, error=error)              acc = 1.0 - (updates / len(self.y))             self.accuracy_per_epoch.append(acc)             self.updates_per_epoch.append(updates)             self.epochs_run = epoch + 1              if updates == 0:                 self.converged = True                 self.stop_reason = \"No errors (linearly separable)\"                  best_updates = 0                 best_weights = self.weights.copy()                 best_bias = float(self.bias)                 break              if updates + min_delta &lt; best_updates:                 best_updates = updates                 best_weights = self.weights.copy()                 best_bias = float(self.bias)                 patience_count = 0  # reset paci\u00eancia             else:                 patience_count += 1              if patience_count &gt;= patience:                 self.stop_reason = f\"No improvement for {patience} epochs\"                 break          self.weights = best_weights         self.bias = best_bias         self.best_updates = best_updates           def predict(self, X_test=None, y_test=None):         if X_test is None:             raise ValueError(\"Entre com o X_test\")          scores = X_test @ self.weights + self.bias         y_pred = (scores &gt;= 0).astype(int)          if y_test is not None:             acc = (y_pred == y_test).mean()             return y_pred, acc         return y_pred      def _rebalance(self, x, error):         if error != 0:             self.weights += self.eta * error * x             if self.att_bias:                 self.bias += self.eta * error"},{"location":"exercicios/vae/vae/","title":"VAE (Variational Autoencoder)","text":"In\u00a0[1]: Copied! <pre>import os\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # GPU n\u00e3o est\u00e1 sendo utilizada\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport random\nimport warnings\nfrom pathlib import Path\n\nimport keras\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom keras import Model, layers, ops\nfrom sklearn.manifold import TSNE\n\n# SET SEED\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# PAR\u00c2METROS\nBATCH_SIZE = 128\nLATENT_DIM = 2\nEPOCHS = 100\nLEARNING_RATE = 1e-3\nVALIDATION_SPLIT = 0.1\n\noutdir = Path(\"figs\")\noutdir.mkdir(exist_ok=True)\n</pre> import os  os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # GPU n\u00e3o est\u00e1 sendo utilizada os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  import warnings  warnings.filterwarnings(\"ignore\")  import os import random import warnings from pathlib import Path  import keras import matplotlib.pyplot as plt import numpy as np import tensorflow as tf from keras import Model, layers, ops from sklearn.manifold import TSNE  # SET SEED SEED = 42 random.seed(SEED) np.random.seed(SEED) tf.random.set_seed(SEED)  # PAR\u00c2METROS BATCH_SIZE = 128 LATENT_DIM = 2 EPOCHS = 100 LEARNING_RATE = 1e-3 VALIDATION_SPLIT = 0.1  outdir = Path(\"figs\") outdir.mkdir(exist_ok=True) <pre>2025-11-16 22:59:48.838436: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2025-11-16 22:59:48.882626: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n</pre> <pre>2025-11-16 22:59:52.802317: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n</pre> <p>Como j\u00e1 citado anteriormente,  o dataset foi importado da pr\u00f3pria biblioteca tensorflow, utilizando o m\u00f3dulo de datasets dele: <code>tf.keras.datasets</code>. Importante citar que nesse m\u00f3dulo, o conjunto de dados de treino e teste j\u00e1 est\u00e3o separados e podem ser carregados diretamente do m\u00e9todo.</p> In\u00a0[2]: Copied! <pre>(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n</pre> (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() <pre>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n</pre> <pre>\r       0/11490434 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 0s/step</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 1105920/11490434 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 0us/step</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2736128/11490434 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 0us/step</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4505600/11490434 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 0us/step</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5611520/11490434 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 0us/step</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6676480/11490434 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 0us/step</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8396800/11490434 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 0us/step</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9863168/11490434 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 0us/step</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11362304/11490434 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 0us/step</pre> <pre>\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11490434/11490434 \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 0s 0us/step\n</pre> <p>Ap\u00f3s isso foi normalizada a entrada dos dados como citado, dividindo tudo por 255 para os dados ficarem na distribui\u00e7\u00e3o entre $[0, 1]$</p> In\u00a0[3]: Copied! <pre>x = x_train.astype(\"float32\") / 255.0\ny = y_train.astype(\"int64\")\nx = np.expand_dims(x, axis=-1)\n</pre> x = x_train.astype(\"float32\") / 255.0 y = y_train.astype(\"int64\") x = np.expand_dims(x, axis=-1) <p>A separa\u00e7\u00e3o do conjunto para valida\u00e7\u00e3o nesse caso foi feita manualmente, a partir das fun\u00e7\u00f5es de permuta\u00e7\u00e3o da numpy, e ap\u00f3s isso a prepara\u00e7\u00e3o do formato dos dados para entrada na biblioteca do tensorflow, por isso da aplica\u00e7\u00e3o dos diversos m\u00e9todos de prepara\u00e7\u00e3o.</p> In\u00a0[4]: Copied! <pre>n = x.shape[0]\nn_val = int(VALIDATION_SPLIT * n)\n\nidx = np.random.RandomState(SEED).permutation(n)\nx = x[idx]; y = y[idx]\nx_val, y_val = x[:n_val], y[:n_val]\nx_train_, y_train_ = x[n_val:], y[n_val:]\n\ntrain_ds = (\n    tf.data.Dataset.from_tensor_slices((x_train_, x_train_, y_train_))\n    .cache()\n    .shuffle(buffer_size=len(x_train_), seed=SEED)\n    .batch(BATCH_SIZE)\n    .prefetch(tf.data.AUTOTUNE)\n)\n\nval_ds = (\n    tf.data.Dataset.from_tensor_slices((x_val, x_val, y_val))\n    .batch(BATCH_SIZE)\n    .prefetch(tf.data.AUTOTUNE)\n)\n</pre> n = x.shape[0] n_val = int(VALIDATION_SPLIT * n)  idx = np.random.RandomState(SEED).permutation(n) x = x[idx]; y = y[idx] x_val, y_val = x[:n_val], y[:n_val] x_train_, y_train_ = x[n_val:], y[n_val:]  train_ds = (     tf.data.Dataset.from_tensor_slices((x_train_, x_train_, y_train_))     .cache()     .shuffle(buffer_size=len(x_train_), seed=SEED)     .batch(BATCH_SIZE)     .prefetch(tf.data.AUTOTUNE) )  val_ds = (     tf.data.Dataset.from_tensor_slices((x_val, x_val, y_val))     .batch(BATCH_SIZE)     .prefetch(tf.data.AUTOTUNE) ) <pre>2025-11-16 22:59:55.610293: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n</pre> <p>Com os conjuntos de treino e valida\u00e7\u00e3o separados, \u00e9 poss\u00edvel iniciar o processo de treinamento e prepara\u00e7\u00e3o dos dados para entrada na rede. Dito isso, s\u00e3o setadas as camadas que o encoder ter\u00e1, com uma entrada de 784, visto o 28x28 de forma achatada, que ser\u00e1 reduzido para 512, e ent\u00e3o 256, at\u00e9 ser reduzido para o tamanho do espa\u00e7o latente escolhido. Para a aplica\u00e7\u00e3o em quest\u00e3o, ser\u00e1 utilizado um espa\u00e7o latente de 2 dimens\u00f5es, uma vez que possibilita a visualiza\u00e7\u00e3o da separa\u00e7\u00e3o dos dados atrav\u00e9s de um gr\u00e1fico.</p> In\u00a0[5]: Copied! <pre>input_img = layers.Input(shape=(28, 28, 1), name=\"img\")\n\n# --- Encoder ---\nx = layers.Flatten()(input_img)\nx = layers.Dense(512, activation=\"relu\")(x)\nx = layers.Dense(256, activation=\"relu\")(x)\nz_mean = layers.Dense(LATENT_DIM, name=\"z_mean\")(x)\nz_log_var = layers.Dense(LATENT_DIM, name=\"z_var\")(x)\n</pre> input_img = layers.Input(shape=(28, 28, 1), name=\"img\")  # --- Encoder --- x = layers.Flatten()(input_img) x = layers.Dense(512, activation=\"relu\")(x) x = layers.Dense(256, activation=\"relu\")(x) z_mean = layers.Dense(LATENT_DIM, name=\"z_mean\")(x) z_log_var = layers.Dense(LATENT_DIM, name=\"z_var\")(x) <p>O m\u00e9todo <code>sampling()</code> criado foi exclusivamente para for\u00e7ar o treinamento do espa\u00e7o latente utilizando $\\mu$ e $\\sigma$, por\u00e9m deixando o gradiente fluir entre $\\mu$ e $\\log{\\sigma^2}$, pois se n\u00e3o o gradiente n\u00e3o seria derivavel.</p> In\u00a0[6]: Copied! <pre>def sampling(args):\n    mu, log_var = args\n    eps = keras.random.normal(shape=ops.shape(mu), mean=0.0, stddev=1.0, seed=SEED)\n    return mu + ops.exp(0.5 * log_var) * eps\n</pre> def sampling(args):     mu, log_var = args     eps = keras.random.normal(shape=ops.shape(mu), mean=0.0, stddev=1.0, seed=SEED)     return mu + ops.exp(0.5 * log_var) * eps In\u00a0[7]: Copied! <pre>z = layers.Lambda(sampling, name=\"z\")([z_mean, z_log_var])\n\nencoder_vae = Model(input_img, [z_mean, z_log_var, z], name=\"encoder\")\nencoder_vae.summary()\n</pre> z = layers.Lambda(sampling, name=\"z\")([z_mean, z_log_var])  encoder_vae = Model(input_img, [z_mean, z_log_var, z], name=\"encoder\") encoder_vae.summary() <pre>Model: \"encoder\"\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)        \u2503 Output Shape      \u2503    Param # \u2503 Connected to      \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 img (InputLayer)    \u2502 (None, 28, 28, 1) \u2502          0 \u2502 -                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 flatten (Flatten)   \u2502 (None, 784)       \u2502          0 \u2502 img[0][0]         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense (Dense)       \u2502 (None, 512)       \u2502    401,920 \u2502 flatten[0][0]     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_1 (Dense)     \u2502 (None, 256)       \u2502    131,328 \u2502 dense[0][0]       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 z_mean (Dense)      \u2502 (None, 2)         \u2502        514 \u2502 dense_1[0][0]     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 z_var (Dense)       \u2502 (None, 2)         \u2502        514 \u2502 dense_1[0][0]     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 z (Lambda)          \u2502 (None, 2)         \u2502          0 \u2502 z_mean[0][0],     \u2502\n\u2502                     \u2502                   \u2502            \u2502 z_var[0][0]       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre> Total params: 534,276 (2.04 MB)\n</pre> <pre> Trainable params: 534,276 (2.04 MB)\n</pre> <pre> Non-trainable params: 0 (0.00 B)\n</pre> <p>O decoder tem a mesma estrutura do enconder por\u00e9m ao contr\u00e1rio, aumentando gradativamente a quantidade dos ner\u00f4nios at\u00e9 chegar nos 784 neur\u00f4nios, que representar\u00e3o os 28x28 pixels, reconstruindo por completo a imagem do algorismo. Durante a reconstru\u00e7\u00e3o, a fun\u00e7\u00e3o de ativa\u00e7\u00e3o dos neur\u00f4nios foi a relu, com a sigmoide sendo utilizada na camada de sa\u00edda.</p> In\u00a0[8]: Copied! <pre># --- Decoder ---\nlatent_inputs = layers.Input(shape=(LATENT_DIM,), name=\"z_sampling\")\nx = layers.Dense(256, activation=\"relu\")(latent_inputs)\nx = layers.Dense(512, activation=\"relu\")(x)\nx = layers.Dense(28 * 28, activation=\"sigmoid\")(x)\noutput_img = layers.Reshape((28, 28, 1))(x)\n\ndecoder_vae = Model(latent_inputs, output_img, name=\"decoder\")\ndecoder_vae.summary()\n</pre> # --- Decoder --- latent_inputs = layers.Input(shape=(LATENT_DIM,), name=\"z_sampling\") x = layers.Dense(256, activation=\"relu\")(latent_inputs) x = layers.Dense(512, activation=\"relu\")(x) x = layers.Dense(28 * 28, activation=\"sigmoid\")(x) output_img = layers.Reshape((28, 28, 1))(x)  decoder_vae = Model(latent_inputs, output_img, name=\"decoder\") decoder_vae.summary() <pre>Model: \"decoder\"\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)                    \u2503 Output Shape           \u2503       Param # \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 z_sampling (InputLayer)         \u2502 (None, 2)              \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_2 (Dense)                 \u2502 (None, 256)            \u2502           768 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_3 (Dense)                 \u2502 (None, 512)            \u2502       131,584 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_4 (Dense)                 \u2502 (None, 784)            \u2502       402,192 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 reshape (Reshape)               \u2502 (None, 28, 28, 1)      \u2502             0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre> Total params: 534,544 (2.04 MB)\n</pre> <pre> Trainable params: 534,544 (2.04 MB)\n</pre> <pre> Non-trainable params: 0 (0.00 B)\n</pre> <p>Para melhor an\u00e1lise sobre o processo de treinamento da rede, foram criados trackers para acompanhar as medidas de perdas durante cada uma das \u00e9pocas de treinamento.</p> In\u00a0[9]: Copied! <pre>total_tracker = keras.metrics.Mean(name=\"loss\")\nrecon_tracker = keras.metrics.Mean(name=\"recon_loss\")\nkl_tracker = keras.metrics.Mean(name=\"kl_loss\")\n</pre> total_tracker = keras.metrics.Mean(name=\"loss\") recon_tracker = keras.metrics.Mean(name=\"recon_loss\") kl_tracker = keras.metrics.Mean(name=\"kl_loss\") <p>A classe <code>VAE()</code>, foi criada para auxiliar no processo de treinamento de aplica\u00e7\u00e3o da rede neural como um todo. Ap\u00f3s estruturar a quantidade de camadas e as fun\u00e7\u00f5es de ativa\u00e7\u00e3o no momento de enconder e decoder, o processo de treinamento foi consolidado na classe para tornar mais f\u00e1cil o processo de atualiza\u00e7\u00e3o dos pesos e melhora da rede neural.</p> In\u00a0[10]: Copied! <pre>class VAE(keras.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super().__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n\n        self.total_loss_tracker = keras.metrics.Mean(name=\"loss\")\n        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n\n    @property\n    def metrics(self):\n        return [self.total_loss_tracker,\n                self.reconstruction_loss_tracker,\n                self.kl_loss_tracker]\n\n    def _compute_losses(self, x, training=False):\n        z_mean, z_log_var, z = self.encoder(x, training=training)\n        recon = self.decoder(z, training=training)\n\n        bce = keras.losses.binary_crossentropy(x, recon)\n        recon_loss = ops.mean(ops.sum(bce, axis=(1, 2)))\n\n        kl = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n        kl_loss = ops.mean(ops.sum(kl, axis=1))\n\n        total = recon_loss + kl_loss\n        return total, recon_loss, kl_loss\n\n    def train_step(self, data):\n        x = data[0] if isinstance(data, (tuple, list)) else data\n        with tf.GradientTape() as tape:\n            total, recon_loss, kl_loss = self._compute_losses(x, training=True)\n        grads = tape.gradient(total, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        self.total_loss_tracker.update_state(total)\n        self.reconstruction_loss_tracker.update_state(recon_loss)\n        self.kl_loss_tracker.update_state(kl_loss)\n        return {\"loss\": self.total_loss_tracker.result(),\n                \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n                \"kl_loss\": self.kl_loss_tracker.result()}\n\n    def test_step(self, data):\n        x = data[0] if isinstance(data, (tuple, list)) else data\n        total, recon_loss, kl_loss = self._compute_losses(x, training=False)\n        self.total_loss_tracker.update_state(total)\n        self.reconstruction_loss_tracker.update_state(recon_loss)\n        self.kl_loss_tracker.update_state(kl_loss)\n        return {\"loss\": self.total_loss_tracker.result(),\n                \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n                \"kl_loss\": self.kl_loss_tracker.result()}\n\n    def call(self, inputs, training=False):\n        z_mean, z_log_var, z = self.encoder(inputs, training=training)\n        return self.decoder(z, training=training)\n</pre> class VAE(keras.Model):     def __init__(self, encoder, decoder, **kwargs):         super().__init__(**kwargs)         self.encoder = encoder         self.decoder = decoder          self.total_loss_tracker = keras.metrics.Mean(name=\"loss\")         self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")         self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")      @property     def metrics(self):         return [self.total_loss_tracker,                 self.reconstruction_loss_tracker,                 self.kl_loss_tracker]      def _compute_losses(self, x, training=False):         z_mean, z_log_var, z = self.encoder(x, training=training)         recon = self.decoder(z, training=training)          bce = keras.losses.binary_crossentropy(x, recon)         recon_loss = ops.mean(ops.sum(bce, axis=(1, 2)))          kl = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))         kl_loss = ops.mean(ops.sum(kl, axis=1))          total = recon_loss + kl_loss         return total, recon_loss, kl_loss      def train_step(self, data):         x = data[0] if isinstance(data, (tuple, list)) else data         with tf.GradientTape() as tape:             total, recon_loss, kl_loss = self._compute_losses(x, training=True)         grads = tape.gradient(total, self.trainable_weights)         self.optimizer.apply_gradients(zip(grads, self.trainable_weights))         self.total_loss_tracker.update_state(total)         self.reconstruction_loss_tracker.update_state(recon_loss)         self.kl_loss_tracker.update_state(kl_loss)         return {\"loss\": self.total_loss_tracker.result(),                 \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),                 \"kl_loss\": self.kl_loss_tracker.result()}      def test_step(self, data):         x = data[0] if isinstance(data, (tuple, list)) else data         total, recon_loss, kl_loss = self._compute_losses(x, training=False)         self.total_loss_tracker.update_state(total)         self.reconstruction_loss_tracker.update_state(recon_loss)         self.kl_loss_tracker.update_state(kl_loss)         return {\"loss\": self.total_loss_tracker.result(),                 \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),                 \"kl_loss\": self.kl_loss_tracker.result()}      def call(self, inputs, training=False):         z_mean, z_log_var, z = self.encoder(inputs, training=training)         return self.decoder(z, training=training) <p>A classe herda de <code>keras.Model</code> e encapsula um Autoencoder Variacional com la\u00e7o de treino customizado. Na sua entrada ela recebe dois modelos Keras: um <code>encoder</code>, que deve devolver tr\u00eas tensores: z_mean; z_log_var e uma amostra latente z. J\u00e1 o <code>decoder</code>, mapeia z de volta para o espa\u00e7o de entrada. Nessa inicializa\u00e7\u00e3o tamb\u00e9m s\u00e3o criados tr\u00eas rastreadores de m\u00e9tricas, para ser poss\u00edvel analisar posteriormente os dados coletados durante a aplica\u00e7\u00e3o do <code>fit()</code>.</p> <p>A propriedade <code>metrics</code> exp\u00f5e a lista desses rastreadores para o mecanismo do Keras. Isso permite que o framework saiba quais m\u00e9tricas devem ser resetadas no in\u00edcio de cada \u00e9poca e mostradas no progresso do treinamento.</p> <p>O m\u00e9todo privado <code>_compute_losses()</code> \u00e9 respons\u00e1vel pelo c\u00e1lculo e mensura\u00e7\u00e3o da perda durante a aplica\u00e7\u00e3o do <code>fit()</code>. A perda de reconstru\u00e7\u00e3o \u00e9 calculada com <code>binary_crossentropy()</code> elemento a elemento, depois, soma-se sobre as dimens\u00f5es espaciais e tira-se a m\u00e9dia no batch.</p> <p>O <code>train_step()</code> personaliza o passo de treinamento por batch. A entrada <code>data</code> pode vir como um tensor <code>x</code> ou uma tupla/lista, aqui, qualquer <code>y</code> \u00e9 ignorado e usa-se apenas <code>x</code>. Dentro de um <code>tf.GradientTape</code>, a classe chama <code>_compute_losses</code>, calcula os gradientes da perda total em rela\u00e7\u00e3o a todos os pesos trein\u00e1veis, aplica-os via <code>self.optimizer.apply_gradients()</code> e atualiza os rastreadores de m\u00e9tricas. O retorno desse m\u00e9todo s\u00e3o os valores correntes de loss, reconstruction_loss e kl_loss.</p> <p>O <code>test_step()</code> faz a avalia\u00e7\u00e3o por batch em valida\u00e7\u00e3o/teste. A assinatura e o desembrulho de <code>data</code> s\u00e3o id\u00eanticos ao <code>train_step</code>, mas n\u00e3o h\u00e1 fita de gradiente nem atualiza\u00e7\u00e3o de pesos, apenas computa as perdas e atualiza as m\u00e9tricas e retorna o mesmo dicion\u00e1rio de logs.</p> <p>Por fim, o <code>call()</code> define a passagem direta do modelo quando voc\u00ea o chama como fun\u00e7\u00e3o. Ele repassa <code>inputs</code> ao <code>encoder</code> obtendo <code>z_mean</code>, <code>z_log_var</code>, <code>z</code> e retorna apenas a reconstru\u00e7\u00e3o <code>decoder()</code>. Em outras palavras, o <code>call</code> serve para infer\u00eancia/gera\u00e7\u00e3o, enquanto o c\u00e1lculo das perdas completas fica concentrado em <code>_compute_losses</code>.</p> In\u00a0[11]: Copied! <pre>vae = VAE(encoder_vae, decoder_vae)\nvae.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE))\nvae.summary()\n</pre> vae = VAE(encoder_vae, decoder_vae) vae.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE)) vae.summary() <pre>Model: \"vae\"\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)                    \u2503 Output Shape           \u2503       Param # \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 encoder (Functional)            \u2502 ((None, 2), (None, 2), \u2502       534,276 \u2502\n\u2502                                 \u2502 (None, 2))             \u2502               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 decoder (Functional)            \u2502 (None, 28, 28, 1)      \u2502       534,544 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre> Total params: 1,068,820 (4.08 MB)\n</pre> <pre> Trainable params: 1,068,820 (4.08 MB)\n</pre> <pre> Non-trainable params: 0 (0.00 B)\n</pre> <p>Aplicando o m\u00e9todo <code>fit()</code> ent\u00e3o tem se que todo o hist\u00f3rico do treinamento e atualiza\u00e7\u00e3o dos par\u00e2metros.</p> In\u00a0[12]: Copied! <pre>history = vae.fit(\n    train_ds.map(lambda x, x_target, y: x),\n    epochs=EPOCHS,\n    validation_data=val_ds.map(lambda x, x_target, y: x),\n    verbose=0 #caso queira observar as m\u00e9tricas por \u00e9poca, deixar como 1\n)\n</pre> history = vae.fit(     train_ds.map(lambda x, x_target, y: x),     epochs=EPOCHS,     validation_data=val_ds.map(lambda x, x_target, y: x),     verbose=0 #caso queira observar as m\u00e9tricas por \u00e9poca, deixar como 1 ) In\u00a0[13]: Copied! <pre>hist = history.history\n\n# === 1. Total Loss ===\nplt.figure()\nplt.plot(hist[\"loss\"], label=\"train\")\nif \"val_loss\" in hist:\n    plt.plot(hist[\"val_loss\"], label=\"val\")\nplt.legend()\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"VAE - Total Loss\")\nplt.tight_layout()\nplt.savefig(outdir / \"01_total_loss.png\", dpi=800)\nplt.show()\n</pre> hist = history.history  # === 1. Total Loss === plt.figure() plt.plot(hist[\"loss\"], label=\"train\") if \"val_loss\" in hist:     plt.plot(hist[\"val_loss\"], label=\"val\") plt.legend() plt.xlabel(\"Epoch\") plt.ylabel(\"Loss\") plt.title(\"VAE - Total Loss\") plt.tight_layout() plt.savefig(outdir / \"01_total_loss.png\", dpi=800) plt.show() In\u00a0[14]: Copied! <pre># === 2. Reconstruction Loss ===\nplt.figure()\nif \"reconstruction_loss\" in hist:\n    plt.plot(hist[\"reconstruction_loss\"], label=\"train\")\n    if \"val_reconstruction_loss\" in hist:\n        plt.plot(hist[\"val_reconstruction_loss\"], label=\"val\")\nelif \"recon_loss\" in hist:\n    plt.plot(hist[\"recon_loss\"], label=\"train\")\n    if \"val_recon_loss\" in hist:\n        plt.plot(hist[\"val_recon_loss\"], label=\"val\")\nplt.legend()\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Reconstruction Loss\")\nplt.title(\"VAE - Reconstruction Loss\")\nplt.tight_layout()\nplt.savefig(outdir / \"02_reconstruction_loss.png\", dpi=800)\nplt.show()\n</pre> # === 2. Reconstruction Loss === plt.figure() if \"reconstruction_loss\" in hist:     plt.plot(hist[\"reconstruction_loss\"], label=\"train\")     if \"val_reconstruction_loss\" in hist:         plt.plot(hist[\"val_reconstruction_loss\"], label=\"val\") elif \"recon_loss\" in hist:     plt.plot(hist[\"recon_loss\"], label=\"train\")     if \"val_recon_loss\" in hist:         plt.plot(hist[\"val_recon_loss\"], label=\"val\") plt.legend() plt.xlabel(\"Epoch\") plt.ylabel(\"Reconstruction Loss\") plt.title(\"VAE - Reconstruction Loss\") plt.tight_layout() plt.savefig(outdir / \"02_reconstruction_loss.png\", dpi=800) plt.show() In\u00a0[15]: Copied! <pre># === 3. KL Loss ===\nplt.figure()\nif \"kl_loss\" in hist:\n    plt.plot(hist[\"kl_loss\"], label=\"train\")\n    if \"val_kl_loss\" in hist:\n        plt.plot(hist[\"val_kl_loss\"], label=\"val\")\nplt.legend()\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"KL Divergence\")\nplt.title(\"VAE - KL Loss\")\nplt.tight_layout()\nplt.savefig(outdir / \"03_kl_loss.png\", dpi=800)\nplt.show()\n</pre> # === 3. KL Loss === plt.figure() if \"kl_loss\" in hist:     plt.plot(hist[\"kl_loss\"], label=\"train\")     if \"val_kl_loss\" in hist:         plt.plot(hist[\"val_kl_loss\"], label=\"val\") plt.legend() plt.xlabel(\"Epoch\") plt.ylabel(\"KL Divergence\") plt.title(\"VAE - KL Loss\") plt.tight_layout() plt.savefig(outdir / \"03_kl_loss.png\", dpi=800) plt.show() <p>No gr\u00e1fico de Total Loss, observa-se uma queda acentuada nas primeiras \u00e9pocas, seguida por uma estabiliza\u00e7\u00e3o gradual. Esse comportamento \u00e9 t\u00edpico de modelos que rapidamente ajustam os par\u00e2metros iniciais para reconstruir as imagens e, depois, refinam lentamente o espa\u00e7o latente. A perda de valida\u00e7\u00e3o acompanha a de treinamento at\u00e9 cerca da 10\u00aa \u00e9poca e, em seguida, se mant\u00e9m ligeiramente acima, o que indica boa generaliza\u00e7\u00e3o, sem sinais evidentes de overfitting \u2014 o modelo continua aprendendo de forma est\u00e1vel, mas a perda de valida\u00e7\u00e3o estabiliza antes da de treino.</p> <p>O gr\u00e1fico de Reconstruction Loss apresenta uma tend\u00eancia semelhante, com redu\u00e7\u00e3o expressiva no in\u00edcio e converg\u00eancia por volta da 30\u00aa \u00e9poca. A diferen\u00e7a entre as curvas de treino e valida\u00e7\u00e3o torna-se constante ap\u00f3s esse ponto, o que sugere que o modelo aprendeu a reconstruir bem os dados, mas ainda apresenta leve discrep\u00e2ncia em rela\u00e7\u00e3o aos exemplos de valida\u00e7\u00e3o \u2014 um indicativo de pequena sobreajuste, comum em autoencoders quando o modelo come\u00e7a a memorizar padr\u00f5es espec\u00edficos do conjunto de treino.</p> <p>J\u00e1 o gr\u00e1fico de KL Loss mostra um comportamento inverso: as curvas crescem ao longo das \u00e9pocas. Isso \u00e9 esperado, pois o termo de diverg\u00eancia KL mede o quanto a distribui\u00e7\u00e3o latente do modelo se aproxima da distribui\u00e7\u00e3o normal padr\u00e3o. O aumento gradual do KL indica que o VAE est\u00e1 aprendendo a regularizar o espa\u00e7o latente, equilibrando a fidelidade da reconstru\u00e7\u00e3o com a suavidade e continuidade da representa\u00e7\u00e3o. O fato de as curvas de treino e valida\u00e7\u00e3o se sobreporem quase totalmente demonstra uma boa estabilidade nesse componente \u2014 ou seja, o modelo n\u00e3o est\u00e1 superajustando o espa\u00e7o latente.</p> In\u00a0[16]: Copied! <pre>val_batch = next(iter(val_ds))\nx_val_batch = val_batch[0] if isinstance(val_batch, (tuple, list)) else val_batch\n\nz_mean, _, _ = encoder_vae.predict(x_val_batch, verbose=0)\nrecons_np = decoder_vae.predict(z_mean, verbose=0)\n\nn_show = 10\nplt.figure(figsize=(n_show*1.2, 2.5))\nx_np = x_val_batch.numpy() if hasattr(x_val_batch, \"numpy\") else np.array(x_val_batch)\n\nx_np = x_val_batch.numpy()\n\nfor i in range(n_show):\n\n    ax = plt.subplot(2, n_show, i + 1)\n    plt.imshow(x_np[i].squeeze(), cmap=\"gray\")\n    plt.axis(\"off\")\n\n    ax = plt.subplot(2, n_show, i + 1 + n_show)\n    plt.imshow(recons_np[i].squeeze(), cmap=\"gray\")\n    plt.axis(\"off\")\n\nplt.suptitle(\"Top: Originais   |   Bottom: Reconstru\u00e7\u00f5es\")\nplt.tight_layout()\nplt.savefig(outdir / \"05_reconstructions.png\", dpi=800)\nplt.show()\n</pre> val_batch = next(iter(val_ds)) x_val_batch = val_batch[0] if isinstance(val_batch, (tuple, list)) else val_batch  z_mean, _, _ = encoder_vae.predict(x_val_batch, verbose=0) recons_np = decoder_vae.predict(z_mean, verbose=0)  n_show = 10 plt.figure(figsize=(n_show*1.2, 2.5)) x_np = x_val_batch.numpy() if hasattr(x_val_batch, \"numpy\") else np.array(x_val_batch)  x_np = x_val_batch.numpy()  for i in range(n_show):      ax = plt.subplot(2, n_show, i + 1)     plt.imshow(x_np[i].squeeze(), cmap=\"gray\")     plt.axis(\"off\")      ax = plt.subplot(2, n_show, i + 1 + n_show)     plt.imshow(recons_np[i].squeeze(), cmap=\"gray\")     plt.axis(\"off\")  plt.suptitle(\"Top: Originais   |   Bottom: Reconstru\u00e7\u00f5es\") plt.tight_layout() plt.savefig(outdir / \"05_reconstructions.png\", dpi=800) plt.show() <p>Observando literalmente a reconstru\u00e7\u00e3o \u00e9 interessante perceber que na grande maioria dos n\u00fameros \u00e9 poss\u00edvel um humano distinguir qual \u00e9 o verdadeiro n\u00famero, no entendo a nitidez da imagem se perde durante a reconstru\u00e7\u00e3o, visto que a ideia do autoencoder \u00e9 capturar as amostras mais relevantes de dados, o que penaliza a qualidade da reprodu\u00e7\u00e3o da imagem. Das 10 imagens selecionadas, \u00e9 poss\u00edvel dizer que 7 imagens s\u00e3o reconstru\u00eddas de forma fidedigna ao algarismo realmente escrito. Contudo, \u00e9 poss\u00edvel perceber que existe uma confus\u00e3o por parte da rede entre 7 e 9, 3 e 5.</p> In\u00a0[17]: Copied! <pre>N_SAMPLES = 20\n\nz_samples = np.random.randn(N_SAMPLES, LATENT_DIM).astype(\"float32\")\ngen = decoder_vae.predict(z_samples, verbose=0)\n\nplt.figure(figsize=(N_SAMPLES*1.2, 1.4))\n\nfor i in range(N_SAMPLES):\n    ax = plt.subplot(1, N_SAMPLES, i + 1)\n    plt.imshow(gen[i].squeeze(), cmap=\"gray\")\n    plt.axis(\"off\")\n\nplt.suptitle(\"Amostras aleat\u00f3rias criadas a partir do espa\u00e7o latente\")\nplt.tight_layout()\nplt.savefig(outdir / \"06_random_samples.png\", dpi=800)\nplt.show()\n</pre> N_SAMPLES = 20  z_samples = np.random.randn(N_SAMPLES, LATENT_DIM).astype(\"float32\") gen = decoder_vae.predict(z_samples, verbose=0)  plt.figure(figsize=(N_SAMPLES*1.2, 1.4))  for i in range(N_SAMPLES):     ax = plt.subplot(1, N_SAMPLES, i + 1)     plt.imshow(gen[i].squeeze(), cmap=\"gray\")     plt.axis(\"off\")  plt.suptitle(\"Amostras aleat\u00f3rias criadas a partir do espa\u00e7o latente\") plt.tight_layout() plt.savefig(outdir / \"06_random_samples.png\", dpi=800) plt.show() In\u00a0[18]: Copied! <pre>z_means = []\nlabels = []\nfor xb, _, yb in val_ds:\n    mu, logv, z = encoder_vae.predict(xb, verbose=0)\n    z_means.append(mu)\n    labels.append(yb.numpy())\nz_means = np.concatenate(z_means, axis=0)\nlabels = np.concatenate(labels, axis=0)\n\nproj = z_means\n\nplt.figure(figsize=(6,6))\nsc = plt.scatter(proj[:, 0], proj[:, 1], c=labels, s=8, cmap=\"tab10\")\nplt.colorbar(sc)\nplt.title(\"VAE - Distribui\u00e7\u00e3o dos algarismos\")\nplt.xlabel(\"X1\")\nplt.ylabel(\"X2\")\nplt.tight_layout()\nplt.savefig(outdir / \"07_latent_space_vae.png\", dpi=800)\nplt.show()\n</pre> z_means = [] labels = [] for xb, _, yb in val_ds:     mu, logv, z = encoder_vae.predict(xb, verbose=0)     z_means.append(mu)     labels.append(yb.numpy()) z_means = np.concatenate(z_means, axis=0) labels = np.concatenate(labels, axis=0)  proj = z_means  plt.figure(figsize=(6,6)) sc = plt.scatter(proj[:, 0], proj[:, 1], c=labels, s=8, cmap=\"tab10\") plt.colorbar(sc) plt.title(\"VAE - Distribui\u00e7\u00e3o dos algarismos\") plt.xlabel(\"X1\") plt.ylabel(\"X2\") plt.tight_layout() plt.savefig(outdir / \"07_latent_space_vae.png\", dpi=800) plt.show() <pre>2025-11-16 23:06:40.846202: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n</pre> <p>Analisando como os n\u00fameros est\u00e3o dispostos no espa\u00e7o latente \u00e9 interessante perceber justamente a distribui\u00e7\u00e3o das confus\u00f5es da rede. Como citado anteriormente, a rede ap\u00f3s o treinamento durante 100 \u00e9pocas, teve uma confus\u00e3o entre os algarismos, 3 e 5, 7 e 9, e observando onde eles est\u00e3o distribu\u00eddos, \u00e9 facilmente percept\u00edvel que eles est\u00e3o se sobrepondo. Por exemplo, o 0, 1, 6 s\u00e3o algarismos que a rede identificou super bem, separando eles completamente do restante. No entanto, o restante est\u00e1 se sobrepondo, apresentando um n\u00e3o apredizado 100% sobre tais n\u00fameros.</p> <p>Agora, como complemento, foi implementado tamb\u00e9m um autoencoder normal, sem o tratamento de regulariza\u00e7\u00e3o dentro do espa\u00e7o latente, para justamente ser poss\u00edvel comparar os resultados. A diferen\u00e7a essencial entre os resultados de um Autoencoder (AE) e um Variational Autoencoder (VAE) estaria nas representa\u00e7\u00f5es latentes e na fidelidade das reconstru\u00e7\u00f5es. O AE tradicional busca apenas comprimir e reconstruir os dados de forma determin\u00edstica, aprendendo uma codifica\u00e7\u00e3o direta que minimiza o erro de reconstru\u00e7\u00e3o. Por isso, suas imagens reconstru\u00eddas tendem a ser mais n\u00edtidas e detalhadas, refletindo fielmente os d\u00edgitos originais do MNIST, ainda que sem uma estrutura probabil\u00edstica subjacente.</p> <p>J\u00e1 o VAE introduz uma abordagem probabil\u00edstica ao impor uma distribui\u00e7\u00e3o sobre o espa\u00e7o latente, for\u00e7ando o modelo a aprender representa\u00e7\u00f5es cont\u00ednuas e suavemente distribu\u00eddas. Essa regulariza\u00e7\u00e3o via termo de diverg\u00eancia KL faz com que as amostras do espa\u00e7o latente sejam mais estruturadas e interpol\u00e1veis o que permite gerar novas imagens plaus\u00edveis, mas tamb\u00e9m traz um custo em termos de reconstru\u00e7\u00e3o: as imagens produzidas pelo VAE tendem a ser mais suaves e menos precisas, apresentando certa perda de nitidez em rela\u00e7\u00e3o \u00e0s reconstru\u00e7\u00f5es do AE.</p> In\u00a0[19]: Copied! <pre># --- Encoder ---\ninputs = layers.Input(shape=(28, 28, 1))\nx = layers.Flatten()(inputs)\nx = layers.Dense(512, activation=\"relu\")(x)\nx = layers.Dense(256, activation=\"relu\")(x)\n</pre> # --- Encoder --- inputs = layers.Input(shape=(28, 28, 1)) x = layers.Flatten()(inputs) x = layers.Dense(512, activation=\"relu\")(x) x = layers.Dense(256, activation=\"relu\")(x) In\u00a0[20]: Copied! <pre># --- Decoder ---\nz_ae = layers.Dense(LATENT_DIM, name=\"z\")(x)\nx = layers.Dense(256, activation=\"relu\")(z_ae)\nx = layers.Dense(512, activation=\"relu\")(x)\nx = layers.Dense(28*28, activation=\"sigmoid\")(x)\noutputs = layers.Reshape((28, 28, 1))(x)\n</pre> # --- Decoder --- z_ae = layers.Dense(LATENT_DIM, name=\"z\")(x) x = layers.Dense(256, activation=\"relu\")(z_ae) x = layers.Dense(512, activation=\"relu\")(x) x = layers.Dense(28*28, activation=\"sigmoid\")(x) outputs = layers.Reshape((28, 28, 1))(x) <p>A estrutura das camadas e quantidades de neur\u00f4nios utilizados foi a mesma, justamente para ser poss\u00edvel a compara\u00e7\u00e3o apenas pela aplica\u00e7\u00e3o da regulariza\u00e7\u00e3o e aproxima\u00e7\u00e3o da distribui\u00e7\u00e3o normal no espa\u00e7o latente. Ou seja, est\u00e1 sendo testado apenas a diferen\u00e7a na tratativa do espa\u00e7o latente, tudo mais constante.</p> In\u00a0[21]: Copied! <pre>ae = Model(inputs, outputs, name=\"autoencoder\")\nae.compile(optimizer=keras.optimizers.Adam(LEARNING_RATE),\n           loss=\"binary_crossentropy\")\nae.summary()\n</pre> ae = Model(inputs, outputs, name=\"autoencoder\") ae.compile(optimizer=keras.optimizers.Adam(LEARNING_RATE),            loss=\"binary_crossentropy\") ae.summary() <pre>Model: \"autoencoder\"\n</pre> <pre>\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Layer (type)                    \u2503 Output Shape           \u2503       Param # \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 input_layer (InputLayer)        \u2502 (None, 28, 28, 1)      \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 flatten_1 (Flatten)             \u2502 (None, 784)            \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_5 (Dense)                 \u2502 (None, 512)            \u2502       401,920 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_6 (Dense)                 \u2502 (None, 256)            \u2502       131,328 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 z (Dense)                       \u2502 (None, 2)              \u2502           514 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_7 (Dense)                 \u2502 (None, 256)            \u2502           768 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_8 (Dense)                 \u2502 (None, 512)            \u2502       131,584 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 dense_9 (Dense)                 \u2502 (None, 784)            \u2502       402,192 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 reshape_1 (Reshape)             \u2502 (None, 28, 28, 1)      \u2502             0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <pre> Total params: 1,068,306 (4.08 MB)\n</pre> <pre> Trainable params: 1,068,306 (4.08 MB)\n</pre> <pre> Non-trainable params: 0 (0.00 B)\n</pre> In\u00a0[22]: Copied! <pre>hist_ae = ae.fit(\n    train_ds.map(lambda x, x_target, y: (x, x)),\n    validation_data=val_ds.map(lambda x, x_target, y: (x, x)),\n    epochs=EPOCHS,\n    verbose=0\n)\n</pre> hist_ae = ae.fit(     train_ds.map(lambda x, x_target, y: (x, x)),     validation_data=val_ds.map(lambda x, x_target, y: (x, x)),     epochs=EPOCHS,     verbose=0 ) In\u00a0[23]: Copied! <pre>val_batch = next(iter(val_ds))\nx_val_batch = val_batch[0] if isinstance(val_batch, (tuple, list)) else val_batch\n</pre> val_batch = next(iter(val_ds)) x_val_batch = val_batch[0] if isinstance(val_batch, (tuple, list)) else val_batch In\u00a0[24]: Copied! <pre>vae_recons = vae(x_val_batch, training=False)\nae_recons  = ae.predict(x_val_batch, verbose=0)\n</pre> vae_recons = vae(x_val_batch, training=False) ae_recons  = ae.predict(x_val_batch, verbose=0) In\u00a0[25]: Copied! <pre>x_np = x_val_batch.numpy() if hasattr(x_val_batch, \"numpy\") else np.array(x_val_batch)\nvae_recons_np = vae_recons.numpy() if hasattr(vae_recons,  \"numpy\")  else np.array(vae_recons)\nae_recons_np = ae_recons if isinstance(ae_recons, np.ndarray) else np.array(ae_recons)\n</pre> x_np = x_val_batch.numpy() if hasattr(x_val_batch, \"numpy\") else np.array(x_val_batch) vae_recons_np = vae_recons.numpy() if hasattr(vae_recons,  \"numpy\")  else np.array(vae_recons) ae_recons_np = ae_recons if isinstance(ae_recons, np.ndarray) else np.array(ae_recons) In\u00a0[26]: Copied! <pre>encoder_ae = Model(inputs=ae.input, outputs=ae.get_layer(\"z\").output)\n\nz_points = []\nlabels = []\n\nfor xb, _, yb in val_ds:\n    z = encoder_ae.predict(xb, verbose=0)\n    z_points.append(z)\n    labels.append(yb.numpy())\n\nz_points = np.concatenate(z_points, axis=0)\nlabels = np.concatenate(labels, axis=0)\n\nplt.figure(figsize=(6,6))\nsc = plt.scatter(z_points[:, 0], z_points[:, 1], c=labels, s=8, cmap=\"tab10\")\nplt.colorbar(sc)\nplt.title(\"AE - Distribui\u00e7\u00e3o dos algarismos\")\nplt.xlabel(\"X1\")\nplt.ylabel(\"X2\")\nplt.tight_layout()\nplt.savefig(outdir / \"08_latent_space_ae.png\", dpi=800)\nplt.show()\n</pre> encoder_ae = Model(inputs=ae.input, outputs=ae.get_layer(\"z\").output)  z_points = [] labels = []  for xb, _, yb in val_ds:     z = encoder_ae.predict(xb, verbose=0)     z_points.append(z)     labels.append(yb.numpy())  z_points = np.concatenate(z_points, axis=0) labels = np.concatenate(labels, axis=0)  plt.figure(figsize=(6,6)) sc = plt.scatter(z_points[:, 0], z_points[:, 1], c=labels, s=8, cmap=\"tab10\") plt.colorbar(sc) plt.title(\"AE - Distribui\u00e7\u00e3o dos algarismos\") plt.xlabel(\"X1\") plt.ylabel(\"X2\") plt.tight_layout() plt.savefig(outdir / \"08_latent_space_ae.png\", dpi=800) plt.show() <pre>2025-11-16 23:13:10.722817: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n</pre> <p>Com rela\u00e7\u00e3o a como o AE conseguiu distribuir os algarismos \u00e9 interessante perceber que o algarismo 1 aparentemente \u00e9 um n\u00famero muito f\u00e1cil de se aprender, porque tanto o AE quanto o VAE conseguiram distinguir muito bem do restante dos n\u00fameros. Por\u00e9m, com rela\u00e7\u00e3o ao restante dos n\u00fameros, \u00e9 claro que o AE tem mais sobreposi\u00e7\u00f5es do que o VAE, com uma mistura/confus\u00e3o maior entre os n\u00fameros.</p> In\u00a0[27]: Copied! <pre>N_SHOW = 10\n\nplt.figure(figsize=(N_SHOW*1.2, 3.6))\nfor i in range(N_SHOW):\n    # Originais\n    ax = plt.subplot(3, N_SHOW, i + 1)\n    plt.imshow(np.squeeze(x_np[i]), cmap=\"gray\")\n    plt.axis(\"off\")\n\n    # VAE\n    ax = plt.subplot(3, N_SHOW, i + 1 + N_SHOW)\n    plt.imshow(np.squeeze(vae_recons_np[i]), cmap=\"gray\")\n    plt.axis(\"off\")\n\n    # AE\n    ax = plt.subplot(3, N_SHOW, i + 1 + 2*N_SHOW)\n    plt.imshow(np.squeeze(ae_recons_np[i]), cmap=\"gray\")\n    plt.axis(\"off\")\n\nplt.suptitle(\"Top: Originais | Middle: VAE | Bottom: AE\")\nplt.tight_layout()\nplt.savefig(outdir / \"09_ae_vs_vae_recon.png\", dpi=800)\nplt.show()\n</pre> N_SHOW = 10  plt.figure(figsize=(N_SHOW*1.2, 3.6)) for i in range(N_SHOW):     # Originais     ax = plt.subplot(3, N_SHOW, i + 1)     plt.imshow(np.squeeze(x_np[i]), cmap=\"gray\")     plt.axis(\"off\")      # VAE     ax = plt.subplot(3, N_SHOW, i + 1 + N_SHOW)     plt.imshow(np.squeeze(vae_recons_np[i]), cmap=\"gray\")     plt.axis(\"off\")      # AE     ax = plt.subplot(3, N_SHOW, i + 1 + 2*N_SHOW)     plt.imshow(np.squeeze(ae_recons_np[i]), cmap=\"gray\")     plt.axis(\"off\")  plt.suptitle(\"Top: Originais | Middle: VAE | Bottom: AE\") plt.tight_layout() plt.savefig(outdir / \"09_ae_vs_vae_recon.png\", dpi=800) plt.show() <p>Na compara\u00e7\u00e3o entre as reconstru\u00e7\u00f5es apresentadas, observa-se que tanto o Autoencoder (AE) quanto o Variational Autoencoder (VAE) conseguiram capturar a estrutura geral dos d\u00edgitos originais do MNIST, preservando o formato b\u00e1sico e a legibilidade dos n\u00fameros. No entanto, h\u00e1 diferen\u00e7as sutis, por\u00e9m importantes, na qualidade visual das imagens reconstru\u00eddas.</p> <p>As reconstru\u00e7\u00f5es feitas pelo VAE tendem a apresentar um aspecto mais suave e difuso, com contornos levemente borrados e menos definidos. Isso ocorre porque o VAE introduz variabilidade no processo de codifica\u00e7\u00e3o ao amostrar pontos do espa\u00e7o latente segundo distribui\u00e7\u00f5es probabil\u00edsticas, o que promove um espa\u00e7o latente cont\u00ednuo e regularizado, mas reduz a precis\u00e3o pixel a pixel.</p> <p>J\u00e1 as reconstru\u00e7\u00f5es do AE mostram-se mais n\u00edtidas e detalhadas, reproduzindo com maior fidelidade os tra\u00e7os originais dos d\u00edgitos. Isso se deve ao fato de o AE aprender uma representa\u00e7\u00e3o determin\u00edstica, que busca minimizar diretamente o erro de reconstru\u00e7\u00e3o, sem a necessidade de balancear esse objetivo com o termo de diverg\u00eancia KL presente no VAE.</p> <p>Em s\u00edntese, o AE oferece reconstru\u00e7\u00f5es visualmente mais precisas e definidas, enquanto o VAE sacrifica parte dessa nitidez em prol de um espa\u00e7o latente mais estruturado e \u00fatil para tarefas de gera\u00e7\u00e3o e interpola\u00e7\u00e3o de novos d\u00edgitos.</p>"},{"location":"exercicios/vae/vae/#vae-variational-autoencoder","title":"VAE (Variational Autoencoder)\u00b6","text":"<p>Como \u00faltimo experimento dessa se\u00e7\u00e3o de explora\u00e7\u00f5es sobre os mais importantes e marcantes algoritmos durante a hist\u00f3ria das redes neurais, foi escolhido um algoritmo voltado para o aprendizado n\u00e3o supervisionado, o VAE. Variational Autoencoder \u00e9 um dos modelos mais elegantes e importantes dentro do aprendizado n\u00e3o supervisionado e da aprendizagem profunda (Deep Learning). Ele combina ideias de autoencoders e de modelagem probabil\u00edstica, e \u00e9 usado principalmente para gera\u00e7\u00e3o de dados, redu\u00e7\u00e3o de dimensionalidade, e aprendizado de representa\u00e7\u00f5es latentes.</p> <p>Para isso, ser\u00e1 primeiramente explorado o funcionamento de forma gerado de um autoenconder, e posteriormente comparado e exemplificado o diferencial do Variational dentro do autoenconder.</p> <p>Por fim, ser\u00e1 utilizado ambos os algortimos no famoso dataset de algarismos escritos MNIST.</p>"},{"location":"exercicios/vae/vae/#o-que-e-um-autoencoder","title":"O que \u00e9 um Autoencoder?\u00b6","text":"<p>Um Autoencoder \u00e9 um tipo de rede neural artificial usada para aprender representa\u00e7\u00f5es compactas de dados de forma n\u00e3o supervisionada, como j\u00e1 citado. Isso significa que ele n\u00e3o precisa do target dispon\u00edvel para ser treinado, ele aprende de outro modo como se aperfei\u00e7oar. Em outras palavras, um autoencoder aprende a \u201ccomprimir\u201d e \u201cdescomprimir\u201d dados, tentando manter o m\u00e1ximo de informa\u00e7\u00e3o relevante poss\u00edvel.</p> <p>A estrutura b\u00e1sica de um autoenconder \u00e9 composta por duas partes, o encoder e o decoder. O encoder recebe o dado origina, por exemplo, uma imagem de 28\u00d728 pixels e o transforma em uma representa\u00e7\u00e3o comprimida chamada de vetor latente. Essa parte \u201caprende\u201d como extrair as caracter\u00edsticas mais importantes do dado. J\u00e1 a outra parte \u00e9, o decoder, tenta reconstruir o dado original a partir dessa representa\u00e7\u00e3o compacta. Desse modo, com o aprendizado dos dados mais importantes e posteriormente a reconstru\u00e7\u00e3o do conjunto de dados, fica expl\u00edcito que \u00e9 nesse momento que existe a m\u00e9trica utilizada para o treinamento. Isto \u00e9, \"O algoritmo conseguiu reconstruir a imagem de uma forma fidedigna a realidade?\". Desse modo, a rede neural \u00e9 treinada utilizando a diferen\u00e7a entre o x de entrada e o $\\hat{x}$.</p> <p>Com isso, o que \u00e9 gerado de aprendizado \u00e9 quais s\u00e3o os dados resumidos que permitem reconstruir o conjunto original de dados, descartando dados ruidosos ou redundantes. Esse aprendizado se d\u00e1 principalmente na estrutura do espa\u00e7o latente, a camada da rede que une o enconder ao decoder. Essa camada \u00e9 a camada com menor quantidade de dimens\u00f5es, agrupando todos os dados principais de uma forma super compacta, condensando a informa\u00e7\u00e3o importante dos dados e aprendendo a abstra\u00e7\u00e3o dos fatores subjacentes. Dentro dele, a rede neural aprende a representar de forma compacta e estruturada o que \u00e9 importante nos dados de entrada, de modo que essa representa\u00e7\u00e3o possa ser decodificada para reconstruir, ou gerar dados semelhantes.</p> <p>Normalmente, um autoencoder \u00e9 utilizado para:</p> <ol> <li>Redu\u00e7\u00e3o de dimensionalidade</li> <li>Detec\u00e7\u00e3o de anomalias</li> <li>Remo\u00e7\u00e3o de ru\u00eddo</li> <li>Compress\u00e3o de dados</li> <li>Aprendizado de representa\u00e7\u00f5es</li> </ol>"},{"location":"exercicios/vae/vae/#qual-a-diferenca-entre-um-autoencoder-e-o-variational-autoenconder","title":"Qual a diferen\u00e7a entre um Autoencoder e o Variational Autoenconder?\u00b6","text":"<p>Como dito anteriomente, o autoencoder cl\u00e1ssico \u00e9 uma rede neural que aprende a codificar e decodificar dados, de forma que para cada entrada o encoder produz exatamente um vetor latente e o decoder usa esse vetor para gerar a reconstru\u00e7\u00e3o, utilizando como principal fun\u00e7\u00e3o de perda envolve apenas o erro de reconstru\u00e7\u00e3o</p> <p>J\u00e1 o VAE \u00e9 uma generaliza\u00e7\u00e3o que traz uma abordagem probabil\u00edstica no espa\u00e7o latente. Em vez de codificar a entrada em um ponto fixo, o encoder estima par\u00e2metros de uma distribui\u00e7\u00e3o, normalmente uma normal, exp\u00f5e os dados no espa\u00e7o latente a essas distribui\u00e7\u00f5es de modo que introduz incerteza e variabilidade no mapa latente, de modo que para cada entrada existam m\u00faltiplas poss\u00edveis representa\u00e7\u00f5es latentes. Al\u00e9m disso, o modelo imp\u00f5e que essa distribui\u00e7\u00e3o latente estimada se aproxime da fun\u00e7\u00e3o desejada, podendo ser uma normal, mas tamb\u00e9m qualquer outro tipo de distribui\u00e7\u00e3o, de modo que \u00e9 poss\u00edvel criar um \"gerador\" de dados utilizando uma determinada fun\u00e7\u00e3o de distribui\u00e7\u00e3o.</p> <p>Essa diferen\u00e7a traz impactos pr\u00e1ticos importantes. No autoencoder cl\u00e1ssico, como n\u00e3o h\u00e1 restri\u00e7\u00e3o formal sobre como os vetores latentes se organizam, os valores latentes podem ser arbitr\u00e1rios, com os vetores pr\u00f3ximos no espa\u00e7o latente podendo n\u00e3o corresponder a entradas semelhantes, e vetores latentes arbitr\u00e1rios podem n\u00e3o gerar reconstru\u00e7\u00f5es v\u00e1lidas. J\u00e1 no VAE, por causa da regulariza\u00e7\u00e3o e do fato de aprender distribui\u00e7\u00f5es latentes, o espa\u00e7o latente tende a ser bem comportado e cont\u00ednuo: amostras da distribui\u00e7\u00e3o prior tamb\u00e9m geram sa\u00eddas plaus\u00edveis. Isso torna o VAE \u00fatil como modelo generativo, de tal forma que \u00e9 poss\u00edvel amostrar novos pontos latentes e gerar novas amostras coerentes com os dados de treino.</p>"},{"location":"exercicios/vae/vae/#aplicacao-no-mnist","title":"Aplica\u00e7\u00e3o no MNIST\u00b6","text":""},{"location":"exercicios/vae/vae/#vae","title":"VAE\u00b6","text":"<p>Para  explorar melhor o funcionamento do desses dois algoritmos, ou melhor, o algoritmo com suas duas varia\u00e7\u00f5es, ser\u00e1 aplicado sobre o dataset MNIST. Esse foi carregado a partir da biblioteca do Tensor Flow, <code>tf.keras.datasets.mnist</code> e tratado de acordo. Tendo em vista que o dataset aborda imagens de algarismos, com uma dimens\u00e3o de 28x28, o pr\u00e9 processamento sobre cada imagem foi a divis\u00e3o dos pixels por 255, mantendo os valores entre $[0, 1]$.</p> <p>Passando para o funcionamento do encoder e decoder, durente o encoder, ser\u00e1 \"achatado\" o dataset para uma dimens\u00e3o, com os 28x28 pixels, sendo representados por um vetor de dimens\u00f5es $(784, 1)$. Ap\u00f3s isso, ser\u00e3o feitas camadas de redu\u00e7\u00e3o da quantidade de neur\u00f4nios at\u00e9 alcan\u00e7ar a camada latente, com apenas dois neur\u00f4nios, onde ser\u00e3o calculadas as seguintes medidas, m\u00e9dia e desvio padr\u00e3o. No processo de reconstru\u00e7\u00e3o da imagem, o decoder reconstr\u00f3i as camadas at\u00e9 alcan\u00e7ar novamente a quantidade de pixels necess\u00e1rios para a imagem com formata\u00e7\u00e3o 28x28 com o aux\u00edlio de uma fun\u00e7\u00e3o sigm\u00f3ide, sendo o seu treinamento baseado em uma fun\u00e7\u00e3o de perda h\u00edbrida:</p> <ol> <li>Reconstru\u00e7\u00e3o (<code>BCE(x, x_hat)</code>)</li> <li>KL entre <code>q(z|x)</code> e o prior <code>p(z) = N(0, I)</code></li> </ol> <p>Onde a primeira parte \u00e9 respons\u00e1vel por medir o qu\u00e3o bem o decodificador consegue reconstruir o dado original a partir da amostra do vetor latente, sendo algo \u00e9 an\u00e1logo \u00e0 fun\u00e7\u00e3o de perda de um autoencoder tradicional, por exemplo, o erro quadr\u00e1tico m\u00e9dio entre entrada e sa\u00edda. J\u00e1 a segunda parte, mede a diferen\u00e7a entre a distribui\u00e7\u00e3o aproximada do espa\u00e7o latente e a distribui\u00e7\u00e3o alvo, no caso estudado, a normal. O objetivo dessa segunda parte da fun\u00e7\u00e3o de perda \u00e9 for\u00e7ar o espa\u00e7o latente aprendido a se parecer com uma distribui\u00e7\u00e3o normal padr\u00e3o, de modo que evita que o modelo memorize cada dado isoladamente e garante que o espa\u00e7o latente seja cont\u00ednuo e interpol\u00e1vel. Com essas duas caracter\u00edsticas extras \u00e9 poss\u00edvel gerar novas amostras apenas amostrando novos dados, sem precisar de dados reais.</p> <p>Partindo ent\u00e3o para o c\u00f3digo em si, em primeiro lugar, foram setados todos os par\u00eamtros necess\u00e1rios para o experimento funcionar:</p> <ul> <li>Setar a seed de randomiza\u00e7\u00e3o para possibilitar reprodutibilidade</li> <li>Setar os par\u00e2metros utilizados</li> <li>Importar as bibliotecas usadas<ul> <li>random</li> <li>numpy</li> <li>tensortflow</li> <li>matplotlib</li> <li>sklearn</li> <li>pathlib</li> <li>keras</li> </ul> </li> <li>Criar diret\u00f3rio para salvar os resultados encontrados</li> </ul>"},{"location":"exercicios/vae/vae/#ae","title":"AE\u00b6","text":""},{"location":"projetos/","title":"Projetos","text":"<p>Projeto 1</p> <p>Projeto 2</p> <p>Projeto 3</p>"}]}